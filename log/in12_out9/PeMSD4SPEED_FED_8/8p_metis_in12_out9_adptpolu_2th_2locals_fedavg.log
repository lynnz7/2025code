2025-04-07 12:47: Experiment log path in: /data/zm/2025code/log/in12_out9
2025-04-07 12:47: Train: (10183, 12, 39, 3), (10183, 9, 39, 3)
2025-04-07 12:47: Val: (3394, 12, 39, 3), (3394, 9, 39, 3)
2025-04-07 12:47: Test: (3395, 12, 39, 3), (3395, 9, 39, 3)
2025-04-07 12:47: memory_usage: (0.837890625, 2.0)
2025-04-07 12:47: Applying learning rate decay.
2025-04-07 12:47: *****************Model Parameter*****************
2025-04-07 12:47: data_l torch.Size([96]) True
2025-04-07 12:47: tod_embedding.weight torch.Size([288, 32]) True
2025-04-07 12:47: dow_embedding.weight torch.Size([7, 32]) True
2025-04-07 12:47: SpatialEmbedding.B_sp torch.Size([307, 32]) True
2025-04-07 12:47: SpatialEmbedding.B_su torch.Size([307, 32]) True
2025-04-07 12:47: data_embedding.weight torch.Size([96, 1]) True
2025-04-07 12:47: data_embedding.bias torch.Size([96]) True
2025-04-07 12:47: MLPA.blocks.0.linear.weight torch.Size([64, 64]) True
2025-04-07 12:47: MLPA.blocks.0.linear.bias torch.Size([64]) True
2025-04-07 12:47: MLPA.blocks.0.norm.weight torch.Size([64]) True
2025-04-07 12:47: MLPA.blocks.0.norm.bias torch.Size([64]) True
2025-04-07 12:47: MLPB.blocks.0.linear.weight torch.Size([64, 64]) True
2025-04-07 12:47: MLPB.blocks.0.linear.bias torch.Size([64]) True
2025-04-07 12:47: MLPB.blocks.0.norm.weight torch.Size([64]) True
2025-04-07 12:47: MLPB.blocks.0.norm.bias torch.Size([64]) True
2025-04-07 12:47: MLPC.blocks.0.linear.weight torch.Size([96, 96]) True
2025-04-07 12:47: MLPC.blocks.0.linear.bias torch.Size([96]) True
2025-04-07 12:47: MLPC.blocks.0.norm.weight torch.Size([96]) True
2025-04-07 12:47: MLPC.blocks.0.norm.bias torch.Size([96]) True
2025-04-07 12:47: MLPD.blocks.0.linear.weight torch.Size([128, 128]) True
2025-04-07 12:47: MLPD.blocks.0.linear.bias torch.Size([128]) True
2025-04-07 12:47: MLPD.blocks.0.norm.weight torch.Size([128]) True
2025-04-07 12:47: MLPD.blocks.0.norm.bias torch.Size([128]) True
2025-04-07 12:47: MLPE.blocks.0.linear.weight torch.Size([224, 224]) True
2025-04-07 12:47: MLPE.blocks.0.linear.bias torch.Size([224]) True
2025-04-07 12:47: MLPE.blocks.0.norm.weight torch.Size([224]) True
2025-04-07 12:47: MLPE.blocks.0.norm.bias torch.Size([224]) True
2025-04-07 12:47: MLPE.blocks.1.linear.weight torch.Size([224, 224]) True
2025-04-07 12:47: MLPE.blocks.1.linear.bias torch.Size([224]) True
2025-04-07 12:47: MLPE.blocks.1.norm.weight torch.Size([224]) True
2025-04-07 12:47: MLPE.blocks.1.norm.bias torch.Size([224]) True
2025-04-07 12:47: MLPE.blocks.2.linear.weight torch.Size([224, 224]) True
2025-04-07 12:47: MLPE.blocks.2.linear.bias torch.Size([224]) True
2025-04-07 12:47: MLPE.blocks.2.norm.weight torch.Size([224]) True
2025-04-07 12:47: MLPE.blocks.2.norm.bias torch.Size([224]) True
2025-04-07 12:47: MLPF.blocks.0.linear.weight torch.Size([12, 12]) True
2025-04-07 12:47: MLPF.blocks.0.linear.bias torch.Size([12]) True
2025-04-07 12:47: MLPF.blocks.0.norm.weight torch.Size([12]) True
2025-04-07 12:47: MLPF.blocks.0.norm.bias torch.Size([12]) True
2025-04-07 12:47: MLPF.blocks.1.linear.weight torch.Size([12, 12]) True
2025-04-07 12:47: MLPF.blocks.1.linear.bias torch.Size([12]) True
2025-04-07 12:47: MLPF.blocks.1.norm.weight torch.Size([12]) True
2025-04-07 12:47: MLPF.blocks.1.norm.bias torch.Size([12]) True
2025-04-07 12:47: steps_linear.weight torch.Size([9, 12]) True
2025-04-07 12:47: steps_linear.bias torch.Size([9]) True
2025-04-07 12:47: out_linear.weight torch.Size([1, 224]) True
2025-04-07 12:47: out_linear.bias torch.Size([1]) True
2025-04-07 12:47: Total params num: 217470
2025-04-07 12:47: *****************Finish Parameter****************
2025-04-07 12:47: Train Epoch 1: 0/159 Loss: 50.851963
2025-04-07 12:47: Train Epoch 1: 20/159 Loss: 10.636330
2025-04-07 12:47: Train Epoch 1: 40/159 Loss: 7.116090
2025-04-07 12:47: Train Epoch 1: 60/159 Loss: 7.120691
2025-04-07 12:48: Train Epoch 1: 80/159 Loss: 6.034465
2025-04-07 12:48: Train Epoch 1: 100/159 Loss: 6.012995
2025-04-07 12:48: Train Epoch 1: 120/159 Loss: 4.815584
2025-04-07 12:48: Train Epoch 1: 140/159 Loss: 4.965208
2025-04-07 12:48: **********Train Epoch 1: Average Loss: 7.699837
2025-04-07 12:48: **********Train Epoch 1: MAE: 7.699837 RMSE: 10.723104 MAPE: 0.119517
2025-04-07 12:48: **********Val Epoch 1: Average Loss: 3.306232
2025-04-07 12:48: **********Val Epoch 1: MAE: 3.306232 RMSE: 6.262990 MAPE: 0.056172
2025-04-07 12:48: *********************************Current best model saved!
2025-04-07 12:48: Train Epoch 1: 0/159 Loss: 4.663684
2025-04-07 12:48: Train Epoch 1: 20/159 Loss: 4.471715
2025-04-07 12:48: Train Epoch 1: 40/159 Loss: 4.073159
2025-04-07 12:48: Train Epoch 1: 60/159 Loss: 4.233804
2025-04-07 12:48: Train Epoch 1: 80/159 Loss: 3.438292
2025-04-07 12:48: Train Epoch 1: 100/159 Loss: 3.672865
2025-04-07 12:48: Train Epoch 1: 120/159 Loss: 4.014753
2025-04-07 12:48: Train Epoch 1: 140/159 Loss: 3.380596
2025-04-07 12:49: **********Train Epoch 1: Average Loss: 3.955612
2025-04-07 12:49: **********Train Epoch 1: MAE: 3.955612 RMSE: 6.412940 MAPE: 0.065684
2025-04-07 12:49: **********Val Epoch 1: Average Loss: 2.361255
2025-04-07 12:49: **********Val Epoch 1: MAE: 2.361255 RMSE: 4.883298 MAPE: 0.041738
2025-04-07 12:49: *********************************Current best model saved!
2025-04-07 12:49: Train Epoch 2: 0/159 Loss: 3.709680
2025-04-07 12:49: Train Epoch 2: 20/159 Loss: 3.235257
2025-04-07 12:49: Train Epoch 2: 40/159 Loss: 2.623609
2025-04-07 12:49: Train Epoch 2: 60/159 Loss: 2.715194
2025-04-07 12:49: Train Epoch 2: 80/159 Loss: 2.479214
2025-04-07 12:49: Train Epoch 2: 100/159 Loss: 2.300442
2025-04-07 12:49: Train Epoch 2: 120/159 Loss: 2.341323
2025-04-07 12:49: Train Epoch 2: 140/159 Loss: 2.260521
2025-04-07 12:49: **********Train Epoch 2: Average Loss: 2.659860
2025-04-07 12:49: **********Train Epoch 2: MAE: 2.659860 RMSE: 4.641821 MAPE: 0.045907
2025-04-07 12:49: **********Val Epoch 2: Average Loss: 1.720296
2025-04-07 12:49: **********Val Epoch 2: MAE: 1.720296 RMSE: 3.658062 MAPE: 0.031353
2025-04-07 12:49: *********************************Current best model saved!
2025-04-07 12:49: Train Epoch 2: 0/159 Loss: 2.110824
2025-04-07 12:49: Train Epoch 2: 20/159 Loss: 2.141644
2025-04-07 12:49: Train Epoch 2: 40/159 Loss: 2.023602
2025-04-07 12:50: Train Epoch 2: 60/159 Loss: 1.969519
2025-04-07 12:50: Train Epoch 2: 80/159 Loss: 1.787935
2025-04-07 12:50: Train Epoch 2: 100/159 Loss: 1.765182
2025-04-07 12:50: Train Epoch 2: 120/159 Loss: 1.577756
2025-04-07 12:50: Train Epoch 2: 140/159 Loss: 1.788358
2025-04-07 12:50: **********Train Epoch 2: Average Loss: 1.911616
2025-04-07 12:50: **********Train Epoch 2: MAE: 1.911616 RMSE: 3.669487 MAPE: 0.033985
2025-04-07 12:50: **********Val Epoch 2: Average Loss: 1.540054
2025-04-07 12:50: **********Val Epoch 2: MAE: 1.540054 RMSE: 3.305513 MAPE: 0.028122
2025-04-07 12:50: *********************************Current best model saved!
2025-04-07 12:50: Train Epoch 3: 0/159 Loss: 1.944221
2025-04-07 12:50: Train Epoch 3: 20/159 Loss: 2.334334
2025-04-07 12:50: Train Epoch 3: 40/159 Loss: 1.795314
2025-04-07 12:50: Train Epoch 3: 60/159 Loss: 1.706413
2025-04-07 12:50: Train Epoch 3: 80/159 Loss: 1.744141
2025-04-07 12:50: Train Epoch 3: 100/159 Loss: 1.666123
2025-04-07 12:50: Train Epoch 3: 120/159 Loss: 1.487990
2025-04-07 12:51: Train Epoch 3: 140/159 Loss: 1.546306
2025-04-07 12:51: **********Train Epoch 3: Average Loss: 1.907918
2025-04-07 12:51: **********Train Epoch 3: MAE: 1.907918 RMSE: 3.584652 MAPE: 0.033741
2025-04-07 12:51: **********Val Epoch 3: Average Loss: 1.483923
2025-04-07 12:51: **********Val Epoch 3: MAE: 1.483923 RMSE: 3.231988 MAPE: 0.027118
2025-04-07 12:51: *********************************Current best model saved!
2025-04-07 12:51: Train Epoch 3: 0/159 Loss: 1.550710
2025-04-07 12:51: Train Epoch 3: 20/159 Loss: 1.781254
2025-04-07 12:51: Train Epoch 3: 40/159 Loss: 1.668504
2025-04-07 12:51: Train Epoch 3: 60/159 Loss: 1.530858
2025-04-07 12:51: Train Epoch 3: 80/159 Loss: 1.380642
2025-04-07 12:51: Train Epoch 3: 100/159 Loss: 1.592028
2025-04-07 12:51: Train Epoch 3: 120/159 Loss: 1.633668
2025-04-07 12:51: Train Epoch 3: 140/159 Loss: 1.571575
2025-04-07 12:51: **********Train Epoch 3: Average Loss: 1.594320
2025-04-07 12:51: **********Train Epoch 3: MAE: 1.594320 RMSE: 3.275238 MAPE: 0.028709
2025-04-07 12:51: **********Val Epoch 3: Average Loss: 1.448546
2025-04-07 12:51: **********Val Epoch 3: MAE: 1.448546 RMSE: 3.171503 MAPE: 0.026356
2025-04-07 12:51: *********************************Current best model saved!
2025-04-07 12:51: Train Epoch 4: 0/159 Loss: 1.477938
2025-04-07 12:51: Train Epoch 4: 20/159 Loss: 1.877242
2025-04-07 12:52: Train Epoch 4: 40/159 Loss: 1.603905
2025-04-07 12:52: Train Epoch 4: 60/159 Loss: 1.428811
2025-04-07 12:52: Train Epoch 4: 80/159 Loss: 1.542530
2025-04-07 12:52: Train Epoch 4: 100/159 Loss: 1.652625
2025-04-07 12:52: Train Epoch 4: 120/159 Loss: 1.501396
2025-04-07 12:52: Train Epoch 4: 140/159 Loss: 1.489624
2025-04-07 12:52: **********Train Epoch 4: Average Loss: 1.650791
2025-04-07 12:52: **********Train Epoch 4: MAE: 1.650791 RMSE: 3.301118 MAPE: 0.029538
2025-04-07 12:52: **********Val Epoch 4: Average Loss: 1.426664
2025-04-07 12:52: **********Val Epoch 4: MAE: 1.426664 RMSE: 3.137158 MAPE: 0.025989
2025-04-07 12:52: *********************************Current best model saved!
2025-04-07 12:52: Train Epoch 4: 0/159 Loss: 1.561721
2025-04-07 12:52: Train Epoch 4: 20/159 Loss: 1.530436
2025-04-07 12:52: Train Epoch 4: 40/159 Loss: 1.511022
2025-04-07 12:52: Train Epoch 4: 60/159 Loss: 1.428622
2025-04-07 12:52: Train Epoch 4: 80/159 Loss: 1.377923
2025-04-07 12:52: Train Epoch 4: 100/159 Loss: 1.710598
2025-04-07 12:53: Train Epoch 4: 120/159 Loss: 1.668465
2025-04-07 12:53: Train Epoch 4: 140/159 Loss: 1.331940
2025-04-07 12:53: **********Train Epoch 4: Average Loss: 1.486760
2025-04-07 12:53: **********Train Epoch 4: MAE: 1.486760 RMSE: 3.157542 MAPE: 0.026857
2025-04-07 12:53: **********Val Epoch 4: Average Loss: 1.407021
2025-04-07 12:53: **********Val Epoch 4: MAE: 1.407021 RMSE: 3.116265 MAPE: 0.025538
2025-04-07 12:53: *********************************Current best model saved!
2025-04-07 12:53: Train Epoch 5: 0/159 Loss: 1.584969
2025-04-07 12:53: Train Epoch 5: 20/159 Loss: 1.379293
2025-04-07 12:53: Train Epoch 5: 40/159 Loss: 1.528592
2025-04-07 12:53: Train Epoch 5: 60/159 Loss: 1.452540
2025-04-07 12:53: Train Epoch 5: 80/159 Loss: 1.485453
2025-04-07 12:53: Train Epoch 5: 100/159 Loss: 1.450006
2025-04-07 12:53: Train Epoch 5: 120/159 Loss: 1.395535
2025-04-07 12:53: Train Epoch 5: 140/159 Loss: 1.574315
2025-04-07 12:53: **********Train Epoch 5: Average Loss: 1.472743
2025-04-07 12:53: **********Train Epoch 5: MAE: 1.472743 RMSE: 3.135878 MAPE: 0.026576
2025-04-07 12:53: **********Val Epoch 5: Average Loss: 1.378433
2025-04-07 12:53: **********Val Epoch 5: MAE: 1.378433 RMSE: 3.080312 MAPE: 0.024978
2025-04-07 12:53: *********************************Current best model saved!
2025-04-07 12:53: Train Epoch 5: 0/159 Loss: 1.404350
2025-04-07 12:54: Train Epoch 5: 20/159 Loss: 1.373337
2025-04-07 12:54: Train Epoch 5: 40/159 Loss: 1.503356
2025-04-07 12:54: Train Epoch 5: 60/159 Loss: 1.336975
2025-04-07 12:54: Train Epoch 5: 80/159 Loss: 1.569342
2025-04-07 12:54: Train Epoch 5: 100/159 Loss: 1.355170
2025-04-07 12:54: Train Epoch 5: 120/159 Loss: 1.348536
2025-04-07 12:54: Train Epoch 5: 140/159 Loss: 1.118370
2025-04-07 12:54: **********Train Epoch 5: Average Loss: 1.411124
2025-04-07 12:54: **********Train Epoch 5: MAE: 1.411124 RMSE: 3.076325 MAPE: 0.025474
2025-04-07 12:54: **********Val Epoch 5: Average Loss: 1.353898
2025-04-07 12:54: **********Val Epoch 5: MAE: 1.353898 RMSE: 3.050656 MAPE: 0.024524
2025-04-07 12:54: *********************************Current best model saved!
2025-04-07 12:54: Train Epoch 6: 0/159 Loss: 1.474552
2025-04-07 12:54: Train Epoch 6: 20/159 Loss: 1.309973
2025-04-07 12:54: Train Epoch 6: 40/159 Loss: 1.424303
2025-04-07 12:54: Train Epoch 6: 60/159 Loss: 1.321256
2025-04-07 12:54: Train Epoch 6: 80/159 Loss: 1.547993
2025-04-07 12:55: Train Epoch 6: 100/159 Loss: 1.338403
2025-04-07 12:55: Train Epoch 6: 120/159 Loss: 1.390396
2025-04-07 12:55: Train Epoch 6: 140/159 Loss: 1.285450
2025-04-07 12:55: **********Train Epoch 6: Average Loss: 1.414904
2025-04-07 12:55: **********Train Epoch 6: MAE: 1.414904 RMSE: 3.075597 MAPE: 0.025521
2025-04-07 12:55: **********Val Epoch 6: Average Loss: 1.355056
2025-04-07 12:55: **********Val Epoch 6: MAE: 1.355056 RMSE: 3.042237 MAPE: 0.024520
2025-04-07 12:55: Train Epoch 6: 0/159 Loss: 1.475455
2025-04-07 12:55: Train Epoch 6: 20/159 Loss: 1.248482
2025-04-07 12:55: Train Epoch 6: 40/159 Loss: 1.500819
2025-04-07 12:55: Train Epoch 6: 60/159 Loss: 1.274871
2025-04-07 12:55: Train Epoch 6: 80/159 Loss: 1.343159
2025-04-07 12:55: Train Epoch 6: 100/159 Loss: 1.434279
2025-04-07 12:55: Train Epoch 6: 120/159 Loss: 1.327864
2025-04-07 12:55: Train Epoch 6: 140/159 Loss: 1.276210
2025-04-07 12:55: **********Train Epoch 6: Average Loss: 1.370958
2025-04-07 12:55: **********Train Epoch 6: MAE: 1.370958 RMSE: 3.027021 MAPE: 0.024731
2025-04-07 12:55: **********Val Epoch 6: Average Loss: 1.338241
2025-04-07 12:55: **********Val Epoch 6: MAE: 1.338241 RMSE: 3.013673 MAPE: 0.024197
2025-04-07 12:55: *********************************Current best model saved!
2025-04-07 12:56: Train Epoch 7: 0/159 Loss: 1.385889
2025-04-07 12:56: Train Epoch 7: 20/159 Loss: 1.444254
2025-04-07 12:56: Train Epoch 7: 40/159 Loss: 1.260787
2025-04-07 12:56: Train Epoch 7: 60/159 Loss: 1.394229
2025-04-07 12:56: Train Epoch 7: 80/159 Loss: 1.272547
2025-04-07 12:56: Train Epoch 7: 100/159 Loss: 1.469403
2025-04-07 12:56: Train Epoch 7: 120/159 Loss: 1.501831
2025-04-07 12:56: Train Epoch 7: 140/159 Loss: 1.566180
2025-04-07 12:56: **********Train Epoch 7: Average Loss: 1.374239
2025-04-07 12:56: **********Train Epoch 7: MAE: 1.374239 RMSE: 3.026097 MAPE: 0.024792
2025-04-07 12:56: **********Val Epoch 7: Average Loss: 1.325749
2025-04-07 12:56: **********Val Epoch 7: MAE: 1.325749 RMSE: 2.998936 MAPE: 0.023953
2025-04-07 12:56: *********************************Current best model saved!
2025-04-07 12:56: Train Epoch 7: 0/159 Loss: 1.260031
2025-04-07 12:56: Train Epoch 7: 20/159 Loss: 1.390883
2025-04-07 12:56: Train Epoch 7: 40/159 Loss: 1.426279
2025-04-07 12:56: Train Epoch 7: 60/159 Loss: 1.282385
2025-04-07 12:56: Train Epoch 7: 80/159 Loss: 1.314334
2025-04-07 12:57: Train Epoch 7: 100/159 Loss: 1.431751
2025-04-07 12:57: Train Epoch 7: 120/159 Loss: 1.381023
2025-04-07 12:57: Train Epoch 7: 140/159 Loss: 1.209193
2025-04-07 12:57: **********Train Epoch 7: Average Loss: 1.339145
2025-04-07 12:57: **********Train Epoch 7: MAE: 1.339145 RMSE: 2.973375 MAPE: 0.024158
2025-04-07 12:57: **********Val Epoch 7: Average Loss: 1.309785
2025-04-07 12:57: **********Val Epoch 7: MAE: 1.309785 RMSE: 2.953144 MAPE: 0.023671
2025-04-07 12:57: *********************************Current best model saved!
2025-04-07 12:57: Train Epoch 8: 0/159 Loss: 1.215212
2025-04-07 12:57: Train Epoch 8: 20/159 Loss: 1.304009
2025-04-07 12:57: Train Epoch 8: 40/159 Loss: 1.247059
2025-04-07 12:57: Train Epoch 8: 60/159 Loss: 1.418969
2025-04-07 12:57: Train Epoch 8: 80/159 Loss: 1.303395
2025-04-07 12:57: Train Epoch 8: 100/159 Loss: 1.261173
2025-04-07 12:57: Train Epoch 8: 120/159 Loss: 1.246946
2025-04-07 12:57: Train Epoch 8: 140/159 Loss: 1.382594
2025-04-07 12:57: **********Train Epoch 8: Average Loss: 1.345747
2025-04-07 12:57: **********Train Epoch 8: MAE: 1.345747 RMSE: 2.978210 MAPE: 0.024259
2025-04-07 12:58: **********Val Epoch 8: Average Loss: 1.306545
2025-04-07 12:58: **********Val Epoch 8: MAE: 1.306545 RMSE: 2.947903 MAPE: 0.023675
2025-04-07 12:58: *********************************Current best model saved!
2025-04-07 12:58: Train Epoch 8: 0/159 Loss: 1.407741
2025-04-07 12:58: Train Epoch 8: 20/159 Loss: 1.613500
2025-04-07 12:58: Train Epoch 8: 40/159 Loss: 1.366279
2025-04-07 12:58: Train Epoch 8: 60/159 Loss: 1.290864
2025-04-07 12:58: Train Epoch 8: 80/159 Loss: 1.305011
2025-04-07 12:58: Train Epoch 8: 100/159 Loss: 1.377340
2025-04-07 12:58: Train Epoch 8: 120/159 Loss: 1.258730
2025-04-07 12:58: Train Epoch 8: 140/159 Loss: 1.223072
2025-04-07 12:58: **********Train Epoch 8: Average Loss: 1.313194
2025-04-07 12:58: **********Train Epoch 8: MAE: 1.313194 RMSE: 2.918118 MAPE: 0.023693
2025-04-07 12:58: **********Val Epoch 8: Average Loss: 1.285650
2025-04-07 12:58: **********Val Epoch 8: MAE: 1.285650 RMSE: 2.887080 MAPE: 0.023258
2025-04-07 12:58: *********************************Current best model saved!
2025-04-07 12:58: Train Epoch 9: 0/159 Loss: 1.338213
2025-04-07 12:58: Train Epoch 9: 20/159 Loss: 1.239145
2025-04-07 12:58: Train Epoch 9: 40/159 Loss: 1.257876
2025-04-07 12:58: Train Epoch 9: 60/159 Loss: 1.305969
2025-04-07 12:59: Train Epoch 9: 80/159 Loss: 1.276776
2025-04-07 12:59: Train Epoch 9: 100/159 Loss: 1.226203
2025-04-07 12:59: Train Epoch 9: 120/159 Loss: 1.299964
2025-04-07 12:59: Train Epoch 9: 140/159 Loss: 1.196243
2025-04-07 12:59: **********Train Epoch 9: Average Loss: 1.323365
2025-04-07 12:59: **********Train Epoch 9: MAE: 1.323365 RMSE: 2.934164 MAPE: 0.023864
2025-04-07 12:59: **********Val Epoch 9: Average Loss: 1.289883
2025-04-07 12:59: **********Val Epoch 9: MAE: 1.289883 RMSE: 2.875123 MAPE: 0.023293
2025-04-07 12:59: Train Epoch 9: 0/159 Loss: 1.319334
2025-04-07 12:59: Train Epoch 9: 20/159 Loss: 1.378920
2025-04-07 12:59: Train Epoch 9: 40/159 Loss: 1.349852
2025-04-07 12:59: Train Epoch 9: 60/159 Loss: 1.228700
2025-04-07 12:59: Train Epoch 9: 80/159 Loss: 1.362285
2025-04-07 12:59: Train Epoch 9: 100/159 Loss: 1.213905
2025-04-07 12:59: Train Epoch 9: 120/159 Loss: 1.301777
2025-04-07 12:59: Train Epoch 9: 140/159 Loss: 1.208887
2025-04-07 13:00: **********Train Epoch 9: Average Loss: 1.293054
2025-04-07 13:00: **********Train Epoch 9: MAE: 1.293054 RMSE: 2.877124 MAPE: 0.023328
2025-04-07 13:00: **********Val Epoch 9: Average Loss: 1.265198
2025-04-07 13:00: **********Val Epoch 9: MAE: 1.265198 RMSE: 2.855751 MAPE: 0.022868
2025-04-07 13:00: *********************************Current best model saved!
2025-04-07 13:00: Train Epoch 10: 0/159 Loss: 1.442844
2025-04-07 13:00: Train Epoch 10: 20/159 Loss: 1.252211
2025-04-07 13:00: Train Epoch 10: 40/159 Loss: 1.301533
2025-04-07 13:00: Train Epoch 10: 60/159 Loss: 1.259168
2025-04-07 13:00: Train Epoch 10: 80/159 Loss: 1.290106
2025-04-07 13:00: Train Epoch 10: 100/159 Loss: 1.267821
2025-04-07 13:00: Train Epoch 10: 120/159 Loss: 1.179081
2025-04-07 13:00: Train Epoch 10: 140/159 Loss: 1.257461
2025-04-07 13:00: **********Train Epoch 10: Average Loss: 1.305796
2025-04-07 13:00: **********Train Epoch 10: MAE: 1.305796 RMSE: 2.902912 MAPE: 0.023566
2025-04-07 13:00: **********Val Epoch 10: Average Loss: 1.275345
2025-04-07 13:00: **********Val Epoch 10: MAE: 1.275345 RMSE: 2.874483 MAPE: 0.023095
2025-04-07 13:00: Train Epoch 10: 0/159 Loss: 1.127520
2025-04-07 13:00: Train Epoch 10: 20/159 Loss: 1.237401
2025-04-07 13:00: Train Epoch 10: 40/159 Loss: 1.148414
2025-04-07 13:01: Train Epoch 10: 60/159 Loss: 1.260887
2025-04-07 13:01: Train Epoch 10: 80/159 Loss: 1.334561
2025-04-07 13:01: Train Epoch 10: 100/159 Loss: 1.314268
2025-04-07 13:01: Train Epoch 10: 120/159 Loss: 1.289732
2025-04-07 13:01: Train Epoch 10: 140/159 Loss: 1.292935
2025-04-07 13:01: **********Train Epoch 10: Average Loss: 1.276700
2025-04-07 13:01: **********Train Epoch 10: MAE: 1.276700 RMSE: 2.844810 MAPE: 0.023041
2025-04-07 13:01: **********Val Epoch 10: Average Loss: 1.253999
2025-04-07 13:01: **********Val Epoch 10: MAE: 1.253999 RMSE: 2.828550 MAPE: 0.022768
2025-04-07 13:01: *********************************Current best model saved!
2025-04-07 13:01: Train Epoch 11: 0/159 Loss: 1.318415
2025-04-07 13:01: Train Epoch 11: 20/159 Loss: 1.288971
2025-04-07 13:01: Experiment log path in: /data/zm/2025code/log/in12_out9
2025-04-07 13:01: Train: (10183, 12, 39, 3), (10183, 9, 39, 3)
2025-04-07 13:01: Val: (3394, 12, 39, 3), (3394, 9, 39, 3)
2025-04-07 13:01: Test: (3395, 12, 39, 3), (3395, 9, 39, 3)
2025-04-07 13:01: memory_usage: (0.837890625, 2.0)
2025-04-07 13:01: Applying learning rate decay.
2025-04-07 13:01: *****************Model Parameter*****************
2025-04-07 13:01: data_l torch.Size([96]) True
2025-04-07 13:01: tod_embedding.weight torch.Size([288, 32]) True
2025-04-07 13:01: dow_embedding.weight torch.Size([7, 32]) True
2025-04-07 13:01: SpatialEmbedding.B_sp torch.Size([307, 32]) True
2025-04-07 13:01: SpatialEmbedding.B_su torch.Size([307, 32]) True
2025-04-07 13:01: data_embedding.weight torch.Size([96, 1]) True
2025-04-07 13:01: data_embedding.bias torch.Size([96]) True
2025-04-07 13:01: MLPA.blocks.0.linear.weight torch.Size([64, 64]) True
2025-04-07 13:01: MLPA.blocks.0.linear.bias torch.Size([64]) True
2025-04-07 13:01: MLPA.blocks.0.norm.weight torch.Size([64]) True
2025-04-07 13:01: MLPA.blocks.0.norm.bias torch.Size([64]) True
2025-04-07 13:01: MLPB.blocks.0.linear.weight torch.Size([64, 64]) True
2025-04-07 13:01: MLPB.blocks.0.linear.bias torch.Size([64]) True
2025-04-07 13:01: MLPB.blocks.0.norm.weight torch.Size([64]) True
2025-04-07 13:01: MLPB.blocks.0.norm.bias torch.Size([64]) True
2025-04-07 13:01: MLPC.blocks.0.linear.weight torch.Size([96, 96]) True
2025-04-07 13:01: MLPC.blocks.0.linear.bias torch.Size([96]) True
2025-04-07 13:01: MLPC.blocks.0.norm.weight torch.Size([96]) True
2025-04-07 13:01: MLPC.blocks.0.norm.bias torch.Size([96]) True
2025-04-07 13:01: MLPD.blocks.0.linear.weight torch.Size([128, 128]) True
2025-04-07 13:01: MLPD.blocks.0.linear.bias torch.Size([128]) True
2025-04-07 13:01: MLPD.blocks.0.norm.weight torch.Size([128]) True
2025-04-07 13:01: MLPD.blocks.0.norm.bias torch.Size([128]) True
2025-04-07 13:01: MLPE.blocks.0.linear.weight torch.Size([224, 224]) True
2025-04-07 13:01: MLPE.blocks.0.linear.bias torch.Size([224]) True
2025-04-07 13:01: MLPE.blocks.0.norm.weight torch.Size([224]) True
2025-04-07 13:01: MLPE.blocks.0.norm.bias torch.Size([224]) True
2025-04-07 13:01: MLPE.blocks.1.linear.weight torch.Size([224, 224]) True
2025-04-07 13:01: MLPE.blocks.1.linear.bias torch.Size([224]) True
2025-04-07 13:01: MLPE.blocks.1.norm.weight torch.Size([224]) True
2025-04-07 13:01: MLPE.blocks.1.norm.bias torch.Size([224]) True
2025-04-07 13:01: MLPE.blocks.2.linear.weight torch.Size([224, 224]) True
2025-04-07 13:01: MLPE.blocks.2.linear.bias torch.Size([224]) True
2025-04-07 13:01: MLPE.blocks.2.norm.weight torch.Size([224]) True
2025-04-07 13:01: MLPE.blocks.2.norm.bias torch.Size([224]) True
2025-04-07 13:01: MLPF.blocks.0.linear.weight torch.Size([12, 12]) True
2025-04-07 13:01: MLPF.blocks.0.linear.bias torch.Size([12]) True
2025-04-07 13:01: MLPF.blocks.0.norm.weight torch.Size([12]) True
2025-04-07 13:01: MLPF.blocks.0.norm.bias torch.Size([12]) True
2025-04-07 13:01: MLPF.blocks.1.linear.weight torch.Size([12, 12]) True
2025-04-07 13:01: MLPF.blocks.1.linear.bias torch.Size([12]) True
2025-04-07 13:01: MLPF.blocks.1.norm.weight torch.Size([12]) True
2025-04-07 13:01: MLPF.blocks.1.norm.bias torch.Size([12]) True
2025-04-07 13:01: steps_linear.weight torch.Size([9, 12]) True
2025-04-07 13:01: steps_linear.bias torch.Size([9]) True
2025-04-07 13:01: out_linear.weight torch.Size([1, 224]) True
2025-04-07 13:01: out_linear.bias torch.Size([1]) True
2025-04-07 13:01: Total params num: 217470
2025-04-07 13:01: *****************Finish Parameter****************
2025-04-07 13:01: Train Epoch 1: 0/159 Loss: 50.851963
2025-04-07 13:01: Train Epoch 1: 20/159 Loss: 10.636330
2025-04-07 13:01: Train Epoch 1: 40/159 Loss: 7.116090
2025-04-07 13:01: Train Epoch 1: 60/159 Loss: 7.120691
2025-04-07 13:02: Train Epoch 1: 80/159 Loss: 6.034465
2025-04-07 13:02: Train Epoch 1: 100/159 Loss: 6.012995
2025-04-07 13:02: Train Epoch 1: 120/159 Loss: 4.815584
2025-04-07 13:02: Experiment log path in: /data/zm/2025code/log/in12_out9
2025-04-07 13:02: Train: (10183, 12, 39, 3), (10183, 9, 39, 3)
2025-04-07 13:02: Val: (3394, 12, 39, 3), (3394, 9, 39, 3)
2025-04-07 13:02: Test: (3395, 12, 39, 3), (3395, 9, 39, 3)
2025-04-07 13:02: memory_usage: (0.837890625, 2.0)
2025-04-07 13:02: Train Epoch 1: 140/159 Loss: 4.965208
2025-04-07 13:02: Applying learning rate decay.
2025-04-07 13:02: *****************Model Parameter*****************
2025-04-07 13:02: data_l torch.Size([96]) True
2025-04-07 13:02: tod_embedding.weight torch.Size([288, 32]) True
2025-04-07 13:02: dow_embedding.weight torch.Size([7, 32]) True
2025-04-07 13:02: SpatialEmbedding.B_sp torch.Size([307, 32]) True
2025-04-07 13:02: SpatialEmbedding.B_su torch.Size([307, 32]) True
2025-04-07 13:02: data_embedding.weight torch.Size([96, 1]) True
2025-04-07 13:02: data_embedding.bias torch.Size([96]) True
2025-04-07 13:02: MLPA.blocks.0.linear.weight torch.Size([64, 64]) True
2025-04-07 13:02: MLPA.blocks.0.linear.bias torch.Size([64]) True
2025-04-07 13:02: MLPA.blocks.0.norm.weight torch.Size([64]) True
2025-04-07 13:02: MLPA.blocks.0.norm.bias torch.Size([64]) True
2025-04-07 13:02: MLPB.blocks.0.linear.weight torch.Size([64, 64]) True
2025-04-07 13:02: MLPB.blocks.0.linear.bias torch.Size([64]) True
2025-04-07 13:02: MLPB.blocks.0.norm.weight torch.Size([64]) True
2025-04-07 13:02: MLPB.blocks.0.norm.bias torch.Size([64]) True
2025-04-07 13:02: MLPC.blocks.0.linear.weight torch.Size([96, 96]) True
2025-04-07 13:02: MLPC.blocks.0.linear.bias torch.Size([96]) True
2025-04-07 13:02: MLPC.blocks.0.norm.weight torch.Size([96]) True
2025-04-07 13:02: MLPC.blocks.0.norm.bias torch.Size([96]) True
2025-04-07 13:02: MLPD.blocks.0.linear.weight torch.Size([128, 128]) True
2025-04-07 13:02: MLPD.blocks.0.linear.bias torch.Size([128]) True
2025-04-07 13:02: MLPD.blocks.0.norm.weight torch.Size([128]) True
2025-04-07 13:02: MLPD.blocks.0.norm.bias torch.Size([128]) True
2025-04-07 13:02: MLPE.blocks.0.linear.weight torch.Size([224, 224]) True
2025-04-07 13:02: MLPE.blocks.0.linear.bias torch.Size([224]) True
2025-04-07 13:02: MLPE.blocks.0.norm.weight torch.Size([224]) True
2025-04-07 13:02: MLPE.blocks.0.norm.bias torch.Size([224]) True
2025-04-07 13:02: MLPE.blocks.1.linear.weight torch.Size([224, 224]) True
2025-04-07 13:02: MLPE.blocks.1.linear.bias torch.Size([224]) True
2025-04-07 13:02: MLPE.blocks.1.norm.weight torch.Size([224]) True
2025-04-07 13:02: MLPE.blocks.1.norm.bias torch.Size([224]) True
2025-04-07 13:02: MLPE.blocks.2.linear.weight torch.Size([224, 224]) True
2025-04-07 13:02: MLPE.blocks.2.linear.bias torch.Size([224]) True
2025-04-07 13:02: MLPE.blocks.2.norm.weight torch.Size([224]) True
2025-04-07 13:02: MLPE.blocks.2.norm.bias torch.Size([224]) True
2025-04-07 13:02: MLPF.blocks.0.linear.weight torch.Size([12, 12]) True
2025-04-07 13:02: MLPF.blocks.0.linear.bias torch.Size([12]) True
2025-04-07 13:02: MLPF.blocks.0.norm.weight torch.Size([12]) True
2025-04-07 13:02: MLPF.blocks.0.norm.bias torch.Size([12]) True
2025-04-07 13:02: MLPF.blocks.1.linear.weight torch.Size([12, 12]) True
2025-04-07 13:02: MLPF.blocks.1.linear.bias torch.Size([12]) True
2025-04-07 13:02: MLPF.blocks.1.norm.weight torch.Size([12]) True
2025-04-07 13:02: MLPF.blocks.1.norm.bias torch.Size([12]) True
2025-04-07 13:02: steps_linear.weight torch.Size([9, 12]) True
2025-04-07 13:02: steps_linear.bias torch.Size([9]) True
2025-04-07 13:02: out_linear.weight torch.Size([1, 224]) True
2025-04-07 13:02: out_linear.bias torch.Size([1]) True
2025-04-07 13:02: Total params num: 217470
2025-04-07 13:02: *****************Finish Parameter****************
2025-04-07 13:02: Train Epoch 1: 0/159 Loss: 50.851963
2025-04-07 13:02: **********Train Epoch 1: Average Loss: 7.699837
2025-04-07 13:02: **********Train Epoch 1: MAE: 7.699837 RMSE: 10.723104 MAPE: 0.119517
2025-04-07 13:02: Train Epoch 1: 20/159 Loss: 10.636330
2025-04-07 13:02: **********Val Epoch 1: Average Loss: 3.306232
2025-04-07 13:02: **********Val Epoch 1: MAE: 3.306232 RMSE: 6.262990 MAPE: 0.056172
2025-04-07 13:02: *********************************Current best model saved!
2025-04-07 13:02: Train Epoch 1: 40/159 Loss: 7.116090
2025-04-07 13:02: Train Epoch 1: 0/159 Loss: 4.663684
2025-04-07 13:02: Train Epoch 1: 60/159 Loss: 7.120691
2025-04-07 13:02: Train Epoch 1: 20/159 Loss: 4.471715
2025-04-07 13:02: Train Epoch 1: 80/159 Loss: 6.034465
2025-04-07 13:02: Train Epoch 1: 40/159 Loss: 4.073159
2025-04-07 13:02: Train Epoch 1: 100/159 Loss: 6.012995
2025-04-07 13:02: Train Epoch 1: 60/159 Loss: 4.233804
2025-04-07 13:02: Train Epoch 1: 120/159 Loss: 4.815584
2025-04-07 13:02: Train Epoch 1: 140/159 Loss: 4.965208
2025-04-07 13:02: Train Epoch 1: 80/159 Loss: 3.438292
2025-04-07 13:02: **********Train Epoch 1: Average Loss: 7.699837
2025-04-07 13:02: **********Train Epoch 1: MAE: 7.699837 RMSE: 10.723104 MAPE: 0.119517
2025-04-07 13:02: Train Epoch 1: 100/159 Loss: 3.672865
2025-04-07 13:02: **********Val Epoch 1: Average Loss: 3.306232
2025-04-07 13:02: **********Val Epoch 1: MAE: 3.306232 RMSE: 6.262990 MAPE: 0.056172
2025-04-07 13:02: *********************************Current best model saved!
2025-04-07 13:02: Train Epoch 1: 0/159 Loss: 4.663684
2025-04-07 13:02: Train Epoch 1: 120/159 Loss: 4.014753
2025-04-07 13:02: Train Epoch 1: 20/159 Loss: 4.471715
2025-04-07 13:02: Train Epoch 1: 140/159 Loss: 3.380596
2025-04-07 13:02: Train Epoch 1: 40/159 Loss: 4.073159
2025-04-07 13:02: **********Train Epoch 1: Average Loss: 3.955612
2025-04-07 13:02: **********Train Epoch 1: MAE: 3.955612 RMSE: 6.412940 MAPE: 0.065684
2025-04-07 13:02: **********Val Epoch 1: Average Loss: 2.361255
2025-04-07 13:02: **********Val Epoch 1: MAE: 2.361255 RMSE: 4.883298 MAPE: 0.041738
2025-04-07 13:02: *********************************Current best model saved!
2025-04-07 13:02: Train Epoch 1: 60/159 Loss: 4.233804
2025-04-07 13:03: Train Epoch 1: 80/159 Loss: 3.438292
2025-04-07 13:03: Train Epoch 1: 100/159 Loss: 3.672865
2025-04-07 13:03: Train Epoch 1: 120/159 Loss: 4.014753
2025-04-07 13:03: Train Epoch 1: 140/159 Loss: 3.380596
2025-04-07 13:03: **********Train Epoch 1: Average Loss: 3.955612
2025-04-07 13:03: **********Train Epoch 1: MAE: 3.955612 RMSE: 6.412940 MAPE: 0.065684
2025-04-07 13:03: **********Val Epoch 1: Average Loss: 2.361255
2025-04-07 13:03: **********Val Epoch 1: MAE: 2.361255 RMSE: 4.883298 MAPE: 0.041738
2025-04-07 13:03: *********************************Current best model saved!
2025-04-07 13:03: Total training time: 1.0210min, best loss: 2.361255
2025-04-07 13:04: Experiment log path in: /data/zm/2025code/log/in12_out9
2025-04-07 13:04: Train: (10183, 12, 39, 3), (10183, 9, 39, 3)
2025-04-07 13:04: Val: (3394, 12, 39, 3), (3394, 9, 39, 3)
2025-04-07 13:04: Test: (3395, 12, 39, 3), (3395, 9, 39, 3)
2025-04-07 13:04: memory_usage: (0.837890625, 2.0)
2025-04-07 13:04: Applying learning rate decay.
2025-04-07 13:04: *****************Model Parameter*****************
2025-04-07 13:04: data_l torch.Size([96]) True
2025-04-07 13:04: tod_embedding.weight torch.Size([288, 32]) True
2025-04-07 13:04: dow_embedding.weight torch.Size([7, 32]) True
2025-04-07 13:04: SpatialEmbedding.B_sp torch.Size([307, 32]) True
2025-04-07 13:04: SpatialEmbedding.B_su torch.Size([307, 32]) True
2025-04-07 13:04: data_embedding.weight torch.Size([96, 1]) True
2025-04-07 13:04: data_embedding.bias torch.Size([96]) True
2025-04-07 13:04: MLPA.blocks.0.linear.weight torch.Size([64, 64]) True
2025-04-07 13:04: MLPA.blocks.0.linear.bias torch.Size([64]) True
2025-04-07 13:04: MLPA.blocks.0.norm.weight torch.Size([64]) True
2025-04-07 13:04: MLPA.blocks.0.norm.bias torch.Size([64]) True
2025-04-07 13:04: MLPB.blocks.0.linear.weight torch.Size([64, 64]) True
2025-04-07 13:04: MLPB.blocks.0.linear.bias torch.Size([64]) True
2025-04-07 13:04: MLPB.blocks.0.norm.weight torch.Size([64]) True
2025-04-07 13:04: MLPB.blocks.0.norm.bias torch.Size([64]) True
2025-04-07 13:04: MLPC.blocks.0.linear.weight torch.Size([96, 96]) True
2025-04-07 13:04: MLPC.blocks.0.linear.bias torch.Size([96]) True
2025-04-07 13:04: MLPC.blocks.0.norm.weight torch.Size([96]) True
2025-04-07 13:04: MLPC.blocks.0.norm.bias torch.Size([96]) True
2025-04-07 13:04: MLPD.blocks.0.linear.weight torch.Size([128, 128]) True
2025-04-07 13:04: MLPD.blocks.0.linear.bias torch.Size([128]) True
2025-04-07 13:04: MLPD.blocks.0.norm.weight torch.Size([128]) True
2025-04-07 13:04: MLPD.blocks.0.norm.bias torch.Size([128]) True
2025-04-07 13:04: MLPE.blocks.0.linear.weight torch.Size([224, 224]) True
2025-04-07 13:04: MLPE.blocks.0.linear.bias torch.Size([224]) True
2025-04-07 13:04: MLPE.blocks.0.norm.weight torch.Size([224]) True
2025-04-07 13:04: MLPE.blocks.0.norm.bias torch.Size([224]) True
2025-04-07 13:04: MLPE.blocks.1.linear.weight torch.Size([224, 224]) True
2025-04-07 13:04: MLPE.blocks.1.linear.bias torch.Size([224]) True
2025-04-07 13:04: MLPE.blocks.1.norm.weight torch.Size([224]) True
2025-04-07 13:04: MLPE.blocks.1.norm.bias torch.Size([224]) True
2025-04-07 13:04: MLPE.blocks.2.linear.weight torch.Size([224, 224]) True
2025-04-07 13:04: MLPE.blocks.2.linear.bias torch.Size([224]) True
2025-04-07 13:04: MLPE.blocks.2.norm.weight torch.Size([224]) True
2025-04-07 13:04: MLPE.blocks.2.norm.bias torch.Size([224]) True
2025-04-07 13:04: MLPF.blocks.0.linear.weight torch.Size([12, 12]) True
2025-04-07 13:04: MLPF.blocks.0.linear.bias torch.Size([12]) True
2025-04-07 13:04: MLPF.blocks.0.norm.weight torch.Size([12]) True
2025-04-07 13:04: MLPF.blocks.0.norm.bias torch.Size([12]) True
2025-04-07 13:04: MLPF.blocks.1.linear.weight torch.Size([12, 12]) True
2025-04-07 13:04: MLPF.blocks.1.linear.bias torch.Size([12]) True
2025-04-07 13:04: MLPF.blocks.1.norm.weight torch.Size([12]) True
2025-04-07 13:04: MLPF.blocks.1.norm.bias torch.Size([12]) True
2025-04-07 13:04: steps_linear.weight torch.Size([9, 12]) True
2025-04-07 13:04: steps_linear.bias torch.Size([9]) True
2025-04-07 13:04: out_linear.weight torch.Size([1, 224]) True
2025-04-07 13:04: out_linear.bias torch.Size([1]) True
2025-04-07 13:04: Total params num: 217470
2025-04-07 13:04: *****************Finish Parameter****************
2025-04-07 13:05: Train Epoch 1: 0/159 Loss: 50.851963
2025-04-07 13:05: Train Epoch 1: 20/159 Loss: 10.636330
2025-04-07 13:05: Train Epoch 1: 40/159 Loss: 7.116090
2025-04-07 13:05: Train Epoch 1: 60/159 Loss: 7.120691
2025-04-07 13:05: Train Epoch 1: 80/159 Loss: 6.034465
2025-04-07 13:05: Train Epoch 1: 100/159 Loss: 6.012995
2025-04-07 13:05: Train Epoch 1: 120/159 Loss: 4.815584
2025-04-07 13:05: Train Epoch 1: 140/159 Loss: 4.965208
2025-04-07 13:05: **********Train Epoch 1: Average Loss: 7.699837
2025-04-07 13:05: **********Train Epoch 1: MAE: 7.699837 RMSE: 10.723104 MAPE: 0.119517
2025-04-07 13:05: **********Val Epoch 1: Average Loss: 3.306232
2025-04-07 13:05: **********Val Epoch 1: MAE: 3.306232 RMSE: 6.262990 MAPE: 0.056172
2025-04-07 13:05: *********************************Current best model saved!
2025-04-07 13:05: Train Epoch 1: 0/159 Loss: 4.663684
2025-04-07 13:05: Train Epoch 1: 20/159 Loss: 4.471715
2025-04-07 13:05: Train Epoch 1: 40/159 Loss: 4.073159
2025-04-07 13:05: Train Epoch 1: 60/159 Loss: 4.233804
2025-04-07 13:05: Train Epoch 1: 80/159 Loss: 3.438292
2025-04-07 13:05: Train Epoch 1: 100/159 Loss: 3.672865
2025-04-07 13:05: Train Epoch 1: 120/159 Loss: 4.014753
2025-04-07 13:05: Train Epoch 1: 140/159 Loss: 3.380596
2025-04-07 13:05: **********Train Epoch 1: Average Loss: 3.955612
2025-04-07 13:05: **********Train Epoch 1: MAE: 3.955612 RMSE: 6.412940 MAPE: 0.065684
2025-04-07 13:05: **********Val Epoch 1: Average Loss: 2.361255
2025-04-07 13:05: **********Val Epoch 1: MAE: 2.361255 RMSE: 4.883298 MAPE: 0.041738
2025-04-07 13:05: *********************************Current best model saved!
2025-04-07 13:05: Total training time: 0.9586min, best loss: 2.361255
2025-04-07 13:07: Experiment log path in: /data/zm/2025code/log/in12_out9
2025-04-07 13:07: Train: (10183, 12, 39, 3), (10183, 9, 39, 3)
2025-04-07 13:07: Val: (3394, 12, 39, 3), (3394, 9, 39, 3)
2025-04-07 13:07: Test: (3395, 12, 39, 3), (3395, 9, 39, 3)
2025-04-07 13:07: memory_usage: (0.837890625, 2.0)
2025-04-07 13:07: Applying learning rate decay.
2025-04-07 13:07: *****************Model Parameter*****************
2025-04-07 13:07: data_l torch.Size([96]) True
2025-04-07 13:07: tod_embedding.weight torch.Size([288, 32]) True
2025-04-07 13:07: dow_embedding.weight torch.Size([7, 32]) True
2025-04-07 13:07: SpatialEmbedding.B_sp torch.Size([307, 32]) True
2025-04-07 13:07: SpatialEmbedding.B_su torch.Size([307, 32]) True
2025-04-07 13:07: data_embedding.weight torch.Size([96, 1]) True
2025-04-07 13:07: data_embedding.bias torch.Size([96]) True
2025-04-07 13:07: MLPA.blocks.0.linear.weight torch.Size([64, 64]) True
2025-04-07 13:07: MLPA.blocks.0.linear.bias torch.Size([64]) True
2025-04-07 13:07: MLPA.blocks.0.norm.weight torch.Size([64]) True
2025-04-07 13:07: MLPA.blocks.0.norm.bias torch.Size([64]) True
2025-04-07 13:07: MLPB.blocks.0.linear.weight torch.Size([64, 64]) True
2025-04-07 13:07: MLPB.blocks.0.linear.bias torch.Size([64]) True
2025-04-07 13:07: MLPB.blocks.0.norm.weight torch.Size([64]) True
2025-04-07 13:07: MLPB.blocks.0.norm.bias torch.Size([64]) True
2025-04-07 13:07: MLPC.blocks.0.linear.weight torch.Size([96, 96]) True
2025-04-07 13:07: MLPC.blocks.0.linear.bias torch.Size([96]) True
2025-04-07 13:07: MLPC.blocks.0.norm.weight torch.Size([96]) True
2025-04-07 13:07: MLPC.blocks.0.norm.bias torch.Size([96]) True
2025-04-07 13:07: MLPD.blocks.0.linear.weight torch.Size([128, 128]) True
2025-04-07 13:07: MLPD.blocks.0.linear.bias torch.Size([128]) True
2025-04-07 13:07: MLPD.blocks.0.norm.weight torch.Size([128]) True
2025-04-07 13:07: MLPD.blocks.0.norm.bias torch.Size([128]) True
2025-04-07 13:07: MLPE.blocks.0.linear.weight torch.Size([224, 224]) True
2025-04-07 13:07: MLPE.blocks.0.linear.bias torch.Size([224]) True
2025-04-07 13:07: MLPE.blocks.0.norm.weight torch.Size([224]) True
2025-04-07 13:07: MLPE.blocks.0.norm.bias torch.Size([224]) True
2025-04-07 13:07: MLPE.blocks.1.linear.weight torch.Size([224, 224]) True
2025-04-07 13:07: MLPE.blocks.1.linear.bias torch.Size([224]) True
2025-04-07 13:07: MLPE.blocks.1.norm.weight torch.Size([224]) True
2025-04-07 13:07: MLPE.blocks.1.norm.bias torch.Size([224]) True
2025-04-07 13:07: MLPE.blocks.2.linear.weight torch.Size([224, 224]) True
2025-04-07 13:07: MLPE.blocks.2.linear.bias torch.Size([224]) True
2025-04-07 13:07: MLPE.blocks.2.norm.weight torch.Size([224]) True
2025-04-07 13:07: MLPE.blocks.2.norm.bias torch.Size([224]) True
2025-04-07 13:07: MLPF.blocks.0.linear.weight torch.Size([12, 12]) True
2025-04-07 13:07: MLPF.blocks.0.linear.bias torch.Size([12]) True
2025-04-07 13:07: MLPF.blocks.0.norm.weight torch.Size([12]) True
2025-04-07 13:07: MLPF.blocks.0.norm.bias torch.Size([12]) True
2025-04-07 13:07: MLPF.blocks.1.linear.weight torch.Size([12, 12]) True
2025-04-07 13:07: MLPF.blocks.1.linear.bias torch.Size([12]) True
2025-04-07 13:07: MLPF.blocks.1.norm.weight torch.Size([12]) True
2025-04-07 13:07: MLPF.blocks.1.norm.bias torch.Size([12]) True
2025-04-07 13:07: steps_linear.weight torch.Size([9, 12]) True
2025-04-07 13:07: steps_linear.bias torch.Size([9]) True
2025-04-07 13:07: out_linear.weight torch.Size([1, 224]) True
2025-04-07 13:07: out_linear.bias torch.Size([1]) True
2025-04-07 13:07: Total params num: 217470
2025-04-07 13:07: *****************Finish Parameter****************
2025-04-07 13:07: Train Epoch 1: 0/159 Loss: 50.851963
2025-04-07 13:07: Train Epoch 1: 20/159 Loss: 10.636330
2025-04-07 13:07: Train Epoch 1: 40/159 Loss: 7.116090
2025-04-07 13:07: Train Epoch 1: 60/159 Loss: 7.120691
2025-04-07 13:07: Train Epoch 1: 80/159 Loss: 6.034465
2025-04-07 13:07: Train Epoch 1: 100/159 Loss: 6.012995
2025-04-07 13:07: Train Epoch 1: 120/159 Loss: 4.815584
2025-04-07 13:07: Train Epoch 1: 140/159 Loss: 4.965208
2025-04-07 13:07: **********Train Epoch 1: Average Loss: 7.699837
2025-04-07 13:07: **********Train Epoch 1: MAE: 7.699837 RMSE: 10.723104 MAPE: 0.119517
2025-04-07 13:07: **********Val Epoch 1: Average Loss: 3.306232
2025-04-07 13:07: **********Val Epoch 1: MAE: 3.306232 RMSE: 6.262990 MAPE: 0.056172
2025-04-07 13:07: *********************************Current best model saved!
2025-04-07 13:07: Train Epoch 1: 0/159 Loss: 4.663684
2025-04-07 13:07: Train Epoch 1: 20/159 Loss: 4.471715
2025-04-07 13:07: Train Epoch 1: 40/159 Loss: 4.073159
2025-04-07 13:07: Train Epoch 1: 60/159 Loss: 4.233804
2025-04-07 13:07: Train Epoch 1: 80/159 Loss: 3.438292
2025-04-07 13:07: Train Epoch 1: 100/159 Loss: 3.672865
2025-04-07 13:07: Train Epoch 1: 120/159 Loss: 4.014753
2025-04-07 13:07: Train Epoch 1: 140/159 Loss: 3.380596
2025-04-07 13:07: **********Train Epoch 1: Average Loss: 3.955612
2025-04-07 13:07: **********Train Epoch 1: MAE: 3.955612 RMSE: 6.412940 MAPE: 0.065684
2025-04-07 13:08: **********Val Epoch 1: Average Loss: 2.361255
2025-04-07 13:08: **********Val Epoch 1: MAE: 2.361255 RMSE: 4.883298 MAPE: 0.041738
2025-04-07 13:08: *********************************Current best model saved!
2025-04-07 13:08: Total training time: 0.9539min, best loss: 2.361255
2025-04-07 13:08: Experiment log path in: /data/zm/2025code/log/in12_out9
2025-04-07 13:08: Train: (10183, 12, 39, 3), (10183, 9, 39, 3)
2025-04-07 13:08: Val: (3394, 12, 39, 3), (3394, 9, 39, 3)
2025-04-07 13:08: Test: (3395, 12, 39, 3), (3395, 9, 39, 3)
2025-04-07 13:08: memory_usage: (0.837890625, 2.0)
2025-04-07 13:08: Applying learning rate decay.
2025-04-07 13:08: *****************Model Parameter*****************
2025-04-07 13:08: data_l torch.Size([96]) True
2025-04-07 13:08: tod_embedding.weight torch.Size([288, 32]) True
2025-04-07 13:08: dow_embedding.weight torch.Size([7, 32]) True
2025-04-07 13:08: SpatialEmbedding.B_sp torch.Size([307, 32]) True
2025-04-07 13:08: SpatialEmbedding.B_su torch.Size([307, 32]) True
2025-04-07 13:08: data_embedding.weight torch.Size([96, 1]) True
2025-04-07 13:08: data_embedding.bias torch.Size([96]) True
2025-04-07 13:08: MLPA.blocks.0.linear.weight torch.Size([64, 64]) True
2025-04-07 13:08: MLPA.blocks.0.linear.bias torch.Size([64]) True
2025-04-07 13:08: MLPA.blocks.0.norm.weight torch.Size([64]) True
2025-04-07 13:08: MLPA.blocks.0.norm.bias torch.Size([64]) True
2025-04-07 13:08: MLPB.blocks.0.linear.weight torch.Size([64, 64]) True
2025-04-07 13:08: MLPB.blocks.0.linear.bias torch.Size([64]) True
2025-04-07 13:08: MLPB.blocks.0.norm.weight torch.Size([64]) True
2025-04-07 13:08: MLPB.blocks.0.norm.bias torch.Size([64]) True
2025-04-07 13:08: MLPC.blocks.0.linear.weight torch.Size([96, 96]) True
2025-04-07 13:08: MLPC.blocks.0.linear.bias torch.Size([96]) True
2025-04-07 13:08: MLPC.blocks.0.norm.weight torch.Size([96]) True
2025-04-07 13:08: MLPC.blocks.0.norm.bias torch.Size([96]) True
2025-04-07 13:08: MLPD.blocks.0.linear.weight torch.Size([128, 128]) True
2025-04-07 13:08: MLPD.blocks.0.linear.bias torch.Size([128]) True
2025-04-07 13:08: MLPD.blocks.0.norm.weight torch.Size([128]) True
2025-04-07 13:08: MLPD.blocks.0.norm.bias torch.Size([128]) True
2025-04-07 13:08: MLPE.blocks.0.linear.weight torch.Size([224, 224]) True
2025-04-07 13:08: MLPE.blocks.0.linear.bias torch.Size([224]) True
2025-04-07 13:08: MLPE.blocks.0.norm.weight torch.Size([224]) True
2025-04-07 13:08: MLPE.blocks.0.norm.bias torch.Size([224]) True
2025-04-07 13:08: MLPE.blocks.1.linear.weight torch.Size([224, 224]) True
2025-04-07 13:08: MLPE.blocks.1.linear.bias torch.Size([224]) True
2025-04-07 13:08: MLPE.blocks.1.norm.weight torch.Size([224]) True
2025-04-07 13:08: MLPE.blocks.1.norm.bias torch.Size([224]) True
2025-04-07 13:08: MLPE.blocks.2.linear.weight torch.Size([224, 224]) True
2025-04-07 13:08: MLPE.blocks.2.linear.bias torch.Size([224]) True
2025-04-07 13:08: MLPE.blocks.2.norm.weight torch.Size([224]) True
2025-04-07 13:08: MLPE.blocks.2.norm.bias torch.Size([224]) True
2025-04-07 13:08: MLPF.blocks.0.linear.weight torch.Size([12, 12]) True
2025-04-07 13:08: MLPF.blocks.0.linear.bias torch.Size([12]) True
2025-04-07 13:08: MLPF.blocks.0.norm.weight torch.Size([12]) True
2025-04-07 13:08: MLPF.blocks.0.norm.bias torch.Size([12]) True
2025-04-07 13:08: MLPF.blocks.1.linear.weight torch.Size([12, 12]) True
2025-04-07 13:08: MLPF.blocks.1.linear.bias torch.Size([12]) True
2025-04-07 13:08: MLPF.blocks.1.norm.weight torch.Size([12]) True
2025-04-07 13:08: MLPF.blocks.1.norm.bias torch.Size([12]) True
2025-04-07 13:08: steps_linear.weight torch.Size([9, 12]) True
2025-04-07 13:08: steps_linear.bias torch.Size([9]) True
2025-04-07 13:08: out_linear.weight torch.Size([1, 224]) True
2025-04-07 13:08: out_linear.bias torch.Size([1]) True
2025-04-07 13:08: Total params num: 217470
2025-04-07 13:08: *****************Finish Parameter****************
2025-04-07 13:08: Train Epoch 1: 0/159 Loss: 50.851963
2025-04-07 13:08: Train Epoch 1: 20/159 Loss: 10.636330
2025-04-07 13:08: Train Epoch 1: 40/159 Loss: 7.116090
2025-04-07 13:08: Train Epoch 1: 60/159 Loss: 7.120691
2025-04-07 13:08: Train Epoch 1: 80/159 Loss: 6.034465
2025-04-07 13:08: Train Epoch 1: 100/159 Loss: 6.012995
2025-04-07 13:08: Train Epoch 1: 120/159 Loss: 4.815584
2025-04-07 13:08: Train Epoch 1: 140/159 Loss: 4.965208
2025-04-07 13:08: **********Train Epoch 1: Average Loss: 7.699837
2025-04-07 13:08: **********Train Epoch 1: MAE: 7.699837 RMSE: 10.723104 MAPE: 0.119517
2025-04-07 13:08: **********Val Epoch 1: Average Loss: 3.306232
2025-04-07 13:08: **********Val Epoch 1: MAE: 3.306232 RMSE: 6.262990 MAPE: 0.056172
2025-04-07 13:08: *********************************Current best model saved!
2025-04-07 13:08: Train Epoch 1: 0/159 Loss: 4.663684
2025-04-07 13:08: Train Epoch 1: 20/159 Loss: 4.471715
2025-04-07 13:09: Train Epoch 1: 40/159 Loss: 4.073159
2025-04-07 13:09: Train Epoch 1: 60/159 Loss: 4.233804
2025-04-07 13:09: Train Epoch 1: 80/159 Loss: 3.438292
2025-04-07 13:09: Train Epoch 1: 100/159 Loss: 3.672865
2025-04-07 13:09: Train Epoch 1: 120/159 Loss: 4.014753
2025-04-07 13:09: Train Epoch 1: 140/159 Loss: 3.380596
2025-04-07 13:09: **********Train Epoch 1: Average Loss: 3.955612
2025-04-07 13:09: **********Train Epoch 1: MAE: 3.955612 RMSE: 6.412940 MAPE: 0.065684
2025-04-07 13:09: **********Val Epoch 1: Average Loss: 2.361255
2025-04-07 13:09: **********Val Epoch 1: MAE: 2.361255 RMSE: 4.883298 MAPE: 0.041738
2025-04-07 13:09: *********************************Current best model saved!
2025-04-07 13:09: Total training time: 0.9500min, best loss: 2.361255
2025-04-07 13:09: Saving current best model to ./checkpoints/PeMSD4SPEED_12_9_8.pth
2025-04-07 13:09: Horizon 01, MAE: 1.7905, RMSE: 3.6842, MAPE: 3.8183%
2025-04-07 13:09: Horizon 02, MAE: 2.0973, RMSE: 3.8689, MAPE: 4.2500%
2025-04-07 13:09: Horizon 03, MAE: 2.7009, RMSE: 5.3782, MAPE: 5.8223%
2025-04-07 13:09: Horizon 04, MAE: 2.6506, RMSE: 5.4002, MAPE: 5.7231%
2025-04-07 13:09: Horizon 05, MAE: 2.4161, RMSE: 4.7161, MAPE: 5.0871%
2025-04-07 13:09: Horizon 06, MAE: 2.0827, RMSE: 4.5684, MAPE: 4.5680%
2025-04-07 13:09: Horizon 07, MAE: 2.1303, RMSE: 4.6631, MAPE: 4.6662%
2025-04-07 13:09: Horizon 08, MAE: 2.4189, RMSE: 4.7728, MAPE: 5.0308%
2025-04-07 13:09: Horizon 09, MAE: 2.6398, RMSE: 5.7220, MAPE: 5.8241%
2025-04-07 13:09: Average Horizon, MAE: 2.3252, RMSE: 4.7959, MAPE: 4.9766%
