2025-04-07 12:47: Experiment log path in: /data/zm/2025code/log/in12_out9
2025-04-07 12:47: Train: (10183, 12, 39, 3), (10183, 9, 39, 3)
2025-04-07 12:47: Val: (3394, 12, 39, 3), (3394, 9, 39, 3)
2025-04-07 12:47: Test: (3395, 12, 39, 3), (3395, 9, 39, 3)
2025-04-07 12:47: memory_usage: (0.837890625, 2.0)
2025-04-07 12:47: Applying learning rate decay.
2025-04-07 12:47: *****************Model Parameter*****************
2025-04-07 12:47: data_l torch.Size([96]) True
2025-04-07 12:47: tod_embedding.weight torch.Size([288, 32]) True
2025-04-07 12:47: dow_embedding.weight torch.Size([7, 32]) True
2025-04-07 12:47: SpatialEmbedding.B_sp torch.Size([307, 32]) True
2025-04-07 12:47: SpatialEmbedding.B_su torch.Size([307, 32]) True
2025-04-07 12:47: data_embedding.weight torch.Size([96, 1]) True
2025-04-07 12:47: data_embedding.bias torch.Size([96]) True
2025-04-07 12:47: MLPA.blocks.0.linear.weight torch.Size([64, 64]) True
2025-04-07 12:47: MLPA.blocks.0.linear.bias torch.Size([64]) True
2025-04-07 12:47: MLPA.blocks.0.norm.weight torch.Size([64]) True
2025-04-07 12:47: MLPA.blocks.0.norm.bias torch.Size([64]) True
2025-04-07 12:47: MLPB.blocks.0.linear.weight torch.Size([64, 64]) True
2025-04-07 12:47: MLPB.blocks.0.linear.bias torch.Size([64]) True
2025-04-07 12:47: MLPB.blocks.0.norm.weight torch.Size([64]) True
2025-04-07 12:47: MLPB.blocks.0.norm.bias torch.Size([64]) True
2025-04-07 12:47: MLPC.blocks.0.linear.weight torch.Size([96, 96]) True
2025-04-07 12:47: MLPC.blocks.0.linear.bias torch.Size([96]) True
2025-04-07 12:47: MLPC.blocks.0.norm.weight torch.Size([96]) True
2025-04-07 12:47: MLPC.blocks.0.norm.bias torch.Size([96]) True
2025-04-07 12:47: MLPD.blocks.0.linear.weight torch.Size([128, 128]) True
2025-04-07 12:47: MLPD.blocks.0.linear.bias torch.Size([128]) True
2025-04-07 12:47: MLPD.blocks.0.norm.weight torch.Size([128]) True
2025-04-07 12:47: MLPD.blocks.0.norm.bias torch.Size([128]) True
2025-04-07 12:47: MLPE.blocks.0.linear.weight torch.Size([224, 224]) True
2025-04-07 12:47: MLPE.blocks.0.linear.bias torch.Size([224]) True
2025-04-07 12:47: MLPE.blocks.0.norm.weight torch.Size([224]) True
2025-04-07 12:47: MLPE.blocks.0.norm.bias torch.Size([224]) True
2025-04-07 12:47: MLPE.blocks.1.linear.weight torch.Size([224, 224]) True
2025-04-07 12:47: MLPE.blocks.1.linear.bias torch.Size([224]) True
2025-04-07 12:47: MLPE.blocks.1.norm.weight torch.Size([224]) True
2025-04-07 12:47: MLPE.blocks.1.norm.bias torch.Size([224]) True
2025-04-07 12:47: MLPE.blocks.2.linear.weight torch.Size([224, 224]) True
2025-04-07 12:47: MLPE.blocks.2.linear.bias torch.Size([224]) True
2025-04-07 12:47: MLPE.blocks.2.norm.weight torch.Size([224]) True
2025-04-07 12:47: MLPE.blocks.2.norm.bias torch.Size([224]) True
2025-04-07 12:47: MLPF.blocks.0.linear.weight torch.Size([12, 12]) True
2025-04-07 12:47: MLPF.blocks.0.linear.bias torch.Size([12]) True
2025-04-07 12:47: MLPF.blocks.0.norm.weight torch.Size([12]) True
2025-04-07 12:47: MLPF.blocks.0.norm.bias torch.Size([12]) True
2025-04-07 12:47: MLPF.blocks.1.linear.weight torch.Size([12, 12]) True
2025-04-07 12:47: MLPF.blocks.1.linear.bias torch.Size([12]) True
2025-04-07 12:47: MLPF.blocks.1.norm.weight torch.Size([12]) True
2025-04-07 12:47: MLPF.blocks.1.norm.bias torch.Size([12]) True
2025-04-07 12:47: steps_linear.weight torch.Size([9, 12]) True
2025-04-07 12:47: steps_linear.bias torch.Size([9]) True
2025-04-07 12:47: out_linear.weight torch.Size([1, 224]) True
2025-04-07 12:47: out_linear.bias torch.Size([1]) True
2025-04-07 12:47: Total params num: 217470
2025-04-07 12:47: *****************Finish Parameter****************
2025-04-07 12:47: Train Epoch 1: 0/159 Loss: 50.851963
2025-04-07 12:47: Train Epoch 1: 20/159 Loss: 10.636330
2025-04-07 12:47: Train Epoch 1: 40/159 Loss: 7.116090
2025-04-07 12:47: Train Epoch 1: 60/159 Loss: 7.120691
2025-04-07 12:48: Train Epoch 1: 80/159 Loss: 6.034465
2025-04-07 12:48: Train Epoch 1: 100/159 Loss: 6.012995
2025-04-07 12:48: Train Epoch 1: 120/159 Loss: 4.815584
2025-04-07 12:48: Train Epoch 1: 140/159 Loss: 4.965208
2025-04-07 12:48: **********Train Epoch 1: Average Loss: 7.699837
2025-04-07 12:48: **********Train Epoch 1: MAE: 7.699837 RMSE: 10.723104 MAPE: 0.119517
2025-04-07 12:48: **********Val Epoch 1: Average Loss: 3.306232
2025-04-07 12:48: **********Val Epoch 1: MAE: 3.306232 RMSE: 6.262990 MAPE: 0.056172
2025-04-07 12:48: *********************************Current best model saved!
2025-04-07 12:48: Train Epoch 1: 0/159 Loss: 4.663684
2025-04-07 12:48: Train Epoch 1: 20/159 Loss: 4.471715
2025-04-07 12:48: Train Epoch 1: 40/159 Loss: 4.073159
2025-04-07 12:48: Train Epoch 1: 60/159 Loss: 4.233804
2025-04-07 12:48: Train Epoch 1: 80/159 Loss: 3.438292
2025-04-07 12:48: Train Epoch 1: 100/159 Loss: 3.672865
2025-04-07 12:48: Train Epoch 1: 120/159 Loss: 4.014753
2025-04-07 12:48: Train Epoch 1: 140/159 Loss: 3.380596
2025-04-07 12:49: **********Train Epoch 1: Average Loss: 3.955612
2025-04-07 12:49: **********Train Epoch 1: MAE: 3.955612 RMSE: 6.412940 MAPE: 0.065684
2025-04-07 12:49: **********Val Epoch 1: Average Loss: 2.361255
2025-04-07 12:49: **********Val Epoch 1: MAE: 2.361255 RMSE: 4.883298 MAPE: 0.041738
2025-04-07 12:49: *********************************Current best model saved!
2025-04-07 12:49: Train Epoch 2: 0/159 Loss: 3.709680
2025-04-07 12:49: Train Epoch 2: 20/159 Loss: 3.235257
2025-04-07 12:49: Train Epoch 2: 40/159 Loss: 2.623609
2025-04-07 12:49: Train Epoch 2: 60/159 Loss: 2.715194
2025-04-07 12:49: Train Epoch 2: 80/159 Loss: 2.479214
2025-04-07 12:49: Train Epoch 2: 100/159 Loss: 2.300442
2025-04-07 12:49: Train Epoch 2: 120/159 Loss: 2.341323
2025-04-07 12:49: Train Epoch 2: 140/159 Loss: 2.260521
2025-04-07 12:49: **********Train Epoch 2: Average Loss: 2.659860
2025-04-07 12:49: **********Train Epoch 2: MAE: 2.659860 RMSE: 4.641821 MAPE: 0.045907
2025-04-07 12:49: **********Val Epoch 2: Average Loss: 1.720296
2025-04-07 12:49: **********Val Epoch 2: MAE: 1.720296 RMSE: 3.658062 MAPE: 0.031353
2025-04-07 12:49: *********************************Current best model saved!
2025-04-07 12:49: Train Epoch 2: 0/159 Loss: 2.110824
2025-04-07 12:49: Train Epoch 2: 20/159 Loss: 2.141644
2025-04-07 12:49: Train Epoch 2: 40/159 Loss: 2.023602
2025-04-07 12:50: Train Epoch 2: 60/159 Loss: 1.969519
2025-04-07 12:50: Train Epoch 2: 80/159 Loss: 1.787935
2025-04-07 12:50: Train Epoch 2: 100/159 Loss: 1.765182
2025-04-07 12:50: Train Epoch 2: 120/159 Loss: 1.577756
2025-04-07 12:50: Train Epoch 2: 140/159 Loss: 1.788358
2025-04-07 12:50: **********Train Epoch 2: Average Loss: 1.911616
2025-04-07 12:50: **********Train Epoch 2: MAE: 1.911616 RMSE: 3.669487 MAPE: 0.033985
2025-04-07 12:50: **********Val Epoch 2: Average Loss: 1.540054
2025-04-07 12:50: **********Val Epoch 2: MAE: 1.540054 RMSE: 3.305513 MAPE: 0.028122
2025-04-07 12:50: *********************************Current best model saved!
2025-04-07 12:50: Train Epoch 3: 0/159 Loss: 1.944221
2025-04-07 12:50: Train Epoch 3: 20/159 Loss: 2.334334
2025-04-07 12:50: Train Epoch 3: 40/159 Loss: 1.795314
2025-04-07 12:50: Train Epoch 3: 60/159 Loss: 1.706413
2025-04-07 12:50: Train Epoch 3: 80/159 Loss: 1.744141
2025-04-07 12:50: Train Epoch 3: 100/159 Loss: 1.666123
2025-04-07 12:50: Train Epoch 3: 120/159 Loss: 1.487990
2025-04-07 12:51: Train Epoch 3: 140/159 Loss: 1.546306
2025-04-07 12:51: **********Train Epoch 3: Average Loss: 1.907918
2025-04-07 12:51: **********Train Epoch 3: MAE: 1.907918 RMSE: 3.584652 MAPE: 0.033741
2025-04-07 12:51: **********Val Epoch 3: Average Loss: 1.483923
2025-04-07 12:51: **********Val Epoch 3: MAE: 1.483923 RMSE: 3.231988 MAPE: 0.027118
2025-04-07 12:51: *********************************Current best model saved!
2025-04-07 12:51: Train Epoch 3: 0/159 Loss: 1.550710
2025-04-07 12:51: Train Epoch 3: 20/159 Loss: 1.781254
2025-04-07 12:51: Train Epoch 3: 40/159 Loss: 1.668504
2025-04-07 12:51: Train Epoch 3: 60/159 Loss: 1.530858
2025-04-07 12:51: Train Epoch 3: 80/159 Loss: 1.380642
2025-04-07 12:51: Train Epoch 3: 100/159 Loss: 1.592028
2025-04-07 12:51: Train Epoch 3: 120/159 Loss: 1.633668
