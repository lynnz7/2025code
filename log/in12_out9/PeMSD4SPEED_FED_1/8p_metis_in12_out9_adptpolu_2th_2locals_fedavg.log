2025-04-07 12:47: Experiment log path in: /data/zm/2025code/log/in12_out9
2025-04-07 12:47: Train: (10183, 12, 38, 3), (10183, 9, 38, 3)
2025-04-07 12:47: Val: (3394, 12, 38, 3), (3394, 9, 38, 3)
2025-04-07 12:47: Test: (3395, 12, 38, 3), (3395, 9, 38, 3)
2025-04-07 12:47: memory_usage: (0.837890625, 2.0)
2025-04-07 12:47: Applying learning rate decay.
2025-04-07 12:47: *****************Model Parameter*****************
2025-04-07 12:47: data_l torch.Size([96]) True
2025-04-07 12:47: tod_embedding.weight torch.Size([288, 32]) True
2025-04-07 12:47: dow_embedding.weight torch.Size([7, 32]) True
2025-04-07 12:47: SpatialEmbedding.B_sp torch.Size([307, 32]) True
2025-04-07 12:47: SpatialEmbedding.B_su torch.Size([307, 32]) True
2025-04-07 12:47: data_embedding.weight torch.Size([96, 1]) True
2025-04-07 12:47: data_embedding.bias torch.Size([96]) True
2025-04-07 12:47: MLPA.blocks.0.linear.weight torch.Size([64, 64]) True
2025-04-07 12:47: MLPA.blocks.0.linear.bias torch.Size([64]) True
2025-04-07 12:47: MLPA.blocks.0.norm.weight torch.Size([64]) True
2025-04-07 12:47: MLPA.blocks.0.norm.bias torch.Size([64]) True
2025-04-07 12:47: MLPB.blocks.0.linear.weight torch.Size([64, 64]) True
2025-04-07 12:47: MLPB.blocks.0.linear.bias torch.Size([64]) True
2025-04-07 12:47: MLPB.blocks.0.norm.weight torch.Size([64]) True
2025-04-07 12:47: MLPB.blocks.0.norm.bias torch.Size([64]) True
2025-04-07 12:47: MLPC.blocks.0.linear.weight torch.Size([96, 96]) True
2025-04-07 12:47: MLPC.blocks.0.linear.bias torch.Size([96]) True
2025-04-07 12:47: MLPC.blocks.0.norm.weight torch.Size([96]) True
2025-04-07 12:47: MLPC.blocks.0.norm.bias torch.Size([96]) True
2025-04-07 12:47: MLPD.blocks.0.linear.weight torch.Size([128, 128]) True
2025-04-07 12:47: MLPD.blocks.0.linear.bias torch.Size([128]) True
2025-04-07 12:47: MLPD.blocks.0.norm.weight torch.Size([128]) True
2025-04-07 12:47: MLPD.blocks.0.norm.bias torch.Size([128]) True
2025-04-07 12:47: MLPE.blocks.0.linear.weight torch.Size([224, 224]) True
2025-04-07 12:47: MLPE.blocks.0.linear.bias torch.Size([224]) True
2025-04-07 12:47: MLPE.blocks.0.norm.weight torch.Size([224]) True
2025-04-07 12:47: MLPE.blocks.0.norm.bias torch.Size([224]) True
2025-04-07 12:47: MLPE.blocks.1.linear.weight torch.Size([224, 224]) True
2025-04-07 12:47: MLPE.blocks.1.linear.bias torch.Size([224]) True
2025-04-07 12:47: MLPE.blocks.1.norm.weight torch.Size([224]) True
2025-04-07 12:47: MLPE.blocks.1.norm.bias torch.Size([224]) True
2025-04-07 12:47: MLPE.blocks.2.linear.weight torch.Size([224, 224]) True
2025-04-07 12:47: MLPE.blocks.2.linear.bias torch.Size([224]) True
2025-04-07 12:47: MLPE.blocks.2.norm.weight torch.Size([224]) True
2025-04-07 12:47: MLPE.blocks.2.norm.bias torch.Size([224]) True
2025-04-07 12:47: MLPF.blocks.0.linear.weight torch.Size([12, 12]) True
2025-04-07 12:47: MLPF.blocks.0.linear.bias torch.Size([12]) True
2025-04-07 12:47: MLPF.blocks.0.norm.weight torch.Size([12]) True
2025-04-07 12:47: MLPF.blocks.0.norm.bias torch.Size([12]) True
2025-04-07 12:47: MLPF.blocks.1.linear.weight torch.Size([12, 12]) True
2025-04-07 12:47: MLPF.blocks.1.linear.bias torch.Size([12]) True
2025-04-07 12:47: MLPF.blocks.1.norm.weight torch.Size([12]) True
2025-04-07 12:47: MLPF.blocks.1.norm.bias torch.Size([12]) True
2025-04-07 12:47: steps_linear.weight torch.Size([9, 12]) True
2025-04-07 12:47: steps_linear.bias torch.Size([9]) True
2025-04-07 12:47: out_linear.weight torch.Size([1, 224]) True
2025-04-07 12:47: out_linear.bias torch.Size([1]) True
2025-04-07 12:47: Total params num: 217470
2025-04-07 12:47: *****************Finish Parameter****************
2025-04-07 12:47: Train Epoch 1: 0/159 Loss: 64.058052
2025-04-07 12:47: Train Epoch 1: 20/159 Loss: 13.168799
2025-04-07 12:47: Train Epoch 1: 40/159 Loss: 9.175293
2025-04-07 12:47: Train Epoch 1: 60/159 Loss: 8.762853
2025-04-07 12:48: Train Epoch 1: 80/159 Loss: 7.858680
2025-04-07 12:48: Train Epoch 1: 100/159 Loss: 7.829686
2025-04-07 12:48: Train Epoch 1: 120/159 Loss: 6.320625
2025-04-07 12:48: Train Epoch 1: 140/159 Loss: 6.386195
2025-04-07 12:48: **********Train Epoch 1: Average Loss: 9.787600
2025-04-07 12:48: **********Train Epoch 1: MAE: 9.787600 RMSE: 13.498837 MAPE: 0.153747
2025-04-07 12:48: **********Val Epoch 1: Average Loss: 4.228376
2025-04-07 12:48: **********Val Epoch 1: MAE: 4.228376 RMSE: 7.768887 MAPE: 0.074786
2025-04-07 12:48: *********************************Current best model saved!
2025-04-07 12:48: Train Epoch 1: 0/159 Loss: 5.984984
2025-04-07 12:48: Train Epoch 1: 20/159 Loss: 5.887138
2025-04-07 12:48: Train Epoch 1: 40/159 Loss: 5.171935
2025-04-07 12:48: Train Epoch 1: 60/159 Loss: 5.264238
2025-04-07 12:48: Train Epoch 1: 80/159 Loss: 4.614097
2025-04-07 12:48: Train Epoch 1: 100/159 Loss: 4.738791
2025-04-07 12:48: Train Epoch 1: 120/159 Loss: 5.262351
2025-04-07 12:48: Train Epoch 1: 140/159 Loss: 4.692492
2025-04-07 12:48: **********Train Epoch 1: Average Loss: 5.190732
2025-04-07 12:48: **********Train Epoch 1: MAE: 5.190732 RMSE: 8.166367 MAPE: 0.089095
2025-04-07 12:49: **********Val Epoch 1: Average Loss: 3.259562
2025-04-07 12:49: **********Val Epoch 1: MAE: 3.259562 RMSE: 6.254460 MAPE: 0.059965
2025-04-07 12:49: *********************************Current best model saved!
2025-04-07 12:49: Train Epoch 2: 0/159 Loss: 4.667183
2025-04-07 12:49: Train Epoch 2: 20/159 Loss: 4.117748
2025-04-07 12:49: Train Epoch 2: 40/159 Loss: 3.612458
2025-04-07 12:49: Train Epoch 2: 60/159 Loss: 3.511184
2025-04-07 12:49: Train Epoch 2: 80/159 Loss: 3.360861
2025-04-07 12:49: Train Epoch 2: 100/159 Loss: 3.362020
2025-04-07 12:49: Train Epoch 2: 120/159 Loss: 3.063937
2025-04-07 12:49: Train Epoch 2: 140/159 Loss: 2.986717
2025-04-07 12:49: **********Train Epoch 2: Average Loss: 3.572870
2025-04-07 12:49: **********Train Epoch 2: MAE: 3.572870 RMSE: 5.799034 MAPE: 0.063991
2025-04-07 12:49: **********Val Epoch 2: Average Loss: 2.318216
2025-04-07 12:49: **********Val Epoch 2: MAE: 2.318216 RMSE: 4.442794 MAPE: 0.043487
2025-04-07 12:49: *********************************Current best model saved!
2025-04-07 12:49: Train Epoch 2: 0/159 Loss: 2.919285
2025-04-07 12:49: Train Epoch 2: 20/159 Loss: 2.815012
2025-04-07 12:49: Train Epoch 2: 40/159 Loss: 2.683972
2025-04-07 12:50: Train Epoch 2: 60/159 Loss: 2.465767
2025-04-07 12:50: Train Epoch 2: 80/159 Loss: 2.401991
2025-04-07 12:50: Train Epoch 2: 100/159 Loss: 2.424617
2025-04-07 12:50: Train Epoch 2: 120/159 Loss: 2.095393
2025-04-07 12:50: Train Epoch 2: 140/159 Loss: 2.480287
2025-04-07 12:50: **********Train Epoch 2: Average Loss: 2.544494
2025-04-07 12:50: **********Train Epoch 2: MAE: 2.544494 RMSE: 4.466056 MAPE: 0.046660
2025-04-07 12:50: **********Val Epoch 2: Average Loss: 2.058025
2025-04-07 12:50: **********Val Epoch 2: MAE: 2.058025 RMSE: 4.047446 MAPE: 0.038221
2025-04-07 12:50: *********************************Current best model saved!
2025-04-07 12:50: Train Epoch 3: 0/159 Loss: 2.676149
2025-04-07 12:50: Train Epoch 3: 20/159 Loss: 3.137313
2025-04-07 12:50: Train Epoch 3: 40/159 Loss: 2.327711
2025-04-07 12:50: Train Epoch 3: 60/159 Loss: 2.386823
2025-04-07 12:50: Train Epoch 3: 80/159 Loss: 2.347530
2025-04-07 12:50: Train Epoch 3: 100/159 Loss: 2.247017
2025-04-07 12:50: Train Epoch 3: 120/159 Loss: 2.029722
2025-04-07 12:51: Train Epoch 3: 140/159 Loss: 2.102675
2025-04-07 12:51: **********Train Epoch 3: Average Loss: 2.541648
2025-04-07 12:51: **********Train Epoch 3: MAE: 2.541648 RMSE: 4.404427 MAPE: 0.046347
2025-04-07 12:51: **********Val Epoch 3: Average Loss: 2.006882
2025-04-07 12:51: **********Val Epoch 3: MAE: 2.006882 RMSE: 3.996379 MAPE: 0.037249
2025-04-07 12:51: *********************************Current best model saved!
2025-04-07 12:51: Train Epoch 3: 0/159 Loss: 2.146543
2025-04-07 12:51: Train Epoch 3: 20/159 Loss: 2.381362
2025-04-07 12:51: Train Epoch 3: 40/159 Loss: 2.144498
2025-04-07 12:51: Train Epoch 3: 60/159 Loss: 2.058693
2025-04-07 12:51: Train Epoch 3: 80/159 Loss: 1.967059
2025-04-07 12:51: Train Epoch 3: 100/159 Loss: 2.119944
2025-04-07 12:51: Train Epoch 3: 120/159 Loss: 2.150771
