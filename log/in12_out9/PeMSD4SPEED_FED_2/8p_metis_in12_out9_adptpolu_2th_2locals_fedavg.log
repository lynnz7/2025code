2025-04-07 12:47: Experiment log path in: /data/zm/2025code/log/in12_out9
2025-04-07 12:47: Train: (10183, 12, 39, 3), (10183, 9, 39, 3)
2025-04-07 12:47: Val: (3394, 12, 39, 3), (3394, 9, 39, 3)
2025-04-07 12:47: Test: (3395, 12, 39, 3), (3395, 9, 39, 3)
2025-04-07 12:47: memory_usage: (0.837890625, 2.0)
2025-04-07 12:47: Applying learning rate decay.
2025-04-07 12:47: *****************Model Parameter*****************
2025-04-07 12:47: data_l torch.Size([96]) True
2025-04-07 12:47: tod_embedding.weight torch.Size([288, 32]) True
2025-04-07 12:47: dow_embedding.weight torch.Size([7, 32]) True
2025-04-07 12:47: SpatialEmbedding.B_sp torch.Size([307, 32]) True
2025-04-07 12:47: SpatialEmbedding.B_su torch.Size([307, 32]) True
2025-04-07 12:47: data_embedding.weight torch.Size([96, 1]) True
2025-04-07 12:47: data_embedding.bias torch.Size([96]) True
2025-04-07 12:47: MLPA.blocks.0.linear.weight torch.Size([64, 64]) True
2025-04-07 12:47: MLPA.blocks.0.linear.bias torch.Size([64]) True
2025-04-07 12:47: MLPA.blocks.0.norm.weight torch.Size([64]) True
2025-04-07 12:47: MLPA.blocks.0.norm.bias torch.Size([64]) True
2025-04-07 12:47: MLPB.blocks.0.linear.weight torch.Size([64, 64]) True
2025-04-07 12:47: MLPB.blocks.0.linear.bias torch.Size([64]) True
2025-04-07 12:47: MLPB.blocks.0.norm.weight torch.Size([64]) True
2025-04-07 12:47: MLPB.blocks.0.norm.bias torch.Size([64]) True
2025-04-07 12:47: MLPC.blocks.0.linear.weight torch.Size([96, 96]) True
2025-04-07 12:47: MLPC.blocks.0.linear.bias torch.Size([96]) True
2025-04-07 12:47: MLPC.blocks.0.norm.weight torch.Size([96]) True
2025-04-07 12:47: MLPC.blocks.0.norm.bias torch.Size([96]) True
2025-04-07 12:47: MLPD.blocks.0.linear.weight torch.Size([128, 128]) True
2025-04-07 12:47: MLPD.blocks.0.linear.bias torch.Size([128]) True
2025-04-07 12:47: MLPD.blocks.0.norm.weight torch.Size([128]) True
2025-04-07 12:47: MLPD.blocks.0.norm.bias torch.Size([128]) True
2025-04-07 12:47: MLPE.blocks.0.linear.weight torch.Size([224, 224]) True
2025-04-07 12:47: MLPE.blocks.0.linear.bias torch.Size([224]) True
2025-04-07 12:47: MLPE.blocks.0.norm.weight torch.Size([224]) True
2025-04-07 12:47: MLPE.blocks.0.norm.bias torch.Size([224]) True
2025-04-07 12:47: MLPE.blocks.1.linear.weight torch.Size([224, 224]) True
2025-04-07 12:47: MLPE.blocks.1.linear.bias torch.Size([224]) True
2025-04-07 12:47: MLPE.blocks.1.norm.weight torch.Size([224]) True
2025-04-07 12:47: MLPE.blocks.1.norm.bias torch.Size([224]) True
2025-04-07 12:47: MLPE.blocks.2.linear.weight torch.Size([224, 224]) True
2025-04-07 12:47: MLPE.blocks.2.linear.bias torch.Size([224]) True
2025-04-07 12:47: MLPE.blocks.2.norm.weight torch.Size([224]) True
2025-04-07 12:47: MLPE.blocks.2.norm.bias torch.Size([224]) True
2025-04-07 12:47: MLPF.blocks.0.linear.weight torch.Size([12, 12]) True
2025-04-07 12:47: MLPF.blocks.0.linear.bias torch.Size([12]) True
2025-04-07 12:47: MLPF.blocks.0.norm.weight torch.Size([12]) True
2025-04-07 12:47: MLPF.blocks.0.norm.bias torch.Size([12]) True
2025-04-07 12:47: MLPF.blocks.1.linear.weight torch.Size([12, 12]) True
2025-04-07 12:47: MLPF.blocks.1.linear.bias torch.Size([12]) True
2025-04-07 12:47: MLPF.blocks.1.norm.weight torch.Size([12]) True
2025-04-07 12:47: MLPF.blocks.1.norm.bias torch.Size([12]) True
2025-04-07 12:47: steps_linear.weight torch.Size([9, 12]) True
2025-04-07 12:47: steps_linear.bias torch.Size([9]) True
2025-04-07 12:47: out_linear.weight torch.Size([1, 224]) True
2025-04-07 12:47: out_linear.bias torch.Size([1]) True
2025-04-07 12:47: Total params num: 217470
2025-04-07 12:47: *****************Finish Parameter****************
2025-04-07 12:47: Train Epoch 1: 0/159 Loss: 75.500458
2025-04-07 12:47: Train Epoch 1: 20/159 Loss: 15.495412
2025-04-07 12:47: Train Epoch 1: 40/159 Loss: 10.554406
2025-04-07 12:47: Train Epoch 1: 60/159 Loss: 10.055817
2025-04-07 12:48: Train Epoch 1: 80/159 Loss: 8.989039
2025-04-07 12:48: Train Epoch 1: 100/159 Loss: 8.802790
2025-04-07 12:48: Train Epoch 1: 120/159 Loss: 7.075926
2025-04-07 12:48: Train Epoch 1: 140/159 Loss: 7.242819
2025-04-07 12:48: **********Train Epoch 1: Average Loss: 11.292009
2025-04-07 12:48: **********Train Epoch 1: MAE: 11.292009 RMSE: 15.656925 MAPE: 0.178814
2025-04-07 12:48: **********Val Epoch 1: Average Loss: 4.664427
2025-04-07 12:48: **********Val Epoch 1: MAE: 4.664427 RMSE: 8.925233 MAPE: 0.086766
2025-04-07 12:48: *********************************Current best model saved!
2025-04-07 12:48: Train Epoch 1: 0/159 Loss: 6.717636
2025-04-07 12:48: Train Epoch 1: 20/159 Loss: 6.806255
2025-04-07 12:48: Train Epoch 1: 40/159 Loss: 5.982345
2025-04-07 12:48: Train Epoch 1: 60/159 Loss: 6.008557
2025-04-07 12:48: Train Epoch 1: 80/159 Loss: 5.100989
2025-04-07 12:48: Train Epoch 1: 100/159 Loss: 5.491214
2025-04-07 12:48: Train Epoch 1: 120/159 Loss: 5.861514
2025-04-07 12:48: Train Epoch 1: 140/159 Loss: 5.038109
2025-04-07 12:49: **********Train Epoch 1: Average Loss: 5.835651
2025-04-07 12:49: **********Train Epoch 1: MAE: 5.835651 RMSE: 9.324039 MAPE: 0.103657
2025-04-07 12:49: **********Val Epoch 1: Average Loss: 3.653518
2025-04-07 12:49: **********Val Epoch 1: MAE: 3.653518 RMSE: 7.263201 MAPE: 0.071278
2025-04-07 12:49: *********************************Current best model saved!
2025-04-07 12:49: Train Epoch 2: 0/159 Loss: 5.511912
2025-04-07 12:49: Train Epoch 2: 20/159 Loss: 5.012875
2025-04-07 12:49: Train Epoch 2: 40/159 Loss: 4.294691
2025-04-07 12:49: Train Epoch 2: 60/159 Loss: 4.117072
2025-04-07 12:49: Train Epoch 2: 80/159 Loss: 3.974290
2025-04-07 12:49: Train Epoch 2: 100/159 Loss: 3.616013
2025-04-07 12:49: Train Epoch 2: 120/159 Loss: 3.454377
2025-04-07 12:49: Train Epoch 2: 140/159 Loss: 3.462279
2025-04-07 12:49: **********Train Epoch 2: Average Loss: 4.099022
2025-04-07 12:49: **********Train Epoch 2: MAE: 4.099022 RMSE: 6.756990 MAPE: 0.076664
2025-04-07 12:49: **********Val Epoch 2: Average Loss: 2.474130
2025-04-07 12:49: **********Val Epoch 2: MAE: 2.474130 RMSE: 5.139594 MAPE: 0.050039
2025-04-07 12:49: *********************************Current best model saved!
2025-04-07 12:49: Train Epoch 2: 0/159 Loss: 3.262849
2025-04-07 12:49: Train Epoch 2: 20/159 Loss: 3.284605
2025-04-07 12:49: Train Epoch 2: 40/159 Loss: 2.967232
2025-04-07 12:50: Train Epoch 2: 60/159 Loss: 2.816471
2025-04-07 12:50: Train Epoch 2: 80/159 Loss: 2.625694
2025-04-07 12:50: Train Epoch 2: 100/159 Loss: 2.579352
2025-04-07 12:50: Train Epoch 2: 120/159 Loss: 2.191868
2025-04-07 12:50: Train Epoch 2: 140/159 Loss: 2.628676
2025-04-07 12:50: **********Train Epoch 2: Average Loss: 2.771976
2025-04-07 12:50: **********Train Epoch 2: MAE: 2.771976 RMSE: 5.095665 MAPE: 0.053793
2025-04-07 12:50: **********Val Epoch 2: Average Loss: 2.229880
2025-04-07 12:50: **********Val Epoch 2: MAE: 2.229880 RMSE: 4.664183 MAPE: 0.044233
2025-04-07 12:50: *********************************Current best model saved!
2025-04-07 12:50: Train Epoch 3: 0/159 Loss: 2.871848
2025-04-07 12:50: Train Epoch 3: 20/159 Loss: 3.627616
2025-04-07 12:50: Train Epoch 3: 40/159 Loss: 2.590578
2025-04-07 12:50: Train Epoch 3: 60/159 Loss: 2.633357
2025-04-07 12:50: Train Epoch 3: 80/159 Loss: 2.427835
2025-04-07 12:50: Train Epoch 3: 100/159 Loss: 2.492526
2025-04-07 12:50: Train Epoch 3: 120/159 Loss: 2.175068
2025-04-07 12:51: Train Epoch 3: 140/159 Loss: 2.241782
2025-04-07 12:51: **********Train Epoch 3: Average Loss: 2.753029
2025-04-07 12:51: **********Train Epoch 3: MAE: 2.753029 RMSE: 5.003882 MAPE: 0.053082
2025-04-07 12:51: **********Val Epoch 3: Average Loss: 2.087650
2025-04-07 12:51: **********Val Epoch 3: MAE: 2.087650 RMSE: 4.606340 MAPE: 0.041920
2025-04-07 12:51: *********************************Current best model saved!
2025-04-07 12:51: Train Epoch 3: 0/159 Loss: 2.231489
2025-04-07 12:51: Train Epoch 3: 20/159 Loss: 2.347952
2025-04-07 12:51: Train Epoch 3: 40/159 Loss: 2.451019
2025-04-07 12:51: Train Epoch 3: 60/159 Loss: 2.104798
2025-04-07 12:51: Train Epoch 3: 80/159 Loss: 2.029513
2025-04-07 12:51: Train Epoch 3: 100/159 Loss: 2.080210
2025-04-07 12:51: Train Epoch 3: 120/159 Loss: 2.271640
