2025-04-07 12:47: Experiment log path in: /data/zm/2025code/log/in12_out9
2025-04-07 12:47: Train: (10183, 12, 39, 3), (10183, 9, 39, 3)
2025-04-07 12:47: Val: (3394, 12, 39, 3), (3394, 9, 39, 3)
2025-04-07 12:47: Test: (3395, 12, 39, 3), (3395, 9, 39, 3)
2025-04-07 12:47: memory_usage: (0.837890625, 2.0)
2025-04-07 12:47: Applying learning rate decay.
2025-04-07 12:47: *****************Model Parameter*****************
2025-04-07 12:47: data_l torch.Size([96]) True
2025-04-07 12:47: tod_embedding.weight torch.Size([288, 32]) True
2025-04-07 12:47: dow_embedding.weight torch.Size([7, 32]) True
2025-04-07 12:47: SpatialEmbedding.B_sp torch.Size([307, 32]) True
2025-04-07 12:47: SpatialEmbedding.B_su torch.Size([307, 32]) True
2025-04-07 12:47: data_embedding.weight torch.Size([96, 1]) True
2025-04-07 12:47: data_embedding.bias torch.Size([96]) True
2025-04-07 12:47: MLPA.blocks.0.linear.weight torch.Size([64, 64]) True
2025-04-07 12:47: MLPA.blocks.0.linear.bias torch.Size([64]) True
2025-04-07 12:47: MLPA.blocks.0.norm.weight torch.Size([64]) True
2025-04-07 12:47: MLPA.blocks.0.norm.bias torch.Size([64]) True
2025-04-07 12:47: MLPB.blocks.0.linear.weight torch.Size([64, 64]) True
2025-04-07 12:47: MLPB.blocks.0.linear.bias torch.Size([64]) True
2025-04-07 12:47: MLPB.blocks.0.norm.weight torch.Size([64]) True
2025-04-07 12:47: MLPB.blocks.0.norm.bias torch.Size([64]) True
2025-04-07 12:47: MLPC.blocks.0.linear.weight torch.Size([96, 96]) True
2025-04-07 12:47: MLPC.blocks.0.linear.bias torch.Size([96]) True
2025-04-07 12:47: MLPC.blocks.0.norm.weight torch.Size([96]) True
2025-04-07 12:47: MLPC.blocks.0.norm.bias torch.Size([96]) True
2025-04-07 12:47: MLPD.blocks.0.linear.weight torch.Size([128, 128]) True
2025-04-07 12:47: MLPD.blocks.0.linear.bias torch.Size([128]) True
2025-04-07 12:47: MLPD.blocks.0.norm.weight torch.Size([128]) True
2025-04-07 12:47: MLPD.blocks.0.norm.bias torch.Size([128]) True
2025-04-07 12:47: MLPE.blocks.0.linear.weight torch.Size([224, 224]) True
2025-04-07 12:47: MLPE.blocks.0.linear.bias torch.Size([224]) True
2025-04-07 12:47: MLPE.blocks.0.norm.weight torch.Size([224]) True
2025-04-07 12:47: MLPE.blocks.0.norm.bias torch.Size([224]) True
2025-04-07 12:47: MLPE.blocks.1.linear.weight torch.Size([224, 224]) True
2025-04-07 12:47: MLPE.blocks.1.linear.bias torch.Size([224]) True
2025-04-07 12:47: MLPE.blocks.1.norm.weight torch.Size([224]) True
2025-04-07 12:47: MLPE.blocks.1.norm.bias torch.Size([224]) True
2025-04-07 12:47: MLPE.blocks.2.linear.weight torch.Size([224, 224]) True
2025-04-07 12:47: MLPE.blocks.2.linear.bias torch.Size([224]) True
2025-04-07 12:47: MLPE.blocks.2.norm.weight torch.Size([224]) True
2025-04-07 12:47: MLPE.blocks.2.norm.bias torch.Size([224]) True
2025-04-07 12:47: MLPF.blocks.0.linear.weight torch.Size([12, 12]) True
2025-04-07 12:47: MLPF.blocks.0.linear.bias torch.Size([12]) True
2025-04-07 12:47: MLPF.blocks.0.norm.weight torch.Size([12]) True
2025-04-07 12:47: MLPF.blocks.0.norm.bias torch.Size([12]) True
2025-04-07 12:47: MLPF.blocks.1.linear.weight torch.Size([12, 12]) True
2025-04-07 12:47: MLPF.blocks.1.linear.bias torch.Size([12]) True
2025-04-07 12:47: MLPF.blocks.1.norm.weight torch.Size([12]) True
2025-04-07 12:47: MLPF.blocks.1.norm.bias torch.Size([12]) True
2025-04-07 12:47: steps_linear.weight torch.Size([9, 12]) True
2025-04-07 12:47: steps_linear.bias torch.Size([9]) True
2025-04-07 12:47: out_linear.weight torch.Size([1, 224]) True
2025-04-07 12:47: out_linear.bias torch.Size([1]) True
2025-04-07 12:47: Total params num: 217470
2025-04-07 12:47: *****************Finish Parameter****************
2025-04-07 12:47: Train Epoch 1: 0/159 Loss: 61.145596
2025-04-07 12:47: Train Epoch 1: 20/159 Loss: 12.634420
2025-04-07 12:47: Train Epoch 1: 40/159 Loss: 8.501131
2025-04-07 12:47: Train Epoch 1: 60/159 Loss: 8.346980
2025-04-07 12:48: Train Epoch 1: 80/159 Loss: 7.311011
2025-04-07 12:48: Train Epoch 1: 100/159 Loss: 7.177951
2025-04-07 12:48: Train Epoch 1: 120/159 Loss: 5.658999
2025-04-07 12:48: Train Epoch 1: 140/159 Loss: 5.728944
2025-04-07 12:48: **********Train Epoch 1: Average Loss: 9.143604
2025-04-07 12:48: **********Train Epoch 1: MAE: 9.143604 RMSE: 12.931816 MAPE: 0.142934
2025-04-07 12:48: **********Val Epoch 1: Average Loss: 3.855627
2025-04-07 12:48: **********Val Epoch 1: MAE: 3.855627 RMSE: 7.832091 MAPE: 0.068638
2025-04-07 12:48: *********************************Current best model saved!
2025-04-07 12:48: Train Epoch 1: 0/159 Loss: 5.516938
2025-04-07 12:48: Train Epoch 1: 20/159 Loss: 5.406407
2025-04-07 12:48: Train Epoch 1: 40/159 Loss: 4.896151
2025-04-07 12:48: Train Epoch 1: 60/159 Loss: 4.793119
2025-04-07 12:48: Train Epoch 1: 80/159 Loss: 4.172186
2025-04-07 12:48: Train Epoch 1: 100/159 Loss: 4.607727
2025-04-07 12:48: Train Epoch 1: 120/159 Loss: 4.972310
2025-04-07 12:48: Train Epoch 1: 140/159 Loss: 4.217640
2025-04-07 12:49: **********Train Epoch 1: Average Loss: 4.772577
2025-04-07 12:49: **********Train Epoch 1: MAE: 4.772577 RMSE: 7.977733 MAPE: 0.081853
2025-04-07 12:49: **********Val Epoch 1: Average Loss: 3.041785
2025-04-07 12:49: **********Val Epoch 1: MAE: 3.041785 RMSE: 6.451424 MAPE: 0.056499
2025-04-07 12:49: *********************************Current best model saved!
2025-04-07 12:49: Train Epoch 2: 0/159 Loss: 4.287425
2025-04-07 12:49: Train Epoch 2: 20/159 Loss: 3.809290
2025-04-07 12:49: Train Epoch 2: 40/159 Loss: 3.368437
2025-04-07 12:49: Train Epoch 2: 60/159 Loss: 3.197043
2025-04-07 12:49: Train Epoch 2: 80/159 Loss: 2.964707
2025-04-07 12:49: Train Epoch 2: 100/159 Loss: 3.159192
2025-04-07 12:49: Train Epoch 2: 120/159 Loss: 2.820817
2025-04-07 12:49: Train Epoch 2: 140/159 Loss: 2.669520
2025-04-07 12:49: **********Train Epoch 2: Average Loss: 3.311362
2025-04-07 12:49: **********Train Epoch 2: MAE: 3.311362 RMSE: 5.802522 MAPE: 0.060003
2025-04-07 12:49: **********Val Epoch 2: Average Loss: 2.231586
2025-04-07 12:49: **********Val Epoch 2: MAE: 2.231586 RMSE: 4.661174 MAPE: 0.043557
2025-04-07 12:49: *********************************Current best model saved!
2025-04-07 12:49: Train Epoch 2: 0/159 Loss: 2.629540
2025-04-07 12:49: Train Epoch 2: 20/159 Loss: 2.423475
2025-04-07 12:49: Train Epoch 2: 40/159 Loss: 2.537314
2025-04-07 12:50: Train Epoch 2: 60/159 Loss: 2.234850
2025-04-07 12:50: Train Epoch 2: 80/159 Loss: 2.243031
2025-04-07 12:50: Train Epoch 2: 100/159 Loss: 2.313257
2025-04-07 12:50: Train Epoch 2: 120/159 Loss: 1.764016
2025-04-07 12:50: Train Epoch 2: 140/159 Loss: 2.244832
2025-04-07 12:50: **********Train Epoch 2: Average Loss: 2.321133
2025-04-07 12:50: **********Train Epoch 2: MAE: 2.321133 RMSE: 4.485928 MAPE: 0.044167
2025-04-07 12:50: **********Val Epoch 2: Average Loss: 1.960685
2025-04-07 12:50: **********Val Epoch 2: MAE: 1.960685 RMSE: 4.051850 MAPE: 0.038470
2025-04-07 12:50: *********************************Current best model saved!
2025-04-07 12:50: Train Epoch 3: 0/159 Loss: 2.537973
2025-04-07 12:50: Train Epoch 3: 20/159 Loss: 2.753036
2025-04-07 12:50: Train Epoch 3: 40/159 Loss: 2.169321
2025-04-07 12:50: Train Epoch 3: 60/159 Loss: 2.135353
2025-04-07 12:50: Train Epoch 3: 80/159 Loss: 1.979466
2025-04-07 12:50: Train Epoch 3: 100/159 Loss: 1.893663
2025-04-07 12:50: Train Epoch 3: 120/159 Loss: 1.791380
2025-04-07 12:51: Train Epoch 3: 140/159 Loss: 2.005107
2025-04-07 12:51: **********Train Epoch 3: Average Loss: 2.304363
2025-04-07 12:51: **********Train Epoch 3: MAE: 2.304363 RMSE: 4.346468 MAPE: 0.043575
2025-04-07 12:51: **********Val Epoch 3: Average Loss: 1.802263
2025-04-07 12:51: **********Val Epoch 3: MAE: 1.802263 RMSE: 3.960262 MAPE: 0.035799
2025-04-07 12:51: *********************************Current best model saved!
2025-04-07 12:51: Train Epoch 3: 0/159 Loss: 1.904757
2025-04-07 12:51: Train Epoch 3: 20/159 Loss: 2.349935
2025-04-07 12:51: Train Epoch 3: 40/159 Loss: 2.002583
2025-04-07 12:51: Train Epoch 3: 60/159 Loss: 1.788095
2025-04-07 12:51: Train Epoch 3: 80/159 Loss: 1.704058
2025-04-07 12:51: Train Epoch 3: 100/159 Loss: 1.908015
2025-04-07 12:51: Train Epoch 3: 120/159 Loss: 1.861627
