2025-04-07 12:47: Experiment log path in: /data/zm/2025code/log/in12_out9
2025-04-07 12:47: Train: (10183, 12, 39, 3), (10183, 9, 39, 3)
2025-04-07 12:47: Val: (3394, 12, 39, 3), (3394, 9, 39, 3)
2025-04-07 12:47: Test: (3395, 12, 39, 3), (3395, 9, 39, 3)
2025-04-07 12:47: memory_usage: (0.837890625, 2.0)
2025-04-07 12:47: Applying learning rate decay.
2025-04-07 12:47: *****************Model Parameter*****************
2025-04-07 12:47: data_l torch.Size([96]) True
2025-04-07 12:47: tod_embedding.weight torch.Size([288, 32]) True
2025-04-07 12:47: dow_embedding.weight torch.Size([7, 32]) True
2025-04-07 12:47: SpatialEmbedding.B_sp torch.Size([307, 32]) True
2025-04-07 12:47: SpatialEmbedding.B_su torch.Size([307, 32]) True
2025-04-07 12:47: data_embedding.weight torch.Size([96, 1]) True
2025-04-07 12:47: data_embedding.bias torch.Size([96]) True
2025-04-07 12:47: MLPA.blocks.0.linear.weight torch.Size([64, 64]) True
2025-04-07 12:47: MLPA.blocks.0.linear.bias torch.Size([64]) True
2025-04-07 12:47: MLPA.blocks.0.norm.weight torch.Size([64]) True
2025-04-07 12:47: MLPA.blocks.0.norm.bias torch.Size([64]) True
2025-04-07 12:47: MLPB.blocks.0.linear.weight torch.Size([64, 64]) True
2025-04-07 12:47: MLPB.blocks.0.linear.bias torch.Size([64]) True
2025-04-07 12:47: MLPB.blocks.0.norm.weight torch.Size([64]) True
2025-04-07 12:47: MLPB.blocks.0.norm.bias torch.Size([64]) True
2025-04-07 12:47: MLPC.blocks.0.linear.weight torch.Size([96, 96]) True
2025-04-07 12:47: MLPC.blocks.0.linear.bias torch.Size([96]) True
2025-04-07 12:47: MLPC.blocks.0.norm.weight torch.Size([96]) True
2025-04-07 12:47: MLPC.blocks.0.norm.bias torch.Size([96]) True
2025-04-07 12:47: MLPD.blocks.0.linear.weight torch.Size([128, 128]) True
2025-04-07 12:47: MLPD.blocks.0.linear.bias torch.Size([128]) True
2025-04-07 12:47: MLPD.blocks.0.norm.weight torch.Size([128]) True
2025-04-07 12:47: MLPD.blocks.0.norm.bias torch.Size([128]) True
2025-04-07 12:47: MLPE.blocks.0.linear.weight torch.Size([224, 224]) True
2025-04-07 12:47: MLPE.blocks.0.linear.bias torch.Size([224]) True
2025-04-07 12:47: MLPE.blocks.0.norm.weight torch.Size([224]) True
2025-04-07 12:47: MLPE.blocks.0.norm.bias torch.Size([224]) True
2025-04-07 12:47: MLPE.blocks.1.linear.weight torch.Size([224, 224]) True
2025-04-07 12:47: MLPE.blocks.1.linear.bias torch.Size([224]) True
2025-04-07 12:47: MLPE.blocks.1.norm.weight torch.Size([224]) True
2025-04-07 12:47: MLPE.blocks.1.norm.bias torch.Size([224]) True
2025-04-07 12:47: MLPE.blocks.2.linear.weight torch.Size([224, 224]) True
2025-04-07 12:47: MLPE.blocks.2.linear.bias torch.Size([224]) True
2025-04-07 12:47: MLPE.blocks.2.norm.weight torch.Size([224]) True
2025-04-07 12:47: MLPE.blocks.2.norm.bias torch.Size([224]) True
2025-04-07 12:47: MLPF.blocks.0.linear.weight torch.Size([12, 12]) True
2025-04-07 12:47: MLPF.blocks.0.linear.bias torch.Size([12]) True
2025-04-07 12:47: MLPF.blocks.0.norm.weight torch.Size([12]) True
2025-04-07 12:47: MLPF.blocks.0.norm.bias torch.Size([12]) True
2025-04-07 12:47: MLPF.blocks.1.linear.weight torch.Size([12, 12]) True
2025-04-07 12:47: MLPF.blocks.1.linear.bias torch.Size([12]) True
2025-04-07 12:47: MLPF.blocks.1.norm.weight torch.Size([12]) True
2025-04-07 12:47: MLPF.blocks.1.norm.bias torch.Size([12]) True
2025-04-07 12:47: steps_linear.weight torch.Size([9, 12]) True
2025-04-07 12:47: steps_linear.bias torch.Size([9]) True
2025-04-07 12:47: out_linear.weight torch.Size([1, 224]) True
2025-04-07 12:47: out_linear.bias torch.Size([1]) True
2025-04-07 12:47: Total params num: 217470
2025-04-07 12:47: *****************Finish Parameter****************
2025-04-07 12:47: Train Epoch 1: 0/159 Loss: 61.145596
2025-04-07 12:47: Train Epoch 1: 20/159 Loss: 12.634420
2025-04-07 12:47: Train Epoch 1: 40/159 Loss: 8.501131
2025-04-07 12:47: Train Epoch 1: 60/159 Loss: 8.346980
2025-04-07 12:48: Train Epoch 1: 80/159 Loss: 7.311011
2025-04-07 12:48: Train Epoch 1: 100/159 Loss: 7.177951
2025-04-07 12:48: Train Epoch 1: 120/159 Loss: 5.658999
2025-04-07 12:48: Train Epoch 1: 140/159 Loss: 5.728944
2025-04-07 12:48: **********Train Epoch 1: Average Loss: 9.143604
2025-04-07 12:48: **********Train Epoch 1: MAE: 9.143604 RMSE: 12.931816 MAPE: 0.142934
2025-04-07 12:48: **********Val Epoch 1: Average Loss: 3.855627
2025-04-07 12:48: **********Val Epoch 1: MAE: 3.855627 RMSE: 7.832091 MAPE: 0.068638
2025-04-07 12:48: *********************************Current best model saved!
2025-04-07 12:48: Train Epoch 1: 0/159 Loss: 5.516938
2025-04-07 12:48: Train Epoch 1: 20/159 Loss: 5.406407
2025-04-07 12:48: Train Epoch 1: 40/159 Loss: 4.896151
2025-04-07 12:48: Train Epoch 1: 60/159 Loss: 4.793119
2025-04-07 12:48: Train Epoch 1: 80/159 Loss: 4.172186
2025-04-07 12:48: Train Epoch 1: 100/159 Loss: 4.607727
2025-04-07 12:48: Train Epoch 1: 120/159 Loss: 4.972310
2025-04-07 12:48: Train Epoch 1: 140/159 Loss: 4.217640
2025-04-07 12:49: **********Train Epoch 1: Average Loss: 4.772577
2025-04-07 12:49: **********Train Epoch 1: MAE: 4.772577 RMSE: 7.977733 MAPE: 0.081853
2025-04-07 12:49: **********Val Epoch 1: Average Loss: 3.041785
2025-04-07 12:49: **********Val Epoch 1: MAE: 3.041785 RMSE: 6.451424 MAPE: 0.056499
2025-04-07 12:49: *********************************Current best model saved!
2025-04-07 12:49: Train Epoch 2: 0/159 Loss: 4.287425
2025-04-07 12:49: Train Epoch 2: 20/159 Loss: 3.809290
2025-04-07 12:49: Train Epoch 2: 40/159 Loss: 3.368437
2025-04-07 12:49: Train Epoch 2: 60/159 Loss: 3.197043
2025-04-07 12:49: Train Epoch 2: 80/159 Loss: 2.964707
2025-04-07 12:49: Train Epoch 2: 100/159 Loss: 3.159192
2025-04-07 12:49: Train Epoch 2: 120/159 Loss: 2.820817
2025-04-07 12:49: Train Epoch 2: 140/159 Loss: 2.669520
2025-04-07 12:49: **********Train Epoch 2: Average Loss: 3.311362
2025-04-07 12:49: **********Train Epoch 2: MAE: 3.311362 RMSE: 5.802522 MAPE: 0.060003
2025-04-07 12:49: **********Val Epoch 2: Average Loss: 2.231586
2025-04-07 12:49: **********Val Epoch 2: MAE: 2.231586 RMSE: 4.661174 MAPE: 0.043557
2025-04-07 12:49: *********************************Current best model saved!
2025-04-07 12:49: Train Epoch 2: 0/159 Loss: 2.629540
2025-04-07 12:49: Train Epoch 2: 20/159 Loss: 2.423475
2025-04-07 12:49: Train Epoch 2: 40/159 Loss: 2.537314
2025-04-07 12:50: Train Epoch 2: 60/159 Loss: 2.234850
2025-04-07 12:50: Train Epoch 2: 80/159 Loss: 2.243031
2025-04-07 12:50: Train Epoch 2: 100/159 Loss: 2.313257
2025-04-07 12:50: Train Epoch 2: 120/159 Loss: 1.764016
2025-04-07 12:50: Train Epoch 2: 140/159 Loss: 2.244832
2025-04-07 12:50: **********Train Epoch 2: Average Loss: 2.321133
2025-04-07 12:50: **********Train Epoch 2: MAE: 2.321133 RMSE: 4.485928 MAPE: 0.044167
2025-04-07 12:50: **********Val Epoch 2: Average Loss: 1.960685
2025-04-07 12:50: **********Val Epoch 2: MAE: 1.960685 RMSE: 4.051850 MAPE: 0.038470
2025-04-07 12:50: *********************************Current best model saved!
2025-04-07 12:50: Train Epoch 3: 0/159 Loss: 2.537973
2025-04-07 12:50: Train Epoch 3: 20/159 Loss: 2.753036
2025-04-07 12:50: Train Epoch 3: 40/159 Loss: 2.169321
2025-04-07 12:50: Train Epoch 3: 60/159 Loss: 2.135353
2025-04-07 12:50: Train Epoch 3: 80/159 Loss: 1.979466
2025-04-07 12:50: Train Epoch 3: 100/159 Loss: 1.893663
2025-04-07 12:50: Train Epoch 3: 120/159 Loss: 1.791380
2025-04-07 12:51: Train Epoch 3: 140/159 Loss: 2.005107
2025-04-07 12:51: **********Train Epoch 3: Average Loss: 2.304363
2025-04-07 12:51: **********Train Epoch 3: MAE: 2.304363 RMSE: 4.346468 MAPE: 0.043575
2025-04-07 12:51: **********Val Epoch 3: Average Loss: 1.802263
2025-04-07 12:51: **********Val Epoch 3: MAE: 1.802263 RMSE: 3.960262 MAPE: 0.035799
2025-04-07 12:51: *********************************Current best model saved!
2025-04-07 12:51: Train Epoch 3: 0/159 Loss: 1.904757
2025-04-07 12:51: Train Epoch 3: 20/159 Loss: 2.349935
2025-04-07 12:51: Train Epoch 3: 40/159 Loss: 2.002583
2025-04-07 12:51: Train Epoch 3: 60/159 Loss: 1.788095
2025-04-07 12:51: Train Epoch 3: 80/159 Loss: 1.704058
2025-04-07 12:51: Train Epoch 3: 100/159 Loss: 1.908015
2025-04-07 12:51: Train Epoch 3: 120/159 Loss: 1.861627
2025-04-07 12:51: Train Epoch 3: 140/159 Loss: 2.023199
2025-04-07 12:51: **********Train Epoch 3: Average Loss: 1.910176
2025-04-07 12:51: **********Train Epoch 3: MAE: 1.910176 RMSE: 3.948574 MAPE: 0.036976
2025-04-07 12:51: **********Val Epoch 3: Average Loss: 1.749110
2025-04-07 12:51: **********Val Epoch 3: MAE: 1.749110 RMSE: 3.896287 MAPE: 0.034368
2025-04-07 12:51: *********************************Current best model saved!
2025-04-07 12:51: Train Epoch 4: 0/159 Loss: 1.745055
2025-04-07 12:51: Train Epoch 4: 20/159 Loss: 2.174346
2025-04-07 12:52: Train Epoch 4: 40/159 Loss: 1.854408
2025-04-07 12:52: Train Epoch 4: 60/159 Loss: 1.773702
2025-04-07 12:52: Train Epoch 4: 80/159 Loss: 1.828664
2025-04-07 12:52: Train Epoch 4: 100/159 Loss: 2.136903
2025-04-07 12:52: Train Epoch 4: 120/159 Loss: 1.819177
2025-04-07 12:52: Train Epoch 4: 140/159 Loss: 2.013587
2025-04-07 12:52: **********Train Epoch 4: Average Loss: 1.927753
2025-04-07 12:52: **********Train Epoch 4: MAE: 1.927753 RMSE: 3.957138 MAPE: 0.037198
2025-04-07 12:52: **********Val Epoch 4: Average Loss: 1.717601
2025-04-07 12:52: **********Val Epoch 4: MAE: 1.717601 RMSE: 3.846950 MAPE: 0.033781
2025-04-07 12:52: *********************************Current best model saved!
2025-04-07 12:52: Train Epoch 4: 0/159 Loss: 1.735302
2025-04-07 12:52: Train Epoch 4: 20/159 Loss: 1.832546
2025-04-07 12:52: Train Epoch 4: 40/159 Loss: 1.812210
2025-04-07 12:52: Train Epoch 4: 60/159 Loss: 1.709420
2025-04-07 12:52: Train Epoch 4: 80/159 Loss: 1.692665
2025-04-07 12:52: Train Epoch 4: 100/159 Loss: 1.943257
2025-04-07 12:53: Train Epoch 4: 120/159 Loss: 1.901089
2025-04-07 12:53: Train Epoch 4: 140/159 Loss: 1.673745
2025-04-07 12:53: **********Train Epoch 4: Average Loss: 1.765640
2025-04-07 12:53: **********Train Epoch 4: MAE: 1.765640 RMSE: 3.791676 MAPE: 0.034232
2025-04-07 12:53: **********Val Epoch 4: Average Loss: 1.679789
2025-04-07 12:53: **********Val Epoch 4: MAE: 1.679789 RMSE: 3.786438 MAPE: 0.032969
2025-04-07 12:53: *********************************Current best model saved!
2025-04-07 12:53: Train Epoch 5: 0/159 Loss: 2.048952
2025-04-07 12:53: Train Epoch 5: 20/159 Loss: 1.522485
2025-04-07 12:53: Train Epoch 5: 40/159 Loss: 1.655094
2025-04-07 12:53: Train Epoch 5: 60/159 Loss: 1.725158
2025-04-07 12:53: Train Epoch 5: 80/159 Loss: 1.895320
2025-04-07 12:53: Train Epoch 5: 100/159 Loss: 1.569700
2025-04-07 12:53: Train Epoch 5: 120/159 Loss: 1.446571
2025-04-07 12:53: Train Epoch 5: 140/159 Loss: 1.992061
2025-04-07 12:53: **********Train Epoch 5: Average Loss: 1.789893
2025-04-07 12:53: **********Train Epoch 5: MAE: 1.789893 RMSE: 3.814768 MAPE: 0.034687
2025-04-07 12:53: **********Val Epoch 5: Average Loss: 1.675817
2025-04-07 12:53: **********Val Epoch 5: MAE: 1.675817 RMSE: 3.791719 MAPE: 0.032946
2025-04-07 12:53: *********************************Current best model saved!
2025-04-07 12:53: Train Epoch 5: 0/159 Loss: 1.702263
2025-04-07 12:54: Train Epoch 5: 20/159 Loss: 1.523680
2025-04-07 12:54: Train Epoch 5: 40/159 Loss: 1.720265
2025-04-07 12:54: Train Epoch 5: 60/159 Loss: 1.681614
2025-04-07 12:54: Train Epoch 5: 80/159 Loss: 1.940746
2025-04-07 12:54: Train Epoch 5: 100/159 Loss: 1.794560
2025-04-07 12:54: Train Epoch 5: 120/159 Loss: 1.596720
2025-04-07 12:54: Train Epoch 5: 140/159 Loss: 1.341836
2025-04-07 12:54: **********Train Epoch 5: Average Loss: 1.697335
2025-04-07 12:54: **********Train Epoch 5: MAE: 1.697335 RMSE: 3.721260 MAPE: 0.032922
2025-04-07 12:54: **********Val Epoch 5: Average Loss: 1.644598
2025-04-07 12:54: **********Val Epoch 5: MAE: 1.644598 RMSE: 3.727454 MAPE: 0.032220
2025-04-07 12:54: *********************************Current best model saved!
2025-04-07 12:54: Train Epoch 6: 0/159 Loss: 1.889242
2025-04-07 12:54: Train Epoch 6: 20/159 Loss: 1.588402
2025-04-07 12:54: Train Epoch 6: 40/159 Loss: 1.541263
2025-04-07 12:54: Train Epoch 6: 60/159 Loss: 1.629206
2025-04-07 12:54: Train Epoch 6: 80/159 Loss: 1.846986
2025-04-07 12:55: Train Epoch 6: 100/159 Loss: 1.771894
2025-04-07 12:55: Train Epoch 6: 120/159 Loss: 1.680777
2025-04-07 12:55: Train Epoch 6: 140/159 Loss: 1.548802
2025-04-07 12:55: **********Train Epoch 6: Average Loss: 1.708543
2025-04-07 12:55: **********Train Epoch 6: MAE: 1.708543 RMSE: 3.740514 MAPE: 0.033111
2025-04-07 12:55: **********Val Epoch 6: Average Loss: 1.634564
2025-04-07 12:55: **********Val Epoch 6: MAE: 1.634564 RMSE: 3.699556 MAPE: 0.031927
2025-04-07 12:55: *********************************Current best model saved!
2025-04-07 12:55: Train Epoch 6: 0/159 Loss: 1.511140
2025-04-07 12:55: Train Epoch 6: 20/159 Loss: 1.614152
2025-04-07 12:55: Train Epoch 6: 40/159 Loss: 1.815960
2025-04-07 12:55: Train Epoch 6: 60/159 Loss: 1.524191
2025-04-07 12:55: Train Epoch 6: 80/159 Loss: 1.591436
2025-04-07 12:55: Train Epoch 6: 100/159 Loss: 1.663088
2025-04-07 12:55: Train Epoch 6: 120/159 Loss: 1.427669
2025-04-07 12:55: Train Epoch 6: 140/159 Loss: 1.571342
2025-04-07 12:55: **********Train Epoch 6: Average Loss: 1.649300
2025-04-07 12:55: **********Train Epoch 6: MAE: 1.649300 RMSE: 3.657831 MAPE: 0.031936
2025-04-07 12:55: **********Val Epoch 6: Average Loss: 1.613379
2025-04-07 12:55: **********Val Epoch 6: MAE: 1.613379 RMSE: 3.679669 MAPE: 0.031599
2025-04-07 12:55: *********************************Current best model saved!
2025-04-07 12:56: Train Epoch 7: 0/159 Loss: 1.718853
2025-04-07 12:56: Train Epoch 7: 20/159 Loss: 1.796052
2025-04-07 12:56: Train Epoch 7: 40/159 Loss: 1.499201
2025-04-07 12:56: Train Epoch 7: 60/159 Loss: 1.746088
2025-04-07 12:56: Train Epoch 7: 80/159 Loss: 1.584150
2025-04-07 12:56: Train Epoch 7: 100/159 Loss: 1.696630
2025-04-07 12:56: Train Epoch 7: 120/159 Loss: 1.853186
2025-04-07 12:56: Train Epoch 7: 140/159 Loss: 1.918644
2025-04-07 12:56: **********Train Epoch 7: Average Loss: 1.662317
2025-04-07 12:56: **********Train Epoch 7: MAE: 1.662317 RMSE: 3.681811 MAPE: 0.032181
2025-04-07 12:56: **********Val Epoch 7: Average Loss: 1.615532
2025-04-07 12:56: **********Val Epoch 7: MAE: 1.615532 RMSE: 3.667791 MAPE: 0.031394
2025-04-07 12:56: Train Epoch 7: 0/159 Loss: 1.581587
2025-04-07 12:56: Train Epoch 7: 20/159 Loss: 1.672094
2025-04-07 12:56: Train Epoch 7: 40/159 Loss: 1.720290
2025-04-07 12:56: Train Epoch 7: 60/159 Loss: 1.478238
2025-04-07 12:57: Train Epoch 7: 80/159 Loss: 1.642231
2025-04-07 12:57: Train Epoch 7: 100/159 Loss: 1.791011
2025-04-07 12:57: Train Epoch 7: 120/159 Loss: 1.632413
2025-04-07 12:57: Train Epoch 7: 140/159 Loss: 1.420599
2025-04-07 12:57: **********Train Epoch 7: Average Loss: 1.611349
2025-04-07 12:57: **********Train Epoch 7: MAE: 1.611349 RMSE: 3.602156 MAPE: 0.031127
2025-04-07 12:57: **********Val Epoch 7: Average Loss: 1.593458
2025-04-07 12:57: **********Val Epoch 7: MAE: 1.593458 RMSE: 3.577434 MAPE: 0.030960
2025-04-07 12:57: *********************************Current best model saved!
2025-04-07 12:57: Train Epoch 8: 0/159 Loss: 1.464545
2025-04-07 12:57: Train Epoch 8: 20/159 Loss: 1.584538
2025-04-07 12:57: Train Epoch 8: 40/159 Loss: 1.557429
2025-04-07 12:57: Train Epoch 8: 60/159 Loss: 1.661841
2025-04-07 12:57: Train Epoch 8: 80/159 Loss: 1.573834
2025-04-07 12:57: Train Epoch 8: 100/159 Loss: 1.483799
2025-04-07 12:57: Train Epoch 8: 120/159 Loss: 1.470374
2025-04-07 12:57: Train Epoch 8: 140/159 Loss: 1.640673
2025-04-07 12:57: **********Train Epoch 8: Average Loss: 1.631098
2025-04-07 12:57: **********Train Epoch 8: MAE: 1.631098 RMSE: 3.635893 MAPE: 0.031531
2025-04-07 12:58: **********Val Epoch 8: Average Loss: 1.588850
2025-04-07 12:58: **********Val Epoch 8: MAE: 1.588850 RMSE: 3.633293 MAPE: 0.030977
2025-04-07 12:58: *********************************Current best model saved!
2025-04-07 12:58: Train Epoch 8: 0/159 Loss: 1.746892
2025-04-07 12:58: Train Epoch 8: 20/159 Loss: 1.761394
2025-04-07 12:58: Train Epoch 8: 40/159 Loss: 1.712561
2025-04-07 12:58: Train Epoch 8: 60/159 Loss: 1.556616
2025-04-07 12:58: Train Epoch 8: 80/159 Loss: 1.510676
2025-04-07 12:58: Train Epoch 8: 100/159 Loss: 1.733214
2025-04-07 12:58: Train Epoch 8: 120/159 Loss: 1.461092
2025-04-07 12:58: Train Epoch 8: 140/159 Loss: 1.508309
2025-04-07 12:58: **********Train Epoch 8: Average Loss: 1.583483
2025-04-07 12:58: **********Train Epoch 8: MAE: 1.583483 RMSE: 3.549264 MAPE: 0.030572
2025-04-07 12:58: **********Val Epoch 8: Average Loss: 1.567968
2025-04-07 12:58: **********Val Epoch 8: MAE: 1.567968 RMSE: 3.554028 MAPE: 0.030458
2025-04-07 12:58: *********************************Current best model saved!
2025-04-07 12:58: Train Epoch 9: 0/159 Loss: 1.534875
2025-04-07 12:58: Train Epoch 9: 20/159 Loss: 1.518257
2025-04-07 12:58: Train Epoch 9: 40/159 Loss: 1.512685
2025-04-07 12:58: Train Epoch 9: 60/159 Loss: 1.483577
2025-04-07 12:59: Train Epoch 9: 80/159 Loss: 1.607396
2025-04-07 12:59: Train Epoch 9: 100/159 Loss: 1.506133
2025-04-07 12:59: Train Epoch 9: 120/159 Loss: 1.552265
2025-04-07 12:59: Train Epoch 9: 140/159 Loss: 1.503863
2025-04-07 12:59: **********Train Epoch 9: Average Loss: 1.612278
2025-04-07 12:59: **********Train Epoch 9: MAE: 1.612278 RMSE: 3.601401 MAPE: 0.031132
2025-04-07 12:59: **********Val Epoch 9: Average Loss: 1.563959
2025-04-07 12:59: **********Val Epoch 9: MAE: 1.563959 RMSE: 3.548439 MAPE: 0.030342
2025-04-07 12:59: *********************************Current best model saved!
2025-04-07 12:59: Train Epoch 9: 0/159 Loss: 1.576769
2025-04-07 12:59: Train Epoch 9: 20/159 Loss: 1.541579
2025-04-07 12:59: Train Epoch 9: 40/159 Loss: 1.617369
2025-04-07 12:59: Train Epoch 9: 60/159 Loss: 1.632591
2025-04-07 12:59: Train Epoch 9: 80/159 Loss: 1.731647
2025-04-07 12:59: Train Epoch 9: 100/159 Loss: 1.383274
2025-04-07 12:59: Train Epoch 9: 120/159 Loss: 1.474695
2025-04-07 12:59: Train Epoch 9: 140/159 Loss: 1.613163
2025-04-07 13:00: **********Train Epoch 9: Average Loss: 1.560331
2025-04-07 13:00: **********Train Epoch 9: MAE: 1.560331 RMSE: 3.507812 MAPE: 0.030103
2025-04-07 13:00: **********Val Epoch 9: Average Loss: 1.541341
2025-04-07 13:00: **********Val Epoch 9: MAE: 1.541341 RMSE: 3.476947 MAPE: 0.029924
2025-04-07 13:00: *********************************Current best model saved!
2025-04-07 13:00: Train Epoch 10: 0/159 Loss: 1.650030
2025-04-07 13:00: Train Epoch 10: 20/159 Loss: 1.505037
2025-04-07 13:00: Train Epoch 10: 40/159 Loss: 1.620600
2025-04-07 13:00: Train Epoch 10: 60/159 Loss: 1.453704
2025-04-07 13:00: Train Epoch 10: 80/159 Loss: 1.554736
2025-04-07 13:00: Train Epoch 10: 100/159 Loss: 1.469069
2025-04-07 13:00: Train Epoch 10: 120/159 Loss: 1.454820
2025-04-07 13:00: Train Epoch 10: 140/159 Loss: 1.528028
2025-04-07 13:00: **********Train Epoch 10: Average Loss: 1.589559
2025-04-07 13:00: **********Train Epoch 10: MAE: 1.589559 RMSE: 3.558671 MAPE: 0.030658
2025-04-07 13:00: **********Val Epoch 10: Average Loss: 1.547786
2025-04-07 13:00: **********Val Epoch 10: MAE: 1.547786 RMSE: 3.503270 MAPE: 0.030096
2025-04-07 13:00: Train Epoch 10: 0/159 Loss: 1.440057
2025-04-07 13:00: Train Epoch 10: 20/159 Loss: 1.519652
2025-04-07 13:00: Train Epoch 10: 40/159 Loss: 1.323158
2025-04-07 13:01: Train Epoch 10: 60/159 Loss: 1.563592
2025-04-07 13:01: Train Epoch 10: 80/159 Loss: 1.597825
2025-04-07 13:01: Train Epoch 10: 100/159 Loss: 1.549715
2025-04-07 13:01: Train Epoch 10: 120/159 Loss: 1.541619
2025-04-07 13:01: Train Epoch 10: 140/159 Loss: 1.478065
2025-04-07 13:01: **********Train Epoch 10: Average Loss: 1.542269
2025-04-07 13:01: **********Train Epoch 10: MAE: 1.542269 RMSE: 3.465415 MAPE: 0.029738
2025-04-07 13:01: **********Val Epoch 10: Average Loss: 1.521626
2025-04-07 13:01: **********Val Epoch 10: MAE: 1.521626 RMSE: 3.425162 MAPE: 0.029474
2025-04-07 13:01: *********************************Current best model saved!
2025-04-07 13:01: Train Epoch 11: 0/159 Loss: 1.652310
2025-04-07 13:01: Train Epoch 11: 20/159 Loss: 1.603450
2025-04-07 13:01: Experiment log path in: /data/zm/2025code/log/in12_out9
2025-04-07 13:01: Train: (10183, 12, 39, 3), (10183, 9, 39, 3)
2025-04-07 13:01: Val: (3394, 12, 39, 3), (3394, 9, 39, 3)
2025-04-07 13:01: Test: (3395, 12, 39, 3), (3395, 9, 39, 3)
2025-04-07 13:01: memory_usage: (0.837890625, 2.0)
2025-04-07 13:01: Applying learning rate decay.
2025-04-07 13:01: *****************Model Parameter*****************
2025-04-07 13:01: data_l torch.Size([96]) True
2025-04-07 13:01: tod_embedding.weight torch.Size([288, 32]) True
2025-04-07 13:01: dow_embedding.weight torch.Size([7, 32]) True
2025-04-07 13:01: SpatialEmbedding.B_sp torch.Size([307, 32]) True
2025-04-07 13:01: SpatialEmbedding.B_su torch.Size([307, 32]) True
2025-04-07 13:01: data_embedding.weight torch.Size([96, 1]) True
2025-04-07 13:01: data_embedding.bias torch.Size([96]) True
2025-04-07 13:01: MLPA.blocks.0.linear.weight torch.Size([64, 64]) True
2025-04-07 13:01: MLPA.blocks.0.linear.bias torch.Size([64]) True
2025-04-07 13:01: MLPA.blocks.0.norm.weight torch.Size([64]) True
2025-04-07 13:01: MLPA.blocks.0.norm.bias torch.Size([64]) True
2025-04-07 13:01: MLPB.blocks.0.linear.weight torch.Size([64, 64]) True
2025-04-07 13:01: MLPB.blocks.0.linear.bias torch.Size([64]) True
2025-04-07 13:01: MLPB.blocks.0.norm.weight torch.Size([64]) True
2025-04-07 13:01: MLPB.blocks.0.norm.bias torch.Size([64]) True
2025-04-07 13:01: MLPC.blocks.0.linear.weight torch.Size([96, 96]) True
2025-04-07 13:01: MLPC.blocks.0.linear.bias torch.Size([96]) True
2025-04-07 13:01: MLPC.blocks.0.norm.weight torch.Size([96]) True
2025-04-07 13:01: MLPC.blocks.0.norm.bias torch.Size([96]) True
2025-04-07 13:01: MLPD.blocks.0.linear.weight torch.Size([128, 128]) True
2025-04-07 13:01: MLPD.blocks.0.linear.bias torch.Size([128]) True
2025-04-07 13:01: MLPD.blocks.0.norm.weight torch.Size([128]) True
2025-04-07 13:01: MLPD.blocks.0.norm.bias torch.Size([128]) True
2025-04-07 13:01: MLPE.blocks.0.linear.weight torch.Size([224, 224]) True
2025-04-07 13:01: MLPE.blocks.0.linear.bias torch.Size([224]) True
2025-04-07 13:01: MLPE.blocks.0.norm.weight torch.Size([224]) True
2025-04-07 13:01: MLPE.blocks.0.norm.bias torch.Size([224]) True
2025-04-07 13:01: MLPE.blocks.1.linear.weight torch.Size([224, 224]) True
2025-04-07 13:01: MLPE.blocks.1.linear.bias torch.Size([224]) True
2025-04-07 13:01: MLPE.blocks.1.norm.weight torch.Size([224]) True
2025-04-07 13:01: MLPE.blocks.1.norm.bias torch.Size([224]) True
2025-04-07 13:01: MLPE.blocks.2.linear.weight torch.Size([224, 224]) True
2025-04-07 13:01: MLPE.blocks.2.linear.bias torch.Size([224]) True
2025-04-07 13:01: MLPE.blocks.2.norm.weight torch.Size([224]) True
2025-04-07 13:01: MLPE.blocks.2.norm.bias torch.Size([224]) True
2025-04-07 13:01: MLPF.blocks.0.linear.weight torch.Size([12, 12]) True
2025-04-07 13:01: MLPF.blocks.0.linear.bias torch.Size([12]) True
2025-04-07 13:01: MLPF.blocks.0.norm.weight torch.Size([12]) True
2025-04-07 13:01: MLPF.blocks.0.norm.bias torch.Size([12]) True
2025-04-07 13:01: MLPF.blocks.1.linear.weight torch.Size([12, 12]) True
2025-04-07 13:01: MLPF.blocks.1.linear.bias torch.Size([12]) True
2025-04-07 13:01: MLPF.blocks.1.norm.weight torch.Size([12]) True
2025-04-07 13:01: MLPF.blocks.1.norm.bias torch.Size([12]) True
2025-04-07 13:01: steps_linear.weight torch.Size([9, 12]) True
2025-04-07 13:01: steps_linear.bias torch.Size([9]) True
2025-04-07 13:01: out_linear.weight torch.Size([1, 224]) True
2025-04-07 13:01: out_linear.bias torch.Size([1]) True
2025-04-07 13:01: Total params num: 217470
2025-04-07 13:01: *****************Finish Parameter****************
2025-04-07 13:01: Train Epoch 11: 40/159 Loss: 1.553752
2025-04-07 13:01: Train Epoch 1: 0/159 Loss: 61.145596
2025-04-07 13:01: Train Epoch 11: 60/159 Loss: 1.375339
2025-04-07 13:01: Train Epoch 1: 20/159 Loss: 12.634420
2025-04-07 13:01: Train Epoch 11: 80/159 Loss: 1.731215
2025-04-07 13:01: Train Epoch 1: 40/159 Loss: 8.501131
2025-04-07 13:01: Train Epoch 11: 100/159 Loss: 1.555866
2025-04-07 13:01: Train Epoch 1: 60/159 Loss: 8.346980
2025-04-07 13:02: Train Epoch 11: 120/159 Loss: 1.358151
2025-04-07 13:02: Train Epoch 1: 80/159 Loss: 7.311011
2025-04-07 13:02: Train Epoch 1: 100/159 Loss: 7.177951
2025-04-07 13:02: Train Epoch 11: 140/159 Loss: 1.757458
2025-04-07 13:02: **********Train Epoch 11: Average Loss: 1.570731
2025-04-07 13:02: **********Train Epoch 11: MAE: 1.570731 RMSE: 3.520062 MAPE: 0.030267
2025-04-07 13:02: Train Epoch 1: 120/159 Loss: 5.658999
2025-04-07 13:02: Experiment log path in: /data/zm/2025code/log/in12_out9
2025-04-07 13:02: Train: (10183, 12, 39, 3), (10183, 9, 39, 3)
2025-04-07 13:02: Val: (3394, 12, 39, 3), (3394, 9, 39, 3)
2025-04-07 13:02: Test: (3395, 12, 39, 3), (3395, 9, 39, 3)
2025-04-07 13:02: memory_usage: (0.837890625, 2.0)
2025-04-07 13:02: **********Val Epoch 11: Average Loss: 1.534441
2025-04-07 13:02: **********Val Epoch 11: MAE: 1.534441 RMSE: 3.484978 MAPE: 0.029814
2025-04-07 13:02: Train Epoch 11: 0/159 Loss: 1.665985
2025-04-07 13:02: Train Epoch 1: 140/159 Loss: 5.728944
2025-04-07 13:02: Applying learning rate decay.
2025-04-07 13:02: *****************Model Parameter*****************
2025-04-07 13:02: data_l torch.Size([96]) True
2025-04-07 13:02: tod_embedding.weight torch.Size([288, 32]) True
2025-04-07 13:02: dow_embedding.weight torch.Size([7, 32]) True
2025-04-07 13:02: SpatialEmbedding.B_sp torch.Size([307, 32]) True
2025-04-07 13:02: SpatialEmbedding.B_su torch.Size([307, 32]) True
2025-04-07 13:02: data_embedding.weight torch.Size([96, 1]) True
2025-04-07 13:02: data_embedding.bias torch.Size([96]) True
2025-04-07 13:02: MLPA.blocks.0.linear.weight torch.Size([64, 64]) True
2025-04-07 13:02: MLPA.blocks.0.linear.bias torch.Size([64]) True
2025-04-07 13:02: MLPA.blocks.0.norm.weight torch.Size([64]) True
2025-04-07 13:02: MLPA.blocks.0.norm.bias torch.Size([64]) True
2025-04-07 13:02: MLPB.blocks.0.linear.weight torch.Size([64, 64]) True
2025-04-07 13:02: MLPB.blocks.0.linear.bias torch.Size([64]) True
2025-04-07 13:02: MLPB.blocks.0.norm.weight torch.Size([64]) True
2025-04-07 13:02: MLPB.blocks.0.norm.bias torch.Size([64]) True
2025-04-07 13:02: MLPC.blocks.0.linear.weight torch.Size([96, 96]) True
2025-04-07 13:02: MLPC.blocks.0.linear.bias torch.Size([96]) True
2025-04-07 13:02: MLPC.blocks.0.norm.weight torch.Size([96]) True
2025-04-07 13:02: MLPC.blocks.0.norm.bias torch.Size([96]) True
2025-04-07 13:02: MLPD.blocks.0.linear.weight torch.Size([128, 128]) True
2025-04-07 13:02: MLPD.blocks.0.linear.bias torch.Size([128]) True
2025-04-07 13:02: MLPD.blocks.0.norm.weight torch.Size([128]) True
2025-04-07 13:02: MLPD.blocks.0.norm.bias torch.Size([128]) True
2025-04-07 13:02: MLPE.blocks.0.linear.weight torch.Size([224, 224]) True
2025-04-07 13:02: MLPE.blocks.0.linear.bias torch.Size([224]) True
2025-04-07 13:02: MLPE.blocks.0.norm.weight torch.Size([224]) True
2025-04-07 13:02: MLPE.blocks.0.norm.bias torch.Size([224]) True
2025-04-07 13:02: MLPE.blocks.1.linear.weight torch.Size([224, 224]) True
2025-04-07 13:02: MLPE.blocks.1.linear.bias torch.Size([224]) True
2025-04-07 13:02: MLPE.blocks.1.norm.weight torch.Size([224]) True
2025-04-07 13:02: MLPE.blocks.1.norm.bias torch.Size([224]) True
2025-04-07 13:02: MLPE.blocks.2.linear.weight torch.Size([224, 224]) True
2025-04-07 13:02: MLPE.blocks.2.linear.bias torch.Size([224]) True
2025-04-07 13:02: MLPE.blocks.2.norm.weight torch.Size([224]) True
2025-04-07 13:02: MLPE.blocks.2.norm.bias torch.Size([224]) True
2025-04-07 13:02: MLPF.blocks.0.linear.weight torch.Size([12, 12]) True
2025-04-07 13:02: MLPF.blocks.0.linear.bias torch.Size([12]) True
2025-04-07 13:02: MLPF.blocks.0.norm.weight torch.Size([12]) True
2025-04-07 13:02: MLPF.blocks.0.norm.bias torch.Size([12]) True
2025-04-07 13:02: MLPF.blocks.1.linear.weight torch.Size([12, 12]) True
2025-04-07 13:02: MLPF.blocks.1.linear.bias torch.Size([12]) True
2025-04-07 13:02: MLPF.blocks.1.norm.weight torch.Size([12]) True
2025-04-07 13:02: MLPF.blocks.1.norm.bias torch.Size([12]) True
2025-04-07 13:02: steps_linear.weight torch.Size([9, 12]) True
2025-04-07 13:02: steps_linear.bias torch.Size([9]) True
2025-04-07 13:02: out_linear.weight torch.Size([1, 224]) True
2025-04-07 13:02: out_linear.bias torch.Size([1]) True
2025-04-07 13:02: Total params num: 217470
2025-04-07 13:02: *****************Finish Parameter****************
2025-04-07 13:02: Train Epoch 1: 0/159 Loss: 61.145596
2025-04-07 13:02: **********Train Epoch 1: Average Loss: 9.143604
2025-04-07 13:02: **********Train Epoch 1: MAE: 9.143604 RMSE: 12.931816 MAPE: 0.142934
2025-04-07 13:02: Train Epoch 11: 20/159 Loss: 1.457561
2025-04-07 13:02: Train Epoch 1: 20/159 Loss: 12.634420
2025-04-07 13:02: **********Val Epoch 1: Average Loss: 3.855627
2025-04-07 13:02: **********Val Epoch 1: MAE: 3.855627 RMSE: 7.832091 MAPE: 0.068638
2025-04-07 13:02: *********************************Current best model saved!
2025-04-07 13:02: Train Epoch 1: 40/159 Loss: 8.501131
2025-04-07 13:02: Train Epoch 1: 0/159 Loss: 5.516938
2025-04-07 13:02: Train Epoch 11: 40/159 Loss: 1.448584
2025-04-07 13:02: Train Epoch 1: 60/159 Loss: 8.346980
2025-04-07 13:02: Train Epoch 1: 20/159 Loss: 5.406407
2025-04-07 13:02: Train Epoch 11: 60/159 Loss: 1.530408
2025-04-07 13:02: Train Epoch 1: 80/159 Loss: 7.311011
2025-04-07 13:02: Train Epoch 1: 40/159 Loss: 4.896151
2025-04-07 13:02: Train Epoch 11: 80/159 Loss: 1.642198
2025-04-07 13:02: Train Epoch 1: 100/159 Loss: 7.177951
2025-04-07 13:02: Train Epoch 1: 60/159 Loss: 4.793119
2025-04-07 13:02: Train Epoch 1: 120/159 Loss: 5.658999
2025-04-07 13:02: Train Epoch 11: 100/159 Loss: 1.473702
2025-04-07 13:02: Train Epoch 1: 140/159 Loss: 5.728944
2025-04-07 13:02: Train Epoch 1: 80/159 Loss: 4.172186
2025-04-07 13:02: Train Epoch 11: 120/159 Loss: 1.604572
2025-04-07 13:02: **********Train Epoch 1: Average Loss: 9.143604
2025-04-07 13:02: **********Train Epoch 1: MAE: 9.143604 RMSE: 12.931816 MAPE: 0.142934
2025-04-07 13:02: Train Epoch 1: 100/159 Loss: 4.607727
2025-04-07 13:02: Train Epoch 11: 140/159 Loss: 1.387528
2025-04-07 13:02: **********Val Epoch 1: Average Loss: 3.855627
2025-04-07 13:02: **********Val Epoch 1: MAE: 3.855627 RMSE: 7.832091 MAPE: 0.068638
2025-04-07 13:02: *********************************Current best model saved!
2025-04-07 13:02: Train Epoch 1: 0/159 Loss: 5.516938
2025-04-07 13:02: Train Epoch 1: 120/159 Loss: 4.972310
2025-04-07 13:02: **********Train Epoch 11: Average Loss: 1.525538
2025-04-07 13:02: **********Train Epoch 11: MAE: 1.525538 RMSE: 3.430999 MAPE: 0.029398
2025-04-07 13:02: Train Epoch 1: 20/159 Loss: 5.406407
2025-04-07 13:02: **********Val Epoch 11: Average Loss: 1.512568
2025-04-07 13:02: **********Val Epoch 11: MAE: 1.512568 RMSE: 3.436416 MAPE: 0.029367
2025-04-07 13:02: *********************************Current best model saved!
2025-04-07 13:02: Train Epoch 1: 140/159 Loss: 4.217640
2025-04-07 13:02: Train Epoch 1: 40/159 Loss: 4.896151
2025-04-07 13:02: **********Train Epoch 1: Average Loss: 4.772577
2025-04-07 13:02: **********Train Epoch 1: MAE: 4.772577 RMSE: 7.977733 MAPE: 0.081853
2025-04-07 13:02: Train Epoch 1: 60/159 Loss: 4.793119
2025-04-07 13:02: **********Val Epoch 1: Average Loss: 3.041785
2025-04-07 13:02: **********Val Epoch 1: MAE: 3.041785 RMSE: 6.451424 MAPE: 0.056499
2025-04-07 13:02: *********************************Current best model saved!
2025-04-07 13:03: Train Epoch 1: 80/159 Loss: 4.172186
2025-04-07 13:03: Train Epoch 1: 100/159 Loss: 4.607727
2025-04-07 13:03: Train Epoch 1: 120/159 Loss: 4.972310
2025-04-07 13:03: Train Epoch 1: 140/159 Loss: 4.217640
2025-04-07 13:03: **********Train Epoch 1: Average Loss: 4.772577
2025-04-07 13:03: **********Train Epoch 1: MAE: 4.772577 RMSE: 7.977733 MAPE: 0.081853
2025-04-07 13:03: **********Val Epoch 1: Average Loss: 3.041785
2025-04-07 13:03: **********Val Epoch 1: MAE: 3.041785 RMSE: 6.451424 MAPE: 0.056499
2025-04-07 13:03: *********************************Current best model saved!
2025-04-07 13:03: Total training time: 1.0254min, best loss: 3.041785
2025-04-07 13:04: Experiment log path in: /data/zm/2025code/log/in12_out9
2025-04-07 13:04: Train: (10183, 12, 39, 3), (10183, 9, 39, 3)
2025-04-07 13:04: Val: (3394, 12, 39, 3), (3394, 9, 39, 3)
2025-04-07 13:04: Test: (3395, 12, 39, 3), (3395, 9, 39, 3)
2025-04-07 13:04: memory_usage: (0.837890625, 2.0)
2025-04-07 13:05: Applying learning rate decay.
2025-04-07 13:05: *****************Model Parameter*****************
2025-04-07 13:05: data_l torch.Size([96]) True
2025-04-07 13:05: tod_embedding.weight torch.Size([288, 32]) True
2025-04-07 13:05: dow_embedding.weight torch.Size([7, 32]) True
2025-04-07 13:05: SpatialEmbedding.B_sp torch.Size([307, 32]) True
2025-04-07 13:05: SpatialEmbedding.B_su torch.Size([307, 32]) True
2025-04-07 13:05: data_embedding.weight torch.Size([96, 1]) True
2025-04-07 13:05: data_embedding.bias torch.Size([96]) True
2025-04-07 13:05: MLPA.blocks.0.linear.weight torch.Size([64, 64]) True
2025-04-07 13:05: MLPA.blocks.0.linear.bias torch.Size([64]) True
2025-04-07 13:05: MLPA.blocks.0.norm.weight torch.Size([64]) True
2025-04-07 13:05: MLPA.blocks.0.norm.bias torch.Size([64]) True
2025-04-07 13:05: MLPB.blocks.0.linear.weight torch.Size([64, 64]) True
2025-04-07 13:05: MLPB.blocks.0.linear.bias torch.Size([64]) True
2025-04-07 13:05: MLPB.blocks.0.norm.weight torch.Size([64]) True
2025-04-07 13:05: MLPB.blocks.0.norm.bias torch.Size([64]) True
2025-04-07 13:05: MLPC.blocks.0.linear.weight torch.Size([96, 96]) True
2025-04-07 13:05: MLPC.blocks.0.linear.bias torch.Size([96]) True
2025-04-07 13:05: MLPC.blocks.0.norm.weight torch.Size([96]) True
2025-04-07 13:05: MLPC.blocks.0.norm.bias torch.Size([96]) True
2025-04-07 13:05: MLPD.blocks.0.linear.weight torch.Size([128, 128]) True
2025-04-07 13:05: MLPD.blocks.0.linear.bias torch.Size([128]) True
2025-04-07 13:05: MLPD.blocks.0.norm.weight torch.Size([128]) True
2025-04-07 13:05: MLPD.blocks.0.norm.bias torch.Size([128]) True
2025-04-07 13:05: MLPE.blocks.0.linear.weight torch.Size([224, 224]) True
2025-04-07 13:05: MLPE.blocks.0.linear.bias torch.Size([224]) True
2025-04-07 13:05: MLPE.blocks.0.norm.weight torch.Size([224]) True
2025-04-07 13:05: MLPE.blocks.0.norm.bias torch.Size([224]) True
2025-04-07 13:05: MLPE.blocks.1.linear.weight torch.Size([224, 224]) True
2025-04-07 13:05: MLPE.blocks.1.linear.bias torch.Size([224]) True
2025-04-07 13:05: MLPE.blocks.1.norm.weight torch.Size([224]) True
2025-04-07 13:05: MLPE.blocks.1.norm.bias torch.Size([224]) True
2025-04-07 13:05: MLPE.blocks.2.linear.weight torch.Size([224, 224]) True
2025-04-07 13:05: MLPE.blocks.2.linear.bias torch.Size([224]) True
2025-04-07 13:05: MLPE.blocks.2.norm.weight torch.Size([224]) True
2025-04-07 13:05: MLPE.blocks.2.norm.bias torch.Size([224]) True
2025-04-07 13:05: MLPF.blocks.0.linear.weight torch.Size([12, 12]) True
2025-04-07 13:05: MLPF.blocks.0.linear.bias torch.Size([12]) True
2025-04-07 13:05: MLPF.blocks.0.norm.weight torch.Size([12]) True
2025-04-07 13:05: MLPF.blocks.0.norm.bias torch.Size([12]) True
2025-04-07 13:05: MLPF.blocks.1.linear.weight torch.Size([12, 12]) True
2025-04-07 13:05: MLPF.blocks.1.linear.bias torch.Size([12]) True
2025-04-07 13:05: MLPF.blocks.1.norm.weight torch.Size([12]) True
2025-04-07 13:05: MLPF.blocks.1.norm.bias torch.Size([12]) True
2025-04-07 13:05: steps_linear.weight torch.Size([9, 12]) True
2025-04-07 13:05: steps_linear.bias torch.Size([9]) True
2025-04-07 13:05: out_linear.weight torch.Size([1, 224]) True
2025-04-07 13:05: out_linear.bias torch.Size([1]) True
2025-04-07 13:05: Total params num: 217470
2025-04-07 13:05: *****************Finish Parameter****************
2025-04-07 13:05: Train Epoch 1: 0/159 Loss: 61.145596
2025-04-07 13:05: Train Epoch 1: 20/159 Loss: 12.634420
2025-04-07 13:05: Train Epoch 1: 40/159 Loss: 8.501131
2025-04-07 13:05: Train Epoch 1: 60/159 Loss: 8.346980
2025-04-07 13:05: Train Epoch 1: 80/159 Loss: 7.311011
2025-04-07 13:05: Train Epoch 1: 100/159 Loss: 7.177951
2025-04-07 13:05: Train Epoch 1: 120/159 Loss: 5.658999
2025-04-07 13:05: Train Epoch 1: 140/159 Loss: 5.728944
2025-04-07 13:05: **********Train Epoch 1: Average Loss: 9.143604
2025-04-07 13:05: **********Train Epoch 1: MAE: 9.143604 RMSE: 12.931816 MAPE: 0.142934
2025-04-07 13:05: **********Val Epoch 1: Average Loss: 3.855627
2025-04-07 13:05: **********Val Epoch 1: MAE: 3.855627 RMSE: 7.832091 MAPE: 0.068638
2025-04-07 13:05: *********************************Current best model saved!
2025-04-07 13:05: Train Epoch 1: 0/159 Loss: 5.516938
2025-04-07 13:05: Train Epoch 1: 20/159 Loss: 5.406407
2025-04-07 13:05: Train Epoch 1: 40/159 Loss: 4.896151
2025-04-07 13:05: Train Epoch 1: 60/159 Loss: 4.793119
2025-04-07 13:05: Train Epoch 1: 80/159 Loss: 4.172186
2025-04-07 13:05: Train Epoch 1: 100/159 Loss: 4.607727
2025-04-07 13:05: Train Epoch 1: 120/159 Loss: 4.972310
2025-04-07 13:05: Train Epoch 1: 140/159 Loss: 4.217640
2025-04-07 13:05: **********Train Epoch 1: Average Loss: 4.772577
2025-04-07 13:05: **********Train Epoch 1: MAE: 4.772577 RMSE: 7.977733 MAPE: 0.081853
2025-04-07 13:05: **********Val Epoch 1: Average Loss: 3.041785
2025-04-07 13:05: **********Val Epoch 1: MAE: 3.041785 RMSE: 6.451424 MAPE: 0.056499
2025-04-07 13:05: *********************************Current best model saved!
2025-04-07 13:05: Total training time: 0.9455min, best loss: 3.041785
2025-04-07 13:07: Experiment log path in: /data/zm/2025code/log/in12_out9
2025-04-07 13:07: Train: (10183, 12, 39, 3), (10183, 9, 39, 3)
2025-04-07 13:07: Val: (3394, 12, 39, 3), (3394, 9, 39, 3)
2025-04-07 13:07: Test: (3395, 12, 39, 3), (3395, 9, 39, 3)
2025-04-07 13:07: memory_usage: (0.837890625, 2.0)
2025-04-07 13:07: Applying learning rate decay.
2025-04-07 13:07: *****************Model Parameter*****************
2025-04-07 13:07: data_l torch.Size([96]) True
2025-04-07 13:07: tod_embedding.weight torch.Size([288, 32]) True
2025-04-07 13:07: dow_embedding.weight torch.Size([7, 32]) True
2025-04-07 13:07: SpatialEmbedding.B_sp torch.Size([307, 32]) True
2025-04-07 13:07: SpatialEmbedding.B_su torch.Size([307, 32]) True
2025-04-07 13:07: data_embedding.weight torch.Size([96, 1]) True
2025-04-07 13:07: data_embedding.bias torch.Size([96]) True
2025-04-07 13:07: MLPA.blocks.0.linear.weight torch.Size([64, 64]) True
2025-04-07 13:07: MLPA.blocks.0.linear.bias torch.Size([64]) True
2025-04-07 13:07: MLPA.blocks.0.norm.weight torch.Size([64]) True
2025-04-07 13:07: MLPA.blocks.0.norm.bias torch.Size([64]) True
2025-04-07 13:07: MLPB.blocks.0.linear.weight torch.Size([64, 64]) True
2025-04-07 13:07: MLPB.blocks.0.linear.bias torch.Size([64]) True
2025-04-07 13:07: MLPB.blocks.0.norm.weight torch.Size([64]) True
2025-04-07 13:07: MLPB.blocks.0.norm.bias torch.Size([64]) True
2025-04-07 13:07: MLPC.blocks.0.linear.weight torch.Size([96, 96]) True
2025-04-07 13:07: MLPC.blocks.0.linear.bias torch.Size([96]) True
2025-04-07 13:07: MLPC.blocks.0.norm.weight torch.Size([96]) True
2025-04-07 13:07: MLPC.blocks.0.norm.bias torch.Size([96]) True
2025-04-07 13:07: MLPD.blocks.0.linear.weight torch.Size([128, 128]) True
2025-04-07 13:07: MLPD.blocks.0.linear.bias torch.Size([128]) True
2025-04-07 13:07: MLPD.blocks.0.norm.weight torch.Size([128]) True
2025-04-07 13:07: MLPD.blocks.0.norm.bias torch.Size([128]) True
2025-04-07 13:07: MLPE.blocks.0.linear.weight torch.Size([224, 224]) True
2025-04-07 13:07: MLPE.blocks.0.linear.bias torch.Size([224]) True
2025-04-07 13:07: MLPE.blocks.0.norm.weight torch.Size([224]) True
2025-04-07 13:07: MLPE.blocks.0.norm.bias torch.Size([224]) True
2025-04-07 13:07: MLPE.blocks.1.linear.weight torch.Size([224, 224]) True
2025-04-07 13:07: MLPE.blocks.1.linear.bias torch.Size([224]) True
2025-04-07 13:07: MLPE.blocks.1.norm.weight torch.Size([224]) True
2025-04-07 13:07: MLPE.blocks.1.norm.bias torch.Size([224]) True
2025-04-07 13:07: MLPE.blocks.2.linear.weight torch.Size([224, 224]) True
2025-04-07 13:07: MLPE.blocks.2.linear.bias torch.Size([224]) True
2025-04-07 13:07: MLPE.blocks.2.norm.weight torch.Size([224]) True
2025-04-07 13:07: MLPE.blocks.2.norm.bias torch.Size([224]) True
2025-04-07 13:07: MLPF.blocks.0.linear.weight torch.Size([12, 12]) True
2025-04-07 13:07: MLPF.blocks.0.linear.bias torch.Size([12]) True
2025-04-07 13:07: MLPF.blocks.0.norm.weight torch.Size([12]) True
2025-04-07 13:07: MLPF.blocks.0.norm.bias torch.Size([12]) True
2025-04-07 13:07: MLPF.blocks.1.linear.weight torch.Size([12, 12]) True
2025-04-07 13:07: MLPF.blocks.1.linear.bias torch.Size([12]) True
2025-04-07 13:07: MLPF.blocks.1.norm.weight torch.Size([12]) True
2025-04-07 13:07: MLPF.blocks.1.norm.bias torch.Size([12]) True
2025-04-07 13:07: steps_linear.weight torch.Size([9, 12]) True
2025-04-07 13:07: steps_linear.bias torch.Size([9]) True
2025-04-07 13:07: out_linear.weight torch.Size([1, 224]) True
2025-04-07 13:07: out_linear.bias torch.Size([1]) True
2025-04-07 13:07: Total params num: 217470
2025-04-07 13:07: *****************Finish Parameter****************
2025-04-07 13:07: Train Epoch 1: 0/159 Loss: 61.145596
2025-04-07 13:07: Train Epoch 1: 20/159 Loss: 12.634420
2025-04-07 13:07: Train Epoch 1: 40/159 Loss: 8.501131
2025-04-07 13:07: Train Epoch 1: 60/159 Loss: 8.346980
2025-04-07 13:07: Train Epoch 1: 80/159 Loss: 7.311011
2025-04-07 13:07: Train Epoch 1: 100/159 Loss: 7.177951
2025-04-07 13:07: Train Epoch 1: 120/159 Loss: 5.658999
2025-04-07 13:07: Train Epoch 1: 140/159 Loss: 5.728944
2025-04-07 13:07: **********Train Epoch 1: Average Loss: 9.143604
2025-04-07 13:07: **********Train Epoch 1: MAE: 9.143604 RMSE: 12.931816 MAPE: 0.142934
2025-04-07 13:07: **********Val Epoch 1: Average Loss: 3.855627
2025-04-07 13:07: **********Val Epoch 1: MAE: 3.855627 RMSE: 7.832091 MAPE: 0.068638
2025-04-07 13:07: *********************************Current best model saved!
2025-04-07 13:07: Train Epoch 1: 0/159 Loss: 5.516938
2025-04-07 13:07: Train Epoch 1: 20/159 Loss: 5.406407
2025-04-07 13:07: Train Epoch 1: 40/159 Loss: 4.896151
2025-04-07 13:07: Train Epoch 1: 60/159 Loss: 4.793119
2025-04-07 13:07: Train Epoch 1: 80/159 Loss: 4.172186
2025-04-07 13:07: Train Epoch 1: 100/159 Loss: 4.607727
2025-04-07 13:07: Train Epoch 1: 120/159 Loss: 4.972310
2025-04-07 13:07: Train Epoch 1: 140/159 Loss: 4.217640
2025-04-07 13:07: **********Train Epoch 1: Average Loss: 4.772577
2025-04-07 13:07: **********Train Epoch 1: MAE: 4.772577 RMSE: 7.977733 MAPE: 0.081853
2025-04-07 13:08: **********Val Epoch 1: Average Loss: 3.041785
2025-04-07 13:08: **********Val Epoch 1: MAE: 3.041785 RMSE: 6.451424 MAPE: 0.056499
2025-04-07 13:08: *********************************Current best model saved!
2025-04-07 13:08: Total training time: 0.9572min, best loss: 3.041785
2025-04-07 13:08: Experiment log path in: /data/zm/2025code/log/in12_out9
2025-04-07 13:08: Train: (10183, 12, 39, 3), (10183, 9, 39, 3)
2025-04-07 13:08: Val: (3394, 12, 39, 3), (3394, 9, 39, 3)
2025-04-07 13:08: Test: (3395, 12, 39, 3), (3395, 9, 39, 3)
2025-04-07 13:08: memory_usage: (0.837890625, 2.0)
2025-04-07 13:08: Applying learning rate decay.
2025-04-07 13:08: *****************Model Parameter*****************
2025-04-07 13:08: data_l torch.Size([96]) True
2025-04-07 13:08: tod_embedding.weight torch.Size([288, 32]) True
2025-04-07 13:08: dow_embedding.weight torch.Size([7, 32]) True
2025-04-07 13:08: SpatialEmbedding.B_sp torch.Size([307, 32]) True
2025-04-07 13:08: SpatialEmbedding.B_su torch.Size([307, 32]) True
2025-04-07 13:08: data_embedding.weight torch.Size([96, 1]) True
2025-04-07 13:08: data_embedding.bias torch.Size([96]) True
2025-04-07 13:08: MLPA.blocks.0.linear.weight torch.Size([64, 64]) True
2025-04-07 13:08: MLPA.blocks.0.linear.bias torch.Size([64]) True
2025-04-07 13:08: MLPA.blocks.0.norm.weight torch.Size([64]) True
2025-04-07 13:08: MLPA.blocks.0.norm.bias torch.Size([64]) True
2025-04-07 13:08: MLPB.blocks.0.linear.weight torch.Size([64, 64]) True
2025-04-07 13:08: MLPB.blocks.0.linear.bias torch.Size([64]) True
2025-04-07 13:08: MLPB.blocks.0.norm.weight torch.Size([64]) True
2025-04-07 13:08: MLPB.blocks.0.norm.bias torch.Size([64]) True
2025-04-07 13:08: MLPC.blocks.0.linear.weight torch.Size([96, 96]) True
2025-04-07 13:08: MLPC.blocks.0.linear.bias torch.Size([96]) True
2025-04-07 13:08: MLPC.blocks.0.norm.weight torch.Size([96]) True
2025-04-07 13:08: MLPC.blocks.0.norm.bias torch.Size([96]) True
2025-04-07 13:08: MLPD.blocks.0.linear.weight torch.Size([128, 128]) True
2025-04-07 13:08: MLPD.blocks.0.linear.bias torch.Size([128]) True
2025-04-07 13:08: MLPD.blocks.0.norm.weight torch.Size([128]) True
2025-04-07 13:08: MLPD.blocks.0.norm.bias torch.Size([128]) True
2025-04-07 13:08: MLPE.blocks.0.linear.weight torch.Size([224, 224]) True
2025-04-07 13:08: MLPE.blocks.0.linear.bias torch.Size([224]) True
2025-04-07 13:08: MLPE.blocks.0.norm.weight torch.Size([224]) True
2025-04-07 13:08: MLPE.blocks.0.norm.bias torch.Size([224]) True
2025-04-07 13:08: MLPE.blocks.1.linear.weight torch.Size([224, 224]) True
2025-04-07 13:08: MLPE.blocks.1.linear.bias torch.Size([224]) True
2025-04-07 13:08: MLPE.blocks.1.norm.weight torch.Size([224]) True
2025-04-07 13:08: MLPE.blocks.1.norm.bias torch.Size([224]) True
2025-04-07 13:08: MLPE.blocks.2.linear.weight torch.Size([224, 224]) True
2025-04-07 13:08: MLPE.blocks.2.linear.bias torch.Size([224]) True
2025-04-07 13:08: MLPE.blocks.2.norm.weight torch.Size([224]) True
2025-04-07 13:08: MLPE.blocks.2.norm.bias torch.Size([224]) True
2025-04-07 13:08: MLPF.blocks.0.linear.weight torch.Size([12, 12]) True
2025-04-07 13:08: MLPF.blocks.0.linear.bias torch.Size([12]) True
2025-04-07 13:08: MLPF.blocks.0.norm.weight torch.Size([12]) True
2025-04-07 13:08: MLPF.blocks.0.norm.bias torch.Size([12]) True
2025-04-07 13:08: MLPF.blocks.1.linear.weight torch.Size([12, 12]) True
2025-04-07 13:08: MLPF.blocks.1.linear.bias torch.Size([12]) True
2025-04-07 13:08: MLPF.blocks.1.norm.weight torch.Size([12]) True
2025-04-07 13:08: MLPF.blocks.1.norm.bias torch.Size([12]) True
2025-04-07 13:08: steps_linear.weight torch.Size([9, 12]) True
2025-04-07 13:08: steps_linear.bias torch.Size([9]) True
2025-04-07 13:08: out_linear.weight torch.Size([1, 224]) True
2025-04-07 13:08: out_linear.bias torch.Size([1]) True
2025-04-07 13:08: Total params num: 217470
2025-04-07 13:08: *****************Finish Parameter****************
2025-04-07 13:08: Train Epoch 1: 0/159 Loss: 61.145596
2025-04-07 13:08: Train Epoch 1: 20/159 Loss: 12.634420
2025-04-07 13:08: Train Epoch 1: 40/159 Loss: 8.501131
2025-04-07 13:08: Train Epoch 1: 60/159 Loss: 8.346980
2025-04-07 13:08: Train Epoch 1: 80/159 Loss: 7.311011
2025-04-07 13:08: Train Epoch 1: 100/159 Loss: 7.177951
2025-04-07 13:08: Train Epoch 1: 120/159 Loss: 5.658999
2025-04-07 13:08: Train Epoch 1: 140/159 Loss: 5.728944
2025-04-07 13:08: **********Train Epoch 1: Average Loss: 9.143604
2025-04-07 13:08: **********Train Epoch 1: MAE: 9.143604 RMSE: 12.931816 MAPE: 0.142934
2025-04-07 13:08: **********Val Epoch 1: Average Loss: 3.855627
2025-04-07 13:08: **********Val Epoch 1: MAE: 3.855627 RMSE: 7.832091 MAPE: 0.068638
2025-04-07 13:08: *********************************Current best model saved!
2025-04-07 13:08: Train Epoch 1: 0/159 Loss: 5.516938
2025-04-07 13:08: Train Epoch 1: 20/159 Loss: 5.406407
2025-04-07 13:09: Train Epoch 1: 40/159 Loss: 4.896151
2025-04-07 13:09: Train Epoch 1: 60/159 Loss: 4.793119
2025-04-07 13:09: Train Epoch 1: 80/159 Loss: 4.172186
2025-04-07 13:09: Train Epoch 1: 100/159 Loss: 4.607727
2025-04-07 13:09: Train Epoch 1: 120/159 Loss: 4.972310
2025-04-07 13:09: Train Epoch 1: 140/159 Loss: 4.217640
2025-04-07 13:09: **********Train Epoch 1: Average Loss: 4.772577
2025-04-07 13:09: **********Train Epoch 1: MAE: 4.772577 RMSE: 7.977733 MAPE: 0.081853
2025-04-07 13:09: **********Val Epoch 1: Average Loss: 3.041785
2025-04-07 13:09: **********Val Epoch 1: MAE: 3.041785 RMSE: 6.451424 MAPE: 0.056499
2025-04-07 13:09: *********************************Current best model saved!
2025-04-07 13:09: Total training time: 0.9530min, best loss: 3.041785
2025-04-07 13:09: Saving current best model to ./checkpoints/PeMSD4SPEED_12_9_6.pth
2025-04-07 13:09: Horizon 01, MAE: 2.1664, RMSE: 4.5377, MAPE: 6.0942%
2025-04-07 13:09: Horizon 02, MAE: 2.5810, RMSE: 4.7971, MAPE: 6.6945%
2025-04-07 13:09: Horizon 03, MAE: 3.7376, RMSE: 7.5524, MAPE: 10.1429%
2025-04-07 13:09: Horizon 04, MAE: 3.2583, RMSE: 6.8817, MAPE: 9.1022%
2025-04-07 13:09: Horizon 05, MAE: 3.1541, RMSE: 6.3639, MAPE: 8.4257%
2025-04-07 13:09: Horizon 06, MAE: 2.6080, RMSE: 5.6984, MAPE: 7.3329%
2025-04-07 13:09: Horizon 07, MAE: 2.7466, RMSE: 6.3552, MAPE: 8.0390%
2025-04-07 13:09: Horizon 08, MAE: 2.9466, RMSE: 5.9533, MAPE: 7.7564%
2025-04-07 13:09: Horizon 09, MAE: 3.7346, RMSE: 8.0102, MAPE: 10.3384%
2025-04-07 13:09: Average Horizon, MAE: 2.9926, RMSE: 6.3330, MAPE: 8.2140%
