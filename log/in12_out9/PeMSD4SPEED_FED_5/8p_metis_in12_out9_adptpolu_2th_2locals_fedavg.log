2025-04-07 12:47: Experiment log path in: /data/zm/2025code/log/in12_out9
2025-04-07 12:47: Train: (10183, 12, 38, 3), (10183, 9, 38, 3)
2025-04-07 12:47: Val: (3394, 12, 38, 3), (3394, 9, 38, 3)
2025-04-07 12:47: Test: (3395, 12, 38, 3), (3395, 9, 38, 3)
2025-04-07 12:47: memory_usage: (0.837890625, 2.0)
2025-04-07 12:47: Applying learning rate decay.
2025-04-07 12:47: *****************Model Parameter*****************
2025-04-07 12:47: data_l torch.Size([96]) True
2025-04-07 12:47: tod_embedding.weight torch.Size([288, 32]) True
2025-04-07 12:47: dow_embedding.weight torch.Size([7, 32]) True
2025-04-07 12:47: SpatialEmbedding.B_sp torch.Size([307, 32]) True
2025-04-07 12:47: SpatialEmbedding.B_su torch.Size([307, 32]) True
2025-04-07 12:47: data_embedding.weight torch.Size([96, 1]) True
2025-04-07 12:47: data_embedding.bias torch.Size([96]) True
2025-04-07 12:47: MLPA.blocks.0.linear.weight torch.Size([64, 64]) True
2025-04-07 12:47: MLPA.blocks.0.linear.bias torch.Size([64]) True
2025-04-07 12:47: MLPA.blocks.0.norm.weight torch.Size([64]) True
2025-04-07 12:47: MLPA.blocks.0.norm.bias torch.Size([64]) True
2025-04-07 12:47: MLPB.blocks.0.linear.weight torch.Size([64, 64]) True
2025-04-07 12:47: MLPB.blocks.0.linear.bias torch.Size([64]) True
2025-04-07 12:47: MLPB.blocks.0.norm.weight torch.Size([64]) True
2025-04-07 12:47: MLPB.blocks.0.norm.bias torch.Size([64]) True
2025-04-07 12:47: MLPC.blocks.0.linear.weight torch.Size([96, 96]) True
2025-04-07 12:47: MLPC.blocks.0.linear.bias torch.Size([96]) True
2025-04-07 12:47: MLPC.blocks.0.norm.weight torch.Size([96]) True
2025-04-07 12:47: MLPC.blocks.0.norm.bias torch.Size([96]) True
2025-04-07 12:47: MLPD.blocks.0.linear.weight torch.Size([128, 128]) True
2025-04-07 12:47: MLPD.blocks.0.linear.bias torch.Size([128]) True
2025-04-07 12:47: MLPD.blocks.0.norm.weight torch.Size([128]) True
2025-04-07 12:47: MLPD.blocks.0.norm.bias torch.Size([128]) True
2025-04-07 12:47: MLPE.blocks.0.linear.weight torch.Size([224, 224]) True
2025-04-07 12:47: MLPE.blocks.0.linear.bias torch.Size([224]) True
2025-04-07 12:47: MLPE.blocks.0.norm.weight torch.Size([224]) True
2025-04-07 12:47: MLPE.blocks.0.norm.bias torch.Size([224]) True
2025-04-07 12:47: MLPE.blocks.1.linear.weight torch.Size([224, 224]) True
2025-04-07 12:47: MLPE.blocks.1.linear.bias torch.Size([224]) True
2025-04-07 12:47: MLPE.blocks.1.norm.weight torch.Size([224]) True
2025-04-07 12:47: MLPE.blocks.1.norm.bias torch.Size([224]) True
2025-04-07 12:47: MLPE.blocks.2.linear.weight torch.Size([224, 224]) True
2025-04-07 12:47: MLPE.blocks.2.linear.bias torch.Size([224]) True
2025-04-07 12:47: MLPE.blocks.2.norm.weight torch.Size([224]) True
2025-04-07 12:47: MLPE.blocks.2.norm.bias torch.Size([224]) True
2025-04-07 12:47: MLPF.blocks.0.linear.weight torch.Size([12, 12]) True
2025-04-07 12:47: MLPF.blocks.0.linear.bias torch.Size([12]) True
2025-04-07 12:47: MLPF.blocks.0.norm.weight torch.Size([12]) True
2025-04-07 12:47: MLPF.blocks.0.norm.bias torch.Size([12]) True
2025-04-07 12:47: MLPF.blocks.1.linear.weight torch.Size([12, 12]) True
2025-04-07 12:47: MLPF.blocks.1.linear.bias torch.Size([12]) True
2025-04-07 12:47: MLPF.blocks.1.norm.weight torch.Size([12]) True
2025-04-07 12:47: MLPF.blocks.1.norm.bias torch.Size([12]) True
2025-04-07 12:47: steps_linear.weight torch.Size([9, 12]) True
2025-04-07 12:47: steps_linear.bias torch.Size([9]) True
2025-04-07 12:47: out_linear.weight torch.Size([1, 224]) True
2025-04-07 12:47: out_linear.bias torch.Size([1]) True
2025-04-07 12:47: Total params num: 217470
2025-04-07 12:47: *****************Finish Parameter****************
2025-04-07 12:47: Train Epoch 1: 0/159 Loss: 68.726891
2025-04-07 12:47: Train Epoch 1: 20/159 Loss: 14.019497
2025-04-07 12:47: Train Epoch 1: 40/159 Loss: 9.392509
2025-04-07 12:47: Train Epoch 1: 60/159 Loss: 9.279954
2025-04-07 12:48: Train Epoch 1: 80/159 Loss: 8.143241
2025-04-07 12:48: Train Epoch 1: 100/159 Loss: 8.105646
2025-04-07 12:48: Train Epoch 1: 120/159 Loss: 6.227976
2025-04-07 12:48: Train Epoch 1: 140/159 Loss: 6.490304
2025-04-07 12:48: **********Train Epoch 1: Average Loss: 10.228516
2025-04-07 12:48: **********Train Epoch 1: MAE: 10.228516 RMSE: 14.448594 MAPE: 0.162561
2025-04-07 12:48: **********Val Epoch 1: Average Loss: 4.193173
2025-04-07 12:48: **********Val Epoch 1: MAE: 4.193173 RMSE: 8.503223 MAPE: 0.078031
2025-04-07 12:48: *********************************Current best model saved!
2025-04-07 12:48: Train Epoch 1: 0/159 Loss: 6.124937
2025-04-07 12:48: Train Epoch 1: 20/159 Loss: 5.803320
2025-04-07 12:48: Train Epoch 1: 40/159 Loss: 5.307498
2025-04-07 12:48: Train Epoch 1: 60/159 Loss: 5.443175
2025-04-07 12:48: Train Epoch 1: 80/159 Loss: 4.635917
2025-04-07 12:48: Train Epoch 1: 100/159 Loss: 4.825020
2025-04-07 12:48: Train Epoch 1: 120/159 Loss: 5.631217
2025-04-07 12:48: Train Epoch 1: 140/159 Loss: 4.923253
2025-04-07 12:49: **********Train Epoch 1: Average Loss: 5.316145
2025-04-07 12:49: **********Train Epoch 1: MAE: 5.316145 RMSE: 8.905841 MAPE: 0.094242
2025-04-07 12:49: **********Val Epoch 1: Average Loss: 3.342114
2025-04-07 12:49: **********Val Epoch 1: MAE: 3.342114 RMSE: 7.199475 MAPE: 0.065039
2025-04-07 12:49: *********************************Current best model saved!
2025-04-07 12:49: Train Epoch 2: 0/159 Loss: 4.916002
2025-04-07 12:49: Train Epoch 2: 20/159 Loss: 4.547178
2025-04-07 12:49: Train Epoch 2: 40/159 Loss: 3.569541
2025-04-07 12:49: Train Epoch 2: 60/159 Loss: 3.712774
2025-04-07 12:49: Train Epoch 2: 80/159 Loss: 3.470375
2025-04-07 12:49: Train Epoch 2: 100/159 Loss: 3.396903
2025-04-07 12:49: Train Epoch 2: 120/159 Loss: 3.144819
2025-04-07 12:49: Train Epoch 2: 140/159 Loss: 3.087095
2025-04-07 12:49: **********Train Epoch 2: Average Loss: 3.720687
2025-04-07 12:49: **********Train Epoch 2: MAE: 3.720687 RMSE: 6.374453 MAPE: 0.069739
2025-04-07 12:49: **********Val Epoch 2: Average Loss: 2.210771
2025-04-07 12:49: **********Val Epoch 2: MAE: 2.210771 RMSE: 4.777020 MAPE: 0.045165
2025-04-07 12:49: *********************************Current best model saved!
2025-04-07 12:49: Train Epoch 2: 0/159 Loss: 3.000442
2025-04-07 12:49: Train Epoch 2: 20/159 Loss: 2.761969
2025-04-07 12:49: Train Epoch 2: 40/159 Loss: 2.761848
2025-04-07 12:50: Train Epoch 2: 60/159 Loss: 2.361880
2025-04-07 12:50: Train Epoch 2: 80/159 Loss: 2.507256
2025-04-07 12:50: Train Epoch 2: 100/159 Loss: 2.261138
2025-04-07 12:50: Train Epoch 2: 120/159 Loss: 1.922764
2025-04-07 12:50: Train Epoch 2: 140/159 Loss: 2.461666
2025-04-07 12:50: **********Train Epoch 2: Average Loss: 2.499537
2025-04-07 12:50: **********Train Epoch 2: MAE: 2.499537 RMSE: 4.725251 MAPE: 0.048710
2025-04-07 12:50: **********Val Epoch 2: Average Loss: 1.922503
2025-04-07 12:50: **********Val Epoch 2: MAE: 1.922503 RMSE: 4.136615 MAPE: 0.038489
2025-04-07 12:50: *********************************Current best model saved!
2025-04-07 12:50: Train Epoch 3: 0/159 Loss: 2.612907
2025-04-07 12:50: Train Epoch 3: 20/159 Loss: 3.183867
2025-04-07 12:50: Train Epoch 3: 40/159 Loss: 2.305716
2025-04-07 12:50: Train Epoch 3: 60/159 Loss: 2.144228
2025-04-07 12:50: Train Epoch 3: 80/159 Loss: 2.207843
2025-04-07 12:50: Train Epoch 3: 100/159 Loss: 1.955817
2025-04-07 12:50: Train Epoch 3: 120/159 Loss: 1.794035
2025-04-07 12:51: Train Epoch 3: 140/159 Loss: 1.892583
2025-04-07 12:51: **********Train Epoch 3: Average Loss: 2.409957
2025-04-07 12:51: **********Train Epoch 3: MAE: 2.409957 RMSE: 4.514419 MAPE: 0.046731
2025-04-07 12:51: **********Val Epoch 3: Average Loss: 1.762671
2025-04-07 12:51: **********Val Epoch 3: MAE: 1.762671 RMSE: 4.044465 MAPE: 0.035894
2025-04-07 12:51: *********************************Current best model saved!
2025-04-07 12:51: Train Epoch 3: 0/159 Loss: 1.900581
2025-04-07 12:51: Train Epoch 3: 20/159 Loss: 2.297915
2025-04-07 12:51: Train Epoch 3: 40/159 Loss: 2.196673
2025-04-07 12:51: Train Epoch 3: 60/159 Loss: 1.772589
2025-04-07 12:51: Train Epoch 3: 80/159 Loss: 1.587777
2025-04-07 12:51: Train Epoch 3: 100/159 Loss: 1.897184
2025-04-07 12:51: Train Epoch 3: 120/159 Loss: 1.804031
