2025-04-07 12:47: Experiment log path in: /data/zm/2025code/log/in12_out9
2025-04-07 12:47: Train: (10183, 12, 39, 3), (10183, 9, 39, 3)
2025-04-07 12:47: Val: (3394, 12, 39, 3), (3394, 9, 39, 3)
2025-04-07 12:47: Test: (3395, 12, 39, 3), (3395, 9, 39, 3)
2025-04-07 12:47: memory_usage: (0.837890625, 2.0)
2025-04-07 12:47: Applying learning rate decay.
2025-04-07 12:47: *****************Model Parameter*****************
2025-04-07 12:47: data_l torch.Size([96]) True
2025-04-07 12:47: tod_embedding.weight torch.Size([288, 32]) True
2025-04-07 12:47: dow_embedding.weight torch.Size([7, 32]) True
2025-04-07 12:47: SpatialEmbedding.B_sp torch.Size([307, 32]) True
2025-04-07 12:47: SpatialEmbedding.B_su torch.Size([307, 32]) True
2025-04-07 12:47: data_embedding.weight torch.Size([96, 1]) True
2025-04-07 12:47: data_embedding.bias torch.Size([96]) True
2025-04-07 12:47: MLPA.blocks.0.linear.weight torch.Size([64, 64]) True
2025-04-07 12:47: MLPA.blocks.0.linear.bias torch.Size([64]) True
2025-04-07 12:47: MLPA.blocks.0.norm.weight torch.Size([64]) True
2025-04-07 12:47: MLPA.blocks.0.norm.bias torch.Size([64]) True
2025-04-07 12:47: MLPB.blocks.0.linear.weight torch.Size([64, 64]) True
2025-04-07 12:47: MLPB.blocks.0.linear.bias torch.Size([64]) True
2025-04-07 12:47: MLPB.blocks.0.norm.weight torch.Size([64]) True
2025-04-07 12:47: MLPB.blocks.0.norm.bias torch.Size([64]) True
2025-04-07 12:47: MLPC.blocks.0.linear.weight torch.Size([96, 96]) True
2025-04-07 12:47: MLPC.blocks.0.linear.bias torch.Size([96]) True
2025-04-07 12:47: MLPC.blocks.0.norm.weight torch.Size([96]) True
2025-04-07 12:47: MLPC.blocks.0.norm.bias torch.Size([96]) True
2025-04-07 12:47: MLPD.blocks.0.linear.weight torch.Size([128, 128]) True
2025-04-07 12:47: MLPD.blocks.0.linear.bias torch.Size([128]) True
2025-04-07 12:47: MLPD.blocks.0.norm.weight torch.Size([128]) True
2025-04-07 12:47: MLPD.blocks.0.norm.bias torch.Size([128]) True
2025-04-07 12:47: MLPE.blocks.0.linear.weight torch.Size([224, 224]) True
2025-04-07 12:47: MLPE.blocks.0.linear.bias torch.Size([224]) True
2025-04-07 12:47: MLPE.blocks.0.norm.weight torch.Size([224]) True
2025-04-07 12:47: MLPE.blocks.0.norm.bias torch.Size([224]) True
2025-04-07 12:47: MLPE.blocks.1.linear.weight torch.Size([224, 224]) True
2025-04-07 12:47: MLPE.blocks.1.linear.bias torch.Size([224]) True
2025-04-07 12:47: MLPE.blocks.1.norm.weight torch.Size([224]) True
2025-04-07 12:47: MLPE.blocks.1.norm.bias torch.Size([224]) True
2025-04-07 12:47: MLPE.blocks.2.linear.weight torch.Size([224, 224]) True
2025-04-07 12:47: MLPE.blocks.2.linear.bias torch.Size([224]) True
2025-04-07 12:47: MLPE.blocks.2.norm.weight torch.Size([224]) True
2025-04-07 12:47: MLPE.blocks.2.norm.bias torch.Size([224]) True
2025-04-07 12:47: MLPF.blocks.0.linear.weight torch.Size([12, 12]) True
2025-04-07 12:47: MLPF.blocks.0.linear.bias torch.Size([12]) True
2025-04-07 12:47: MLPF.blocks.0.norm.weight torch.Size([12]) True
2025-04-07 12:47: MLPF.blocks.0.norm.bias torch.Size([12]) True
2025-04-07 12:47: MLPF.blocks.1.linear.weight torch.Size([12, 12]) True
2025-04-07 12:47: MLPF.blocks.1.linear.bias torch.Size([12]) True
2025-04-07 12:47: MLPF.blocks.1.norm.weight torch.Size([12]) True
2025-04-07 12:47: MLPF.blocks.1.norm.bias torch.Size([12]) True
2025-04-07 12:47: steps_linear.weight torch.Size([9, 12]) True
2025-04-07 12:47: steps_linear.bias torch.Size([9]) True
2025-04-07 12:47: out_linear.weight torch.Size([1, 224]) True
2025-04-07 12:47: out_linear.bias torch.Size([1]) True
2025-04-07 12:47: Total params num: 217470
2025-04-07 12:47: *****************Finish Parameter****************
2025-04-07 12:47: Train Epoch 1: 0/159 Loss: 42.045288
2025-04-07 12:47: Train Epoch 1: 20/159 Loss: 8.550679
2025-04-07 12:47: Train Epoch 1: 40/159 Loss: 5.937626
2025-04-07 12:47: Train Epoch 1: 60/159 Loss: 5.764762
2025-04-07 12:48: Train Epoch 1: 80/159 Loss: 5.059196
2025-04-07 12:48: Train Epoch 1: 100/159 Loss: 4.911646
2025-04-07 12:48: Train Epoch 1: 120/159 Loss: 3.946990
2025-04-07 12:48: Train Epoch 1: 140/159 Loss: 3.996039
2025-04-07 12:48: **********Train Epoch 1: Average Loss: 6.354800
2025-04-07 12:48: **********Train Epoch 1: MAE: 6.354800 RMSE: 8.933545 MAPE: 0.099028
2025-04-07 12:48: **********Val Epoch 1: Average Loss: 2.746859
2025-04-07 12:48: **********Val Epoch 1: MAE: 2.746859 RMSE: 5.450007 MAPE: 0.046176
2025-04-07 12:48: *********************************Current best model saved!
2025-04-07 12:48: Train Epoch 1: 0/159 Loss: 3.853873
2025-04-07 12:48: Train Epoch 1: 20/159 Loss: 3.729018
2025-04-07 12:48: Train Epoch 1: 40/159 Loss: 3.416988
2025-04-07 12:48: Train Epoch 1: 60/159 Loss: 3.369370
2025-04-07 12:48: Train Epoch 1: 80/159 Loss: 2.933887
2025-04-07 12:48: Train Epoch 1: 100/159 Loss: 3.092708
2025-04-07 12:48: Train Epoch 1: 120/159 Loss: 3.468787
2025-04-07 12:48: Train Epoch 1: 140/159 Loss: 2.859216
2025-04-07 12:49: **********Train Epoch 1: Average Loss: 3.290859
2025-04-07 12:49: **********Train Epoch 1: MAE: 3.290859 RMSE: 5.555380 MAPE: 0.054095
2025-04-07 12:49: **********Val Epoch 1: Average Loss: 2.055054
2025-04-07 12:49: **********Val Epoch 1: MAE: 2.055054 RMSE: 4.588377 MAPE: 0.035640
2025-04-07 12:49: *********************************Current best model saved!
2025-04-07 12:49: Train Epoch 2: 0/159 Loss: 3.109115
2025-04-07 12:49: Train Epoch 2: 20/159 Loss: 2.571643
2025-04-07 12:49: Train Epoch 2: 40/159 Loss: 2.294266
2025-04-07 12:49: Train Epoch 2: 60/159 Loss: 2.279744
2025-04-07 12:49: Train Epoch 2: 80/159 Loss: 2.118265
2025-04-07 12:49: Train Epoch 2: 100/159 Loss: 2.230370
2025-04-07 12:49: Train Epoch 2: 120/159 Loss: 2.028356
2025-04-07 12:49: Train Epoch 2: 140/159 Loss: 1.906647
2025-04-07 12:49: **********Train Epoch 2: Average Loss: 2.313082
2025-04-07 12:49: **********Train Epoch 2: MAE: 2.313082 RMSE: 4.224022 MAPE: 0.039274
2025-04-07 12:49: **********Val Epoch 2: Average Loss: 1.547402
2025-04-07 12:49: **********Val Epoch 2: MAE: 1.547402 RMSE: 3.494604 MAPE: 0.027708
2025-04-07 12:49: *********************************Current best model saved!
2025-04-07 12:49: Train Epoch 2: 0/159 Loss: 1.829269
2025-04-07 12:49: Train Epoch 2: 20/159 Loss: 1.724330
2025-04-07 12:49: Train Epoch 2: 40/159 Loss: 1.774196
2025-04-07 12:50: Train Epoch 2: 60/159 Loss: 1.653445
2025-04-07 12:50: Train Epoch 2: 80/159 Loss: 1.609274
2025-04-07 12:50: Train Epoch 2: 100/159 Loss: 1.584928
2025-04-07 12:50: Train Epoch 2: 120/159 Loss: 1.343686
2025-04-07 12:50: Train Epoch 2: 140/159 Loss: 1.563887
2025-04-07 12:50: **********Train Epoch 2: Average Loss: 1.653426
2025-04-07 12:50: **********Train Epoch 2: MAE: 1.653426 RMSE: 3.394170 MAPE: 0.028995
2025-04-07 12:50: **********Val Epoch 2: Average Loss: 1.356486
2025-04-07 12:50: **********Val Epoch 2: MAE: 1.356486 RMSE: 3.121699 MAPE: 0.024644
2025-04-07 12:50: *********************************Current best model saved!
2025-04-07 12:50: Train Epoch 3: 0/159 Loss: 1.766187
2025-04-07 12:50: Train Epoch 3: 20/159 Loss: 2.012522
2025-04-07 12:50: Train Epoch 3: 40/159 Loss: 1.533639
2025-04-07 12:50: Train Epoch 3: 60/159 Loss: 1.412097
2025-04-07 12:50: Train Epoch 3: 80/159 Loss: 1.442621
2025-04-07 12:50: Train Epoch 3: 100/159 Loss: 1.418455
2025-04-07 12:50: Train Epoch 3: 120/159 Loss: 1.299799
2025-04-07 12:51: Train Epoch 3: 140/159 Loss: 1.349684
2025-04-07 12:51: **********Train Epoch 3: Average Loss: 1.627040
2025-04-07 12:51: **********Train Epoch 3: MAE: 1.627040 RMSE: 3.192082 MAPE: 0.028454
2025-04-07 12:51: **********Val Epoch 3: Average Loss: 1.284158
2025-04-07 12:51: **********Val Epoch 3: MAE: 1.284158 RMSE: 2.916684 MAPE: 0.023339
2025-04-07 12:51: *********************************Current best model saved!
2025-04-07 12:51: Train Epoch 3: 0/159 Loss: 1.283000
2025-04-07 12:51: Train Epoch 3: 20/159 Loss: 1.584294
2025-04-07 12:51: Train Epoch 3: 40/159 Loss: 1.456670
2025-04-07 12:51: Train Epoch 3: 60/159 Loss: 1.306202
2025-04-07 12:51: Train Epoch 3: 80/159 Loss: 1.133433
2025-04-07 12:51: Train Epoch 3: 100/159 Loss: 1.298787
2025-04-07 12:51: Train Epoch 3: 120/159 Loss: 1.340128
