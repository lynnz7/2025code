2025-04-07 12:47: Experiment log path in: /data/zm/2025code/log/in12_out9
2025-04-07 12:47: Train: (10183, 12, 38, 3), (10183, 9, 38, 3)
2025-04-07 12:47: Val: (3394, 12, 38, 3), (3394, 9, 38, 3)
2025-04-07 12:47: Test: (3395, 12, 38, 3), (3395, 9, 38, 3)
2025-04-07 12:47: memory_usage: (0.837890625, 2.0)
2025-04-07 12:47: Applying learning rate decay.
2025-04-07 12:47: *****************Model Parameter*****************
2025-04-07 12:47: data_l torch.Size([96]) True
2025-04-07 12:47: tod_embedding.weight torch.Size([288, 32]) True
2025-04-07 12:47: dow_embedding.weight torch.Size([7, 32]) True
2025-04-07 12:47: SpatialEmbedding.B_sp torch.Size([307, 32]) True
2025-04-07 12:47: SpatialEmbedding.B_su torch.Size([307, 32]) True
2025-04-07 12:47: data_embedding.weight torch.Size([96, 1]) True
2025-04-07 12:47: data_embedding.bias torch.Size([96]) True
2025-04-07 12:47: MLPA.blocks.0.linear.weight torch.Size([64, 64]) True
2025-04-07 12:47: MLPA.blocks.0.linear.bias torch.Size([64]) True
2025-04-07 12:47: MLPA.blocks.0.norm.weight torch.Size([64]) True
2025-04-07 12:47: MLPA.blocks.0.norm.bias torch.Size([64]) True
2025-04-07 12:47: MLPB.blocks.0.linear.weight torch.Size([64, 64]) True
2025-04-07 12:47: MLPB.blocks.0.linear.bias torch.Size([64]) True
2025-04-07 12:47: MLPB.blocks.0.norm.weight torch.Size([64]) True
2025-04-07 12:47: MLPB.blocks.0.norm.bias torch.Size([64]) True
2025-04-07 12:47: MLPC.blocks.0.linear.weight torch.Size([96, 96]) True
2025-04-07 12:47: MLPC.blocks.0.linear.bias torch.Size([96]) True
2025-04-07 12:47: MLPC.blocks.0.norm.weight torch.Size([96]) True
2025-04-07 12:47: MLPC.blocks.0.norm.bias torch.Size([96]) True
2025-04-07 12:47: MLPD.blocks.0.linear.weight torch.Size([128, 128]) True
2025-04-07 12:47: MLPD.blocks.0.linear.bias torch.Size([128]) True
2025-04-07 12:47: MLPD.blocks.0.norm.weight torch.Size([128]) True
2025-04-07 12:47: MLPD.blocks.0.norm.bias torch.Size([128]) True
2025-04-07 12:47: MLPE.blocks.0.linear.weight torch.Size([224, 224]) True
2025-04-07 12:47: MLPE.blocks.0.linear.bias torch.Size([224]) True
2025-04-07 12:47: MLPE.blocks.0.norm.weight torch.Size([224]) True
2025-04-07 12:47: MLPE.blocks.0.norm.bias torch.Size([224]) True
2025-04-07 12:47: MLPE.blocks.1.linear.weight torch.Size([224, 224]) True
2025-04-07 12:47: MLPE.blocks.1.linear.bias torch.Size([224]) True
2025-04-07 12:47: MLPE.blocks.1.norm.weight torch.Size([224]) True
2025-04-07 12:47: MLPE.blocks.1.norm.bias torch.Size([224]) True
2025-04-07 12:47: MLPE.blocks.2.linear.weight torch.Size([224, 224]) True
2025-04-07 12:47: MLPE.blocks.2.linear.bias torch.Size([224]) True
2025-04-07 12:47: MLPE.blocks.2.norm.weight torch.Size([224]) True
2025-04-07 12:47: MLPE.blocks.2.norm.bias torch.Size([224]) True
2025-04-07 12:47: MLPF.blocks.0.linear.weight torch.Size([12, 12]) True
2025-04-07 12:47: MLPF.blocks.0.linear.bias torch.Size([12]) True
2025-04-07 12:47: MLPF.blocks.0.norm.weight torch.Size([12]) True
2025-04-07 12:47: MLPF.blocks.0.norm.bias torch.Size([12]) True
2025-04-07 12:47: MLPF.blocks.1.linear.weight torch.Size([12, 12]) True
2025-04-07 12:47: MLPF.blocks.1.linear.bias torch.Size([12]) True
2025-04-07 12:47: MLPF.blocks.1.norm.weight torch.Size([12]) True
2025-04-07 12:47: MLPF.blocks.1.norm.bias torch.Size([12]) True
2025-04-07 12:47: steps_linear.weight torch.Size([9, 12]) True
2025-04-07 12:47: steps_linear.bias torch.Size([9]) True
2025-04-07 12:47: out_linear.weight torch.Size([1, 224]) True
2025-04-07 12:47: out_linear.bias torch.Size([1]) True
2025-04-07 12:47: Total params num: 217470
2025-04-07 12:47: *****************Finish Parameter****************
2025-04-07 12:47: Train Epoch 1: 0/159 Loss: 65.589424
2025-04-07 12:47: Train Epoch 1: 20/159 Loss: 13.655357
2025-04-07 12:47: Train Epoch 1: 40/159 Loss: 9.163928
2025-04-07 12:47: Train Epoch 1: 60/159 Loss: 9.137123
2025-04-07 12:48: Train Epoch 1: 80/159 Loss: 7.879640
2025-04-07 12:48: Train Epoch 1: 100/159 Loss: 7.807212
2025-04-07 12:48: Train Epoch 1: 120/159 Loss: 6.331015
2025-04-07 12:48: Train Epoch 1: 140/159 Loss: 6.243287
2025-04-07 12:48: **********Train Epoch 1: Average Loss: 9.884232
2025-04-07 12:48: **********Train Epoch 1: MAE: 9.884232 RMSE: 13.896668 MAPE: 0.155564
2025-04-07 12:48: **********Val Epoch 1: Average Loss: 4.201629
2025-04-07 12:48: **********Val Epoch 1: MAE: 4.201629 RMSE: 8.235288 MAPE: 0.075937
2025-04-07 12:48: *********************************Current best model saved!
2025-04-07 12:48: Train Epoch 1: 0/159 Loss: 6.058083
2025-04-07 12:48: Train Epoch 1: 20/159 Loss: 5.897754
2025-04-07 12:48: Train Epoch 1: 40/159 Loss: 5.246946
2025-04-07 12:48: Train Epoch 1: 60/159 Loss: 5.367328
2025-04-07 12:48: Train Epoch 1: 80/159 Loss: 4.573376
2025-04-07 12:48: Train Epoch 1: 100/159 Loss: 4.846632
2025-04-07 12:48: Train Epoch 1: 120/159 Loss: 5.355935
2025-04-07 12:48: Train Epoch 1: 140/159 Loss: 4.800341
2025-04-07 12:49: **********Train Epoch 1: Average Loss: 5.256569
2025-04-07 12:49: **********Train Epoch 1: MAE: 5.256569 RMSE: 8.624588 MAPE: 0.091316
2025-04-07 12:49: **********Val Epoch 1: Average Loss: 3.428683
2025-04-07 12:49: **********Val Epoch 1: MAE: 3.428683 RMSE: 6.969414 MAPE: 0.064445
2025-04-07 12:49: *********************************Current best model saved!
2025-04-07 12:49: Train Epoch 2: 0/159 Loss: 4.890951
2025-04-07 12:49: Train Epoch 2: 20/159 Loss: 4.124314
2025-04-07 12:49: Train Epoch 2: 40/159 Loss: 3.512931
2025-04-07 12:49: Train Epoch 2: 60/159 Loss: 3.502963
2025-04-07 12:49: Train Epoch 2: 80/159 Loss: 3.257009
2025-04-07 12:49: Train Epoch 2: 100/159 Loss: 3.230066
2025-04-07 12:49: Train Epoch 2: 120/159 Loss: 3.244364
2025-04-07 12:49: Train Epoch 2: 140/159 Loss: 2.958978
2025-04-07 12:49: **********Train Epoch 2: Average Loss: 3.547770
2025-04-07 12:49: **********Train Epoch 2: MAE: 3.547770 RMSE: 5.970516 MAPE: 0.065325
2025-04-07 12:49: **********Val Epoch 2: Average Loss: 2.266730
2025-04-07 12:49: **********Val Epoch 2: MAE: 2.266730 RMSE: 4.541210 MAPE: 0.044742
2025-04-07 12:49: *********************************Current best model saved!
2025-04-07 12:49: Train Epoch 2: 0/159 Loss: 2.907327
2025-04-07 12:49: Train Epoch 2: 20/159 Loss: 2.656001
2025-04-07 12:49: Train Epoch 2: 40/159 Loss: 2.772385
2025-04-07 12:50: Train Epoch 2: 60/159 Loss: 2.618925
2025-04-07 12:50: Train Epoch 2: 80/159 Loss: 2.481926
2025-04-07 12:50: Train Epoch 2: 100/159 Loss: 2.408937
2025-04-07 12:50: Train Epoch 2: 120/159 Loss: 1.994681
2025-04-07 12:50: Train Epoch 2: 140/159 Loss: 2.399445
2025-04-07 12:50: **********Train Epoch 2: Average Loss: 2.519413
2025-04-07 12:50: **********Train Epoch 2: MAE: 2.519413 RMSE: 4.570662 MAPE: 0.048098
2025-04-07 12:50: **********Val Epoch 2: Average Loss: 1.977874
2025-04-07 12:50: **********Val Epoch 2: MAE: 1.977874 RMSE: 4.090422 MAPE: 0.038656
2025-04-07 12:50: *********************************Current best model saved!
2025-04-07 12:50: Train Epoch 3: 0/159 Loss: 2.702797
2025-04-07 12:50: Train Epoch 3: 20/159 Loss: 3.229676
2025-04-07 12:50: Train Epoch 3: 40/159 Loss: 2.394502
2025-04-07 12:50: Train Epoch 3: 60/159 Loss: 2.314904
2025-04-07 12:50: Train Epoch 3: 80/159 Loss: 2.237553
2025-04-07 12:50: Train Epoch 3: 100/159 Loss: 2.101612
2025-04-07 12:50: Train Epoch 3: 120/159 Loss: 2.000645
2025-04-07 12:51: Train Epoch 3: 140/159 Loss: 2.014324
2025-04-07 12:51: **********Train Epoch 3: Average Loss: 2.517580
2025-04-07 12:51: **********Train Epoch 3: MAE: 2.517580 RMSE: 4.478485 MAPE: 0.047797
2025-04-07 12:51: **********Val Epoch 3: Average Loss: 1.928384
2025-04-07 12:51: **********Val Epoch 3: MAE: 1.928384 RMSE: 3.964532 MAPE: 0.037694
2025-04-07 12:51: *********************************Current best model saved!
2025-04-07 12:51: Train Epoch 3: 0/159 Loss: 2.057737
2025-04-07 12:51: Train Epoch 3: 20/159 Loss: 2.349294
2025-04-07 12:51: Train Epoch 3: 40/159 Loss: 2.113976
2025-04-07 12:51: Train Epoch 3: 60/159 Loss: 2.006478
2025-04-07 12:51: Train Epoch 3: 80/159 Loss: 1.829644
2025-04-07 12:51: Train Epoch 3: 100/159 Loss: 2.021881
2025-04-07 12:51: Train Epoch 3: 120/159 Loss: 2.131601
