2025-04-07 12:47: Experiment log path in: /data/zm/2025code/log/in12_out9
2025-04-07 12:47: Train: (10183, 12, 38, 3), (10183, 9, 38, 3)
2025-04-07 12:47: Val: (3394, 12, 38, 3), (3394, 9, 38, 3)
2025-04-07 12:47: Test: (3395, 12, 38, 3), (3395, 9, 38, 3)
2025-04-07 12:47: memory_usage: (0.837890625, 2.0)
2025-04-07 12:47: Applying learning rate decay.
2025-04-07 12:47: *****************Model Parameter*****************
2025-04-07 12:47: data_l torch.Size([96]) True
2025-04-07 12:47: tod_embedding.weight torch.Size([288, 32]) True
2025-04-07 12:47: dow_embedding.weight torch.Size([7, 32]) True
2025-04-07 12:47: SpatialEmbedding.B_sp torch.Size([307, 32]) True
2025-04-07 12:47: SpatialEmbedding.B_su torch.Size([307, 32]) True
2025-04-07 12:47: data_embedding.weight torch.Size([96, 1]) True
2025-04-07 12:47: data_embedding.bias torch.Size([96]) True
2025-04-07 12:47: MLPA.blocks.0.linear.weight torch.Size([64, 64]) True
2025-04-07 12:47: MLPA.blocks.0.linear.bias torch.Size([64]) True
2025-04-07 12:47: MLPA.blocks.0.norm.weight torch.Size([64]) True
2025-04-07 12:47: MLPA.blocks.0.norm.bias torch.Size([64]) True
2025-04-07 12:47: MLPB.blocks.0.linear.weight torch.Size([64, 64]) True
2025-04-07 12:47: MLPB.blocks.0.linear.bias torch.Size([64]) True
2025-04-07 12:47: MLPB.blocks.0.norm.weight torch.Size([64]) True
2025-04-07 12:47: MLPB.blocks.0.norm.bias torch.Size([64]) True
2025-04-07 12:47: MLPC.blocks.0.linear.weight torch.Size([96, 96]) True
2025-04-07 12:47: MLPC.blocks.0.linear.bias torch.Size([96]) True
2025-04-07 12:47: MLPC.blocks.0.norm.weight torch.Size([96]) True
2025-04-07 12:47: MLPC.blocks.0.norm.bias torch.Size([96]) True
2025-04-07 12:47: MLPD.blocks.0.linear.weight torch.Size([128, 128]) True
2025-04-07 12:47: MLPD.blocks.0.linear.bias torch.Size([128]) True
2025-04-07 12:47: MLPD.blocks.0.norm.weight torch.Size([128]) True
2025-04-07 12:47: MLPD.blocks.0.norm.bias torch.Size([128]) True
2025-04-07 12:47: MLPE.blocks.0.linear.weight torch.Size([224, 224]) True
2025-04-07 12:47: MLPE.blocks.0.linear.bias torch.Size([224]) True
2025-04-07 12:47: MLPE.blocks.0.norm.weight torch.Size([224]) True
2025-04-07 12:47: MLPE.blocks.0.norm.bias torch.Size([224]) True
2025-04-07 12:47: MLPE.blocks.1.linear.weight torch.Size([224, 224]) True
2025-04-07 12:47: MLPE.blocks.1.linear.bias torch.Size([224]) True
2025-04-07 12:47: MLPE.blocks.1.norm.weight torch.Size([224]) True
2025-04-07 12:47: MLPE.blocks.1.norm.bias torch.Size([224]) True
2025-04-07 12:47: MLPE.blocks.2.linear.weight torch.Size([224, 224]) True
2025-04-07 12:47: MLPE.blocks.2.linear.bias torch.Size([224]) True
2025-04-07 12:47: MLPE.blocks.2.norm.weight torch.Size([224]) True
2025-04-07 12:47: MLPE.blocks.2.norm.bias torch.Size([224]) True
2025-04-07 12:47: MLPF.blocks.0.linear.weight torch.Size([12, 12]) True
2025-04-07 12:47: MLPF.blocks.0.linear.bias torch.Size([12]) True
2025-04-07 12:47: MLPF.blocks.0.norm.weight torch.Size([12]) True
2025-04-07 12:47: MLPF.blocks.0.norm.bias torch.Size([12]) True
2025-04-07 12:47: MLPF.blocks.1.linear.weight torch.Size([12, 12]) True
2025-04-07 12:47: MLPF.blocks.1.linear.bias torch.Size([12]) True
2025-04-07 12:47: MLPF.blocks.1.norm.weight torch.Size([12]) True
2025-04-07 12:47: MLPF.blocks.1.norm.bias torch.Size([12]) True
2025-04-07 12:47: steps_linear.weight torch.Size([9, 12]) True
2025-04-07 12:47: steps_linear.bias torch.Size([9]) True
2025-04-07 12:47: out_linear.weight torch.Size([1, 224]) True
2025-04-07 12:47: out_linear.bias torch.Size([1]) True
2025-04-07 12:47: Total params num: 217470
2025-04-07 12:47: *****************Finish Parameter****************
2025-04-07 12:47: Train Epoch 1: 0/159 Loss: 65.589424
2025-04-07 12:47: Train Epoch 1: 20/159 Loss: 13.655357
2025-04-07 12:47: Train Epoch 1: 40/159 Loss: 9.163928
2025-04-07 12:47: Train Epoch 1: 60/159 Loss: 9.137123
2025-04-07 12:48: Train Epoch 1: 80/159 Loss: 7.879640
2025-04-07 12:48: Train Epoch 1: 100/159 Loss: 7.807212
2025-04-07 12:48: Train Epoch 1: 120/159 Loss: 6.331015
2025-04-07 12:48: Train Epoch 1: 140/159 Loss: 6.243287
2025-04-07 12:48: **********Train Epoch 1: Average Loss: 9.884232
2025-04-07 12:48: **********Train Epoch 1: MAE: 9.884232 RMSE: 13.896668 MAPE: 0.155564
2025-04-07 12:48: **********Val Epoch 1: Average Loss: 4.201629
2025-04-07 12:48: **********Val Epoch 1: MAE: 4.201629 RMSE: 8.235288 MAPE: 0.075937
2025-04-07 12:48: *********************************Current best model saved!
2025-04-07 12:48: Train Epoch 1: 0/159 Loss: 6.058083
2025-04-07 12:48: Train Epoch 1: 20/159 Loss: 5.897754
2025-04-07 12:48: Train Epoch 1: 40/159 Loss: 5.246946
2025-04-07 12:48: Train Epoch 1: 60/159 Loss: 5.367328
2025-04-07 12:48: Train Epoch 1: 80/159 Loss: 4.573376
2025-04-07 12:48: Train Epoch 1: 100/159 Loss: 4.846632
2025-04-07 12:48: Train Epoch 1: 120/159 Loss: 5.355935
2025-04-07 12:48: Train Epoch 1: 140/159 Loss: 4.800341
2025-04-07 12:49: **********Train Epoch 1: Average Loss: 5.256569
2025-04-07 12:49: **********Train Epoch 1: MAE: 5.256569 RMSE: 8.624588 MAPE: 0.091316
2025-04-07 12:49: **********Val Epoch 1: Average Loss: 3.428683
2025-04-07 12:49: **********Val Epoch 1: MAE: 3.428683 RMSE: 6.969414 MAPE: 0.064445
2025-04-07 12:49: *********************************Current best model saved!
2025-04-07 12:49: Train Epoch 2: 0/159 Loss: 4.890951
2025-04-07 12:49: Train Epoch 2: 20/159 Loss: 4.124314
2025-04-07 12:49: Train Epoch 2: 40/159 Loss: 3.512931
2025-04-07 12:49: Train Epoch 2: 60/159 Loss: 3.502963
2025-04-07 12:49: Train Epoch 2: 80/159 Loss: 3.257009
2025-04-07 12:49: Train Epoch 2: 100/159 Loss: 3.230066
2025-04-07 12:49: Train Epoch 2: 120/159 Loss: 3.244364
2025-04-07 12:49: Train Epoch 2: 140/159 Loss: 2.958978
2025-04-07 12:49: **********Train Epoch 2: Average Loss: 3.547770
2025-04-07 12:49: **********Train Epoch 2: MAE: 3.547770 RMSE: 5.970516 MAPE: 0.065325
2025-04-07 12:49: **********Val Epoch 2: Average Loss: 2.266730
2025-04-07 12:49: **********Val Epoch 2: MAE: 2.266730 RMSE: 4.541210 MAPE: 0.044742
2025-04-07 12:49: *********************************Current best model saved!
2025-04-07 12:49: Train Epoch 2: 0/159 Loss: 2.907327
2025-04-07 12:49: Train Epoch 2: 20/159 Loss: 2.656001
2025-04-07 12:49: Train Epoch 2: 40/159 Loss: 2.772385
2025-04-07 12:50: Train Epoch 2: 60/159 Loss: 2.618925
2025-04-07 12:50: Train Epoch 2: 80/159 Loss: 2.481926
2025-04-07 12:50: Train Epoch 2: 100/159 Loss: 2.408937
2025-04-07 12:50: Train Epoch 2: 120/159 Loss: 1.994681
2025-04-07 12:50: Train Epoch 2: 140/159 Loss: 2.399445
2025-04-07 12:50: **********Train Epoch 2: Average Loss: 2.519413
2025-04-07 12:50: **********Train Epoch 2: MAE: 2.519413 RMSE: 4.570662 MAPE: 0.048098
2025-04-07 12:50: **********Val Epoch 2: Average Loss: 1.977874
2025-04-07 12:50: **********Val Epoch 2: MAE: 1.977874 RMSE: 4.090422 MAPE: 0.038656
2025-04-07 12:50: *********************************Current best model saved!
2025-04-07 12:50: Train Epoch 3: 0/159 Loss: 2.702797
2025-04-07 12:50: Train Epoch 3: 20/159 Loss: 3.229676
2025-04-07 12:50: Train Epoch 3: 40/159 Loss: 2.394502
2025-04-07 12:50: Train Epoch 3: 60/159 Loss: 2.314904
2025-04-07 12:50: Train Epoch 3: 80/159 Loss: 2.237553
2025-04-07 12:50: Train Epoch 3: 100/159 Loss: 2.101612
2025-04-07 12:50: Train Epoch 3: 120/159 Loss: 2.000645
2025-04-07 12:51: Train Epoch 3: 140/159 Loss: 2.014324
2025-04-07 12:51: **********Train Epoch 3: Average Loss: 2.517580
2025-04-07 12:51: **********Train Epoch 3: MAE: 2.517580 RMSE: 4.478485 MAPE: 0.047797
2025-04-07 12:51: **********Val Epoch 3: Average Loss: 1.928384
2025-04-07 12:51: **********Val Epoch 3: MAE: 1.928384 RMSE: 3.964532 MAPE: 0.037694
2025-04-07 12:51: *********************************Current best model saved!
2025-04-07 12:51: Train Epoch 3: 0/159 Loss: 2.057737
2025-04-07 12:51: Train Epoch 3: 20/159 Loss: 2.349294
2025-04-07 12:51: Train Epoch 3: 40/159 Loss: 2.113976
2025-04-07 12:51: Train Epoch 3: 60/159 Loss: 2.006478
2025-04-07 12:51: Train Epoch 3: 80/159 Loss: 1.829644
2025-04-07 12:51: Train Epoch 3: 100/159 Loss: 2.021881
2025-04-07 12:51: Train Epoch 3: 120/159 Loss: 2.131601
2025-04-07 12:51: Train Epoch 3: 140/159 Loss: 2.069790
2025-04-07 12:51: **********Train Epoch 3: Average Loss: 2.070831
2025-04-07 12:51: **********Train Epoch 3: MAE: 2.070831 RMSE: 4.018298 MAPE: 0.039781
2025-04-07 12:51: **********Val Epoch 3: Average Loss: 1.857692
2025-04-07 12:51: **********Val Epoch 3: MAE: 1.857692 RMSE: 3.862203 MAPE: 0.035638
2025-04-07 12:51: *********************************Current best model saved!
2025-04-07 12:51: Train Epoch 4: 0/159 Loss: 1.826396
2025-04-07 12:51: Train Epoch 4: 20/159 Loss: 2.319934
2025-04-07 12:52: Train Epoch 4: 40/159 Loss: 2.022210
2025-04-07 12:52: Train Epoch 4: 60/159 Loss: 1.953312
2025-04-07 12:52: Train Epoch 4: 80/159 Loss: 2.077877
2025-04-07 12:52: Train Epoch 4: 100/159 Loss: 2.186769
2025-04-07 12:52: Train Epoch 4: 120/159 Loss: 1.947069
2025-04-07 12:52: Train Epoch 4: 140/159 Loss: 1.946097
2025-04-07 12:52: **********Train Epoch 4: Average Loss: 2.053817
2025-04-07 12:52: **********Train Epoch 4: MAE: 2.053817 RMSE: 3.997399 MAPE: 0.039512
2025-04-07 12:52: **********Val Epoch 4: Average Loss: 1.849739
2025-04-07 12:52: **********Val Epoch 4: MAE: 1.849739 RMSE: 3.876235 MAPE: 0.035862
2025-04-07 12:52: *********************************Current best model saved!
2025-04-07 12:52: Train Epoch 4: 0/159 Loss: 2.014945
2025-04-07 12:52: Train Epoch 4: 20/159 Loss: 2.084269
2025-04-07 12:52: Train Epoch 4: 40/159 Loss: 1.936248
2025-04-07 12:52: Train Epoch 4: 60/159 Loss: 1.936453
2025-04-07 12:52: Train Epoch 4: 80/159 Loss: 1.973210
2025-04-07 12:52: Train Epoch 4: 100/159 Loss: 2.069904
2025-04-07 12:53: Train Epoch 4: 120/159 Loss: 2.040925
2025-04-07 12:53: Train Epoch 4: 140/159 Loss: 1.693600
2025-04-07 12:53: **********Train Epoch 4: Average Loss: 1.902363
2025-04-07 12:53: **********Train Epoch 4: MAE: 1.902363 RMSE: 3.827288 MAPE: 0.036262
2025-04-07 12:53: **********Val Epoch 4: Average Loss: 1.806681
2025-04-07 12:53: **********Val Epoch 4: MAE: 1.806681 RMSE: 3.779427 MAPE: 0.035316
2025-04-07 12:53: *********************************Current best model saved!
2025-04-07 12:53: Train Epoch 5: 0/159 Loss: 2.191804
2025-04-07 12:53: Train Epoch 5: 20/159 Loss: 1.718564
2025-04-07 12:53: Train Epoch 5: 40/159 Loss: 1.976372
2025-04-07 12:53: Train Epoch 5: 60/159 Loss: 1.937212
2025-04-07 12:53: Train Epoch 5: 80/159 Loss: 2.032124
2025-04-07 12:53: Train Epoch 5: 100/159 Loss: 1.874218
2025-04-07 12:53: Train Epoch 5: 120/159 Loss: 1.742953
2025-04-07 12:53: Train Epoch 5: 140/159 Loss: 2.061858
2025-04-07 12:53: **********Train Epoch 5: Average Loss: 1.924346
2025-04-07 12:53: **********Train Epoch 5: MAE: 1.924346 RMSE: 3.868034 MAPE: 0.036934
2025-04-07 12:53: **********Val Epoch 5: Average Loss: 1.787453
2025-04-07 12:53: **********Val Epoch 5: MAE: 1.787453 RMSE: 3.739871 MAPE: 0.034318
2025-04-07 12:53: *********************************Current best model saved!
2025-04-07 12:53: Train Epoch 5: 0/159 Loss: 1.880910
2025-04-07 12:54: Train Epoch 5: 20/159 Loss: 1.762215
2025-04-07 12:54: Train Epoch 5: 40/159 Loss: 1.961958
2025-04-07 12:54: Train Epoch 5: 60/159 Loss: 1.795666
2025-04-07 12:54: Train Epoch 5: 80/159 Loss: 2.012781
2025-04-07 12:54: Train Epoch 5: 100/159 Loss: 1.998622
2025-04-07 12:54: Train Epoch 5: 120/159 Loss: 1.727242
2025-04-07 12:54: Train Epoch 5: 140/159 Loss: 1.445807
2025-04-07 12:54: **********Train Epoch 5: Average Loss: 1.834817
2025-04-07 12:54: **********Train Epoch 5: MAE: 1.834817 RMSE: 3.745952 MAPE: 0.034965
2025-04-07 12:54: **********Val Epoch 5: Average Loss: 1.756894
2025-04-07 12:54: **********Val Epoch 5: MAE: 1.756894 RMSE: 3.643568 MAPE: 0.033576
2025-04-07 12:54: *********************************Current best model saved!
2025-04-07 12:54: Train Epoch 6: 0/159 Loss: 2.023798
2025-04-07 12:54: Train Epoch 6: 20/159 Loss: 1.783903
2025-04-07 12:54: Train Epoch 6: 40/159 Loss: 1.829605
2025-04-07 12:54: Train Epoch 6: 60/159 Loss: 1.801767
2025-04-07 12:54: Train Epoch 6: 80/159 Loss: 1.993047
2025-04-07 12:55: Train Epoch 6: 100/159 Loss: 1.789104
2025-04-07 12:55: Train Epoch 6: 120/159 Loss: 1.958683
2025-04-07 12:55: Train Epoch 6: 140/159 Loss: 1.701894
2025-04-07 12:55: **********Train Epoch 6: Average Loss: 1.865722
2025-04-07 12:55: **********Train Epoch 6: MAE: 1.865722 RMSE: 3.802282 MAPE: 0.035643
2025-04-07 12:55: **********Val Epoch 6: Average Loss: 1.763848
2025-04-07 12:55: **********Val Epoch 6: MAE: 1.763848 RMSE: 3.669345 MAPE: 0.034003
2025-04-07 12:55: Train Epoch 6: 0/159 Loss: 1.786749
2025-04-07 12:55: Train Epoch 6: 20/159 Loss: 1.736314
2025-04-07 12:55: Train Epoch 6: 40/159 Loss: 1.815657
2025-04-07 12:55: Train Epoch 6: 60/159 Loss: 1.756914
2025-04-07 12:55: Train Epoch 6: 80/159 Loss: 1.751585
2025-04-07 12:55: Train Epoch 6: 100/159 Loss: 1.839719
2025-04-07 12:55: Train Epoch 6: 120/159 Loss: 1.718793
2025-04-07 12:55: Train Epoch 6: 140/159 Loss: 1.672536
2025-04-07 12:55: **********Train Epoch 6: Average Loss: 1.793969
2025-04-07 12:55: **********Train Epoch 6: MAE: 1.793969 RMSE: 3.690697 MAPE: 0.034098
2025-04-07 12:55: **********Val Epoch 6: Average Loss: 1.732162
2025-04-07 12:55: **********Val Epoch 6: MAE: 1.732162 RMSE: 3.606235 MAPE: 0.033167
2025-04-07 12:55: *********************************Current best model saved!
2025-04-07 12:56: Train Epoch 7: 0/159 Loss: 1.849508
2025-04-07 12:56: Train Epoch 7: 20/159 Loss: 1.888793
2025-04-07 12:56: Train Epoch 7: 40/159 Loss: 1.654198
2025-04-07 12:56: Train Epoch 7: 60/159 Loss: 1.824878
2025-04-07 12:56: Train Epoch 7: 80/159 Loss: 1.702063
2025-04-07 12:56: Train Epoch 7: 100/159 Loss: 1.920351
2025-04-07 12:56: Train Epoch 7: 120/159 Loss: 2.077653
2025-04-07 12:56: Train Epoch 7: 140/159 Loss: 2.058284
2025-04-07 12:56: **********Train Epoch 7: Average Loss: 1.818753
2025-04-07 12:56: **********Train Epoch 7: MAE: 1.818753 RMSE: 3.744869 MAPE: 0.034668
2025-04-07 12:56: **********Val Epoch 7: Average Loss: 1.734428
2025-04-07 12:56: **********Val Epoch 7: MAE: 1.734428 RMSE: 3.611555 MAPE: 0.032971
2025-04-07 12:56: Train Epoch 7: 0/159 Loss: 1.719985
2025-04-07 12:56: Train Epoch 7: 20/159 Loss: 1.873162
2025-04-07 12:56: Train Epoch 7: 40/159 Loss: 1.861921
2025-04-07 12:56: Train Epoch 7: 60/159 Loss: 1.814795
2025-04-07 12:56: Train Epoch 7: 80/159 Loss: 1.730864
2025-04-07 12:57: Train Epoch 7: 100/159 Loss: 1.881674
2025-04-07 12:57: Train Epoch 7: 120/159 Loss: 1.849336
2025-04-07 12:57: Train Epoch 7: 140/159 Loss: 1.579260
2025-04-07 12:57: **********Train Epoch 7: Average Loss: 1.762488
2025-04-07 12:57: **********Train Epoch 7: MAE: 1.762488 RMSE: 3.627805 MAPE: 0.033466
2025-04-07 12:57: **********Val Epoch 7: Average Loss: 1.710938
2025-04-07 12:57: **********Val Epoch 7: MAE: 1.710938 RMSE: 3.551829 MAPE: 0.032490
2025-04-07 12:57: *********************************Current best model saved!
2025-04-07 12:57: Train Epoch 8: 0/159 Loss: 1.692465
2025-04-07 12:57: Train Epoch 8: 20/159 Loss: 1.731768
2025-04-07 12:57: Train Epoch 8: 40/159 Loss: 1.698602
2025-04-07 12:57: Train Epoch 8: 60/159 Loss: 1.798167
2025-04-07 12:57: Train Epoch 8: 80/159 Loss: 1.673865
2025-04-07 12:57: Train Epoch 8: 100/159 Loss: 1.752818
2025-04-07 12:57: Train Epoch 8: 120/159 Loss: 1.619289
2025-04-07 12:57: Train Epoch 8: 140/159 Loss: 1.743208
2025-04-07 12:57: **********Train Epoch 8: Average Loss: 1.785140
2025-04-07 12:57: **********Train Epoch 8: MAE: 1.785140 RMSE: 3.680198 MAPE: 0.033882
2025-04-07 12:58: **********Val Epoch 8: Average Loss: 1.720261
2025-04-07 12:58: **********Val Epoch 8: MAE: 1.720261 RMSE: 3.566482 MAPE: 0.032681
2025-04-07 12:58: Train Epoch 8: 0/159 Loss: 1.845679
2025-04-07 12:58: Train Epoch 8: 20/159 Loss: 1.918185
2025-04-07 12:58: Train Epoch 8: 40/159 Loss: 1.739896
2025-04-07 12:58: Train Epoch 8: 60/159 Loss: 1.644899
2025-04-07 12:58: Train Epoch 8: 80/159 Loss: 1.708639
2025-04-07 12:58: Train Epoch 8: 100/159 Loss: 1.865927
2025-04-07 12:58: Train Epoch 8: 120/159 Loss: 1.690266
2025-04-07 12:58: Train Epoch 8: 140/159 Loss: 1.631223
2025-04-07 12:58: **********Train Epoch 8: Average Loss: 1.726047
2025-04-07 12:58: **********Train Epoch 8: MAE: 1.726047 RMSE: 3.543813 MAPE: 0.032711
2025-04-07 12:58: **********Val Epoch 8: Average Loss: 1.673094
2025-04-07 12:58: **********Val Epoch 8: MAE: 1.673094 RMSE: 3.457256 MAPE: 0.031685
2025-04-07 12:58: *********************************Current best model saved!
2025-04-07 12:58: Train Epoch 9: 0/159 Loss: 1.818850
2025-04-07 12:58: Train Epoch 9: 20/159 Loss: 1.690210
2025-04-07 12:58: Train Epoch 9: 40/159 Loss: 1.650491
2025-04-07 12:58: Train Epoch 9: 60/159 Loss: 1.728826
2025-04-07 12:59: Train Epoch 9: 80/159 Loss: 1.753379
2025-04-07 12:59: Train Epoch 9: 100/159 Loss: 1.678148
2025-04-07 12:59: Train Epoch 9: 120/159 Loss: 1.666018
2025-04-07 12:59: Train Epoch 9: 140/159 Loss: 1.568850
2025-04-07 12:59: **********Train Epoch 9: Average Loss: 1.758308
2025-04-07 12:59: **********Train Epoch 9: MAE: 1.758308 RMSE: 3.626975 MAPE: 0.033364
2025-04-07 12:59: **********Val Epoch 9: Average Loss: 1.689109
2025-04-07 12:59: **********Val Epoch 9: MAE: 1.689109 RMSE: 3.478076 MAPE: 0.032113
2025-04-07 12:59: Train Epoch 9: 0/159 Loss: 1.697092
2025-04-07 12:59: Train Epoch 9: 20/159 Loss: 1.719514
2025-04-07 12:59: Train Epoch 9: 40/159 Loss: 1.707912
2025-04-07 12:59: Train Epoch 9: 60/159 Loss: 1.639463
2025-04-07 12:59: Train Epoch 9: 80/159 Loss: 1.721465
2025-04-07 12:59: Train Epoch 9: 100/159 Loss: 1.562529
2025-04-07 12:59: Train Epoch 9: 120/159 Loss: 1.700494
2025-04-07 12:59: Train Epoch 9: 140/159 Loss: 1.685037
2025-04-07 13:00: **********Train Epoch 9: Average Loss: 1.699837
2025-04-07 13:00: **********Train Epoch 9: MAE: 1.699837 RMSE: 3.475353 MAPE: 0.032201
2025-04-07 13:00: **********Val Epoch 9: Average Loss: 1.660611
2025-04-07 13:00: **********Val Epoch 9: MAE: 1.660611 RMSE: 3.400347 MAPE: 0.031329
2025-04-07 13:00: *********************************Current best model saved!
2025-04-07 13:00: Train Epoch 10: 0/159 Loss: 1.878428
2025-04-07 13:00: Train Epoch 10: 20/159 Loss: 1.601648
2025-04-07 13:00: Train Epoch 10: 40/159 Loss: 1.642017
2025-04-07 13:00: Train Epoch 10: 60/159 Loss: 1.645319
2025-04-07 13:00: Train Epoch 10: 80/159 Loss: 1.745775
2025-04-07 13:00: Train Epoch 10: 100/159 Loss: 1.711808
2025-04-07 13:00: Train Epoch 10: 120/159 Loss: 1.544185
2025-04-07 13:00: Train Epoch 10: 140/159 Loss: 1.709502
2025-04-07 13:00: **********Train Epoch 10: Average Loss: 1.735402
2025-04-07 13:00: **********Train Epoch 10: MAE: 1.735402 RMSE: 3.572210 MAPE: 0.032904
2025-04-07 13:00: **********Val Epoch 10: Average Loss: 1.675311
2025-04-07 13:00: **********Val Epoch 10: MAE: 1.675311 RMSE: 3.424230 MAPE: 0.032049
2025-04-07 13:00: Train Epoch 10: 0/159 Loss: 1.577303
2025-04-07 13:00: Train Epoch 10: 20/159 Loss: 1.656688
2025-04-07 13:00: Train Epoch 10: 40/159 Loss: 1.410524
2025-04-07 13:01: Train Epoch 10: 60/159 Loss: 1.684470
2025-04-07 13:01: Train Epoch 10: 80/159 Loss: 1.757692
2025-04-07 13:01: Train Epoch 10: 100/159 Loss: 1.741253
2025-04-07 13:01: Train Epoch 10: 120/159 Loss: 1.659497
2025-04-07 13:01: Train Epoch 10: 140/159 Loss: 1.669726
2025-04-07 13:01: **********Train Epoch 10: Average Loss: 1.681132
2025-04-07 13:01: **********Train Epoch 10: MAE: 1.681132 RMSE: 3.423456 MAPE: 0.031827
2025-04-07 13:01: **********Val Epoch 10: Average Loss: 1.634548
2025-04-07 13:01: **********Val Epoch 10: MAE: 1.634548 RMSE: 3.334994 MAPE: 0.030989
2025-04-07 13:01: *********************************Current best model saved!
2025-04-07 13:01: Train Epoch 11: 0/159 Loss: 1.818348
2025-04-07 13:01: Train Epoch 11: 20/159 Loss: 1.698768
2025-04-07 13:01: Experiment log path in: /data/zm/2025code/log/in12_out9
2025-04-07 13:01: Train: (10183, 12, 38, 3), (10183, 9, 38, 3)
2025-04-07 13:01: Val: (3394, 12, 38, 3), (3394, 9, 38, 3)
2025-04-07 13:01: Test: (3395, 12, 38, 3), (3395, 9, 38, 3)
2025-04-07 13:01: memory_usage: (0.837890625, 2.0)
2025-04-07 13:01: Applying learning rate decay.
2025-04-07 13:01: *****************Model Parameter*****************
2025-04-07 13:01: data_l torch.Size([96]) True
2025-04-07 13:01: tod_embedding.weight torch.Size([288, 32]) True
2025-04-07 13:01: dow_embedding.weight torch.Size([7, 32]) True
2025-04-07 13:01: SpatialEmbedding.B_sp torch.Size([307, 32]) True
2025-04-07 13:01: SpatialEmbedding.B_su torch.Size([307, 32]) True
2025-04-07 13:01: data_embedding.weight torch.Size([96, 1]) True
2025-04-07 13:01: data_embedding.bias torch.Size([96]) True
2025-04-07 13:01: MLPA.blocks.0.linear.weight torch.Size([64, 64]) True
2025-04-07 13:01: MLPA.blocks.0.linear.bias torch.Size([64]) True
2025-04-07 13:01: MLPA.blocks.0.norm.weight torch.Size([64]) True
2025-04-07 13:01: MLPA.blocks.0.norm.bias torch.Size([64]) True
2025-04-07 13:01: MLPB.blocks.0.linear.weight torch.Size([64, 64]) True
2025-04-07 13:01: MLPB.blocks.0.linear.bias torch.Size([64]) True
2025-04-07 13:01: MLPB.blocks.0.norm.weight torch.Size([64]) True
2025-04-07 13:01: MLPB.blocks.0.norm.bias torch.Size([64]) True
2025-04-07 13:01: MLPC.blocks.0.linear.weight torch.Size([96, 96]) True
2025-04-07 13:01: MLPC.blocks.0.linear.bias torch.Size([96]) True
2025-04-07 13:01: MLPC.blocks.0.norm.weight torch.Size([96]) True
2025-04-07 13:01: MLPC.blocks.0.norm.bias torch.Size([96]) True
2025-04-07 13:01: MLPD.blocks.0.linear.weight torch.Size([128, 128]) True
2025-04-07 13:01: MLPD.blocks.0.linear.bias torch.Size([128]) True
2025-04-07 13:01: MLPD.blocks.0.norm.weight torch.Size([128]) True
2025-04-07 13:01: MLPD.blocks.0.norm.bias torch.Size([128]) True
2025-04-07 13:01: MLPE.blocks.0.linear.weight torch.Size([224, 224]) True
2025-04-07 13:01: MLPE.blocks.0.linear.bias torch.Size([224]) True
2025-04-07 13:01: MLPE.blocks.0.norm.weight torch.Size([224]) True
2025-04-07 13:01: MLPE.blocks.0.norm.bias torch.Size([224]) True
2025-04-07 13:01: MLPE.blocks.1.linear.weight torch.Size([224, 224]) True
2025-04-07 13:01: MLPE.blocks.1.linear.bias torch.Size([224]) True
2025-04-07 13:01: MLPE.blocks.1.norm.weight torch.Size([224]) True
2025-04-07 13:01: MLPE.blocks.1.norm.bias torch.Size([224]) True
2025-04-07 13:01: MLPE.blocks.2.linear.weight torch.Size([224, 224]) True
2025-04-07 13:01: MLPE.blocks.2.linear.bias torch.Size([224]) True
2025-04-07 13:01: MLPE.blocks.2.norm.weight torch.Size([224]) True
2025-04-07 13:01: MLPE.blocks.2.norm.bias torch.Size([224]) True
2025-04-07 13:01: MLPF.blocks.0.linear.weight torch.Size([12, 12]) True
2025-04-07 13:01: MLPF.blocks.0.linear.bias torch.Size([12]) True
2025-04-07 13:01: MLPF.blocks.0.norm.weight torch.Size([12]) True
2025-04-07 13:01: MLPF.blocks.0.norm.bias torch.Size([12]) True
2025-04-07 13:01: MLPF.blocks.1.linear.weight torch.Size([12, 12]) True
2025-04-07 13:01: MLPF.blocks.1.linear.bias torch.Size([12]) True
2025-04-07 13:01: MLPF.blocks.1.norm.weight torch.Size([12]) True
2025-04-07 13:01: MLPF.blocks.1.norm.bias torch.Size([12]) True
2025-04-07 13:01: steps_linear.weight torch.Size([9, 12]) True
2025-04-07 13:01: steps_linear.bias torch.Size([9]) True
2025-04-07 13:01: out_linear.weight torch.Size([1, 224]) True
2025-04-07 13:01: out_linear.bias torch.Size([1]) True
2025-04-07 13:01: Total params num: 217470
2025-04-07 13:01: *****************Finish Parameter****************
2025-04-07 13:01: Train Epoch 11: 40/159 Loss: 1.703579
2025-04-07 13:01: Train Epoch 1: 0/159 Loss: 65.589424
2025-04-07 13:01: Train Epoch 1: 20/159 Loss: 13.655357
2025-04-07 13:01: Train Epoch 1: 40/159 Loss: 9.163928
2025-04-07 13:01: Train Epoch 1: 60/159 Loss: 9.137123
2025-04-07 13:01: Train Epoch 1: 80/159 Loss: 7.879640
2025-04-07 13:02: Train Epoch 1: 100/159 Loss: 7.807212
2025-04-07 13:02: Train Epoch 1: 120/159 Loss: 6.331015
2025-04-07 13:02: Experiment log path in: /data/zm/2025code/log/in12_out9
2025-04-07 13:02: Train Epoch 1: 140/159 Loss: 6.243287
2025-04-07 13:02: Train: (10183, 12, 38, 3), (10183, 9, 38, 3)
2025-04-07 13:02: Val: (3394, 12, 38, 3), (3394, 9, 38, 3)
2025-04-07 13:02: Test: (3395, 12, 38, 3), (3395, 9, 38, 3)
2025-04-07 13:02: memory_usage: (0.837890625, 2.0)
2025-04-07 13:02: Applying learning rate decay.
2025-04-07 13:02: *****************Model Parameter*****************
2025-04-07 13:02: data_l torch.Size([96]) True
2025-04-07 13:02: tod_embedding.weight torch.Size([288, 32]) True
2025-04-07 13:02: dow_embedding.weight torch.Size([7, 32]) True
2025-04-07 13:02: SpatialEmbedding.B_sp torch.Size([307, 32]) True
2025-04-07 13:02: SpatialEmbedding.B_su torch.Size([307, 32]) True
2025-04-07 13:02: data_embedding.weight torch.Size([96, 1]) True
2025-04-07 13:02: data_embedding.bias torch.Size([96]) True
2025-04-07 13:02: MLPA.blocks.0.linear.weight torch.Size([64, 64]) True
2025-04-07 13:02: MLPA.blocks.0.linear.bias torch.Size([64]) True
2025-04-07 13:02: MLPA.blocks.0.norm.weight torch.Size([64]) True
2025-04-07 13:02: MLPA.blocks.0.norm.bias torch.Size([64]) True
2025-04-07 13:02: MLPB.blocks.0.linear.weight torch.Size([64, 64]) True
2025-04-07 13:02: MLPB.blocks.0.linear.bias torch.Size([64]) True
2025-04-07 13:02: MLPB.blocks.0.norm.weight torch.Size([64]) True
2025-04-07 13:02: MLPB.blocks.0.norm.bias torch.Size([64]) True
2025-04-07 13:02: MLPC.blocks.0.linear.weight torch.Size([96, 96]) True
2025-04-07 13:02: MLPC.blocks.0.linear.bias torch.Size([96]) True
2025-04-07 13:02: MLPC.blocks.0.norm.weight torch.Size([96]) True
2025-04-07 13:02: MLPC.blocks.0.norm.bias torch.Size([96]) True
2025-04-07 13:02: MLPD.blocks.0.linear.weight torch.Size([128, 128]) True
2025-04-07 13:02: MLPD.blocks.0.linear.bias torch.Size([128]) True
2025-04-07 13:02: MLPD.blocks.0.norm.weight torch.Size([128]) True
2025-04-07 13:02: MLPD.blocks.0.norm.bias torch.Size([128]) True
2025-04-07 13:02: MLPE.blocks.0.linear.weight torch.Size([224, 224]) True
2025-04-07 13:02: MLPE.blocks.0.linear.bias torch.Size([224]) True
2025-04-07 13:02: MLPE.blocks.0.norm.weight torch.Size([224]) True
2025-04-07 13:02: MLPE.blocks.0.norm.bias torch.Size([224]) True
2025-04-07 13:02: MLPE.blocks.1.linear.weight torch.Size([224, 224]) True
2025-04-07 13:02: MLPE.blocks.1.linear.bias torch.Size([224]) True
2025-04-07 13:02: MLPE.blocks.1.norm.weight torch.Size([224]) True
2025-04-07 13:02: MLPE.blocks.1.norm.bias torch.Size([224]) True
2025-04-07 13:02: MLPE.blocks.2.linear.weight torch.Size([224, 224]) True
2025-04-07 13:02: MLPE.blocks.2.linear.bias torch.Size([224]) True
2025-04-07 13:02: MLPE.blocks.2.norm.weight torch.Size([224]) True
2025-04-07 13:02: MLPE.blocks.2.norm.bias torch.Size([224]) True
2025-04-07 13:02: MLPF.blocks.0.linear.weight torch.Size([12, 12]) True
2025-04-07 13:02: MLPF.blocks.0.linear.bias torch.Size([12]) True
2025-04-07 13:02: MLPF.blocks.0.norm.weight torch.Size([12]) True
2025-04-07 13:02: MLPF.blocks.0.norm.bias torch.Size([12]) True
2025-04-07 13:02: MLPF.blocks.1.linear.weight torch.Size([12, 12]) True
2025-04-07 13:02: MLPF.blocks.1.linear.bias torch.Size([12]) True
2025-04-07 13:02: MLPF.blocks.1.norm.weight torch.Size([12]) True
2025-04-07 13:02: MLPF.blocks.1.norm.bias torch.Size([12]) True
2025-04-07 13:02: steps_linear.weight torch.Size([9, 12]) True
2025-04-07 13:02: steps_linear.bias torch.Size([9]) True
2025-04-07 13:02: out_linear.weight torch.Size([1, 224]) True
2025-04-07 13:02: out_linear.bias torch.Size([1]) True
2025-04-07 13:02: Total params num: 217470
2025-04-07 13:02: *****************Finish Parameter****************
2025-04-07 13:02: Train Epoch 1: 0/159 Loss: 65.589424
2025-04-07 13:02: **********Train Epoch 1: Average Loss: 9.884232
2025-04-07 13:02: **********Train Epoch 1: MAE: 9.884232 RMSE: 13.896668 MAPE: 0.155564
2025-04-07 13:02: Train Epoch 1: 20/159 Loss: 13.655357
2025-04-07 13:02: **********Val Epoch 1: Average Loss: 4.201629
2025-04-07 13:02: **********Val Epoch 1: MAE: 4.201629 RMSE: 8.235288 MAPE: 0.075937
2025-04-07 13:02: *********************************Current best model saved!
2025-04-07 13:02: Train Epoch 1: 0/159 Loss: 6.058083
2025-04-07 13:02: Train Epoch 1: 40/159 Loss: 9.163928
2025-04-07 13:02: Train Epoch 1: 60/159 Loss: 9.137123
2025-04-07 13:02: Train Epoch 1: 20/159 Loss: 5.897754
2025-04-07 13:02: Train Epoch 1: 80/159 Loss: 7.879640
2025-04-07 13:02: Train Epoch 1: 40/159 Loss: 5.246946
2025-04-07 13:02: Train Epoch 1: 100/159 Loss: 7.807212
2025-04-07 13:02: Train Epoch 1: 60/159 Loss: 5.367328
2025-04-07 13:02: Train Epoch 1: 120/159 Loss: 6.331015
2025-04-07 13:02: Train Epoch 1: 80/159 Loss: 4.573376
2025-04-07 13:02: Train Epoch 1: 140/159 Loss: 6.243287
2025-04-07 13:02: **********Train Epoch 1: Average Loss: 9.884232
2025-04-07 13:02: **********Train Epoch 1: MAE: 9.884232 RMSE: 13.896668 MAPE: 0.155564
2025-04-07 13:02: Train Epoch 1: 100/159 Loss: 4.846632
2025-04-07 13:02: **********Val Epoch 1: Average Loss: 4.201629
2025-04-07 13:02: **********Val Epoch 1: MAE: 4.201629 RMSE: 8.235288 MAPE: 0.075937
2025-04-07 13:02: *********************************Current best model saved!
2025-04-07 13:02: Train Epoch 1: 0/159 Loss: 6.058083
2025-04-07 13:02: Train Epoch 1: 120/159 Loss: 5.355935
2025-04-07 13:02: Train Epoch 1: 20/159 Loss: 5.897754
2025-04-07 13:02: Train Epoch 1: 140/159 Loss: 4.800341
2025-04-07 13:02: Train Epoch 1: 40/159 Loss: 5.246946
2025-04-07 13:02: **********Train Epoch 1: Average Loss: 5.256569
2025-04-07 13:02: **********Train Epoch 1: MAE: 5.256569 RMSE: 8.624588 MAPE: 0.091316
2025-04-07 13:02: **********Val Epoch 1: Average Loss: 3.428683
2025-04-07 13:02: **********Val Epoch 1: MAE: 3.428683 RMSE: 6.969414 MAPE: 0.064445
2025-04-07 13:02: *********************************Current best model saved!
2025-04-07 13:02: Train Epoch 1: 60/159 Loss: 5.367328
2025-04-07 13:03: Train Epoch 1: 80/159 Loss: 4.573376
2025-04-07 13:03: Train Epoch 1: 100/159 Loss: 4.846632
2025-04-07 13:03: Train Epoch 1: 120/159 Loss: 5.355935
2025-04-07 13:03: Train Epoch 1: 140/159 Loss: 4.800341
2025-04-07 13:03: **********Train Epoch 1: Average Loss: 5.256569
2025-04-07 13:03: **********Train Epoch 1: MAE: 5.256569 RMSE: 8.624588 MAPE: 0.091316
2025-04-07 13:03: **********Val Epoch 1: Average Loss: 3.428683
2025-04-07 13:03: **********Val Epoch 1: MAE: 3.428683 RMSE: 6.969414 MAPE: 0.064445
2025-04-07 13:03: *********************************Current best model saved!
2025-04-07 13:03: Total training time: 1.0215min, best loss: 3.428683
2025-04-07 13:04: Experiment log path in: /data/zm/2025code/log/in12_out9
2025-04-07 13:04: Train: (10183, 12, 38, 3), (10183, 9, 38, 3)
2025-04-07 13:04: Val: (3394, 12, 38, 3), (3394, 9, 38, 3)
2025-04-07 13:04: Test: (3395, 12, 38, 3), (3395, 9, 38, 3)
2025-04-07 13:04: memory_usage: (0.837890625, 2.0)
2025-04-07 13:05: Applying learning rate decay.
2025-04-07 13:05: *****************Model Parameter*****************
2025-04-07 13:05: data_l torch.Size([96]) True
2025-04-07 13:05: tod_embedding.weight torch.Size([288, 32]) True
2025-04-07 13:05: dow_embedding.weight torch.Size([7, 32]) True
2025-04-07 13:05: SpatialEmbedding.B_sp torch.Size([307, 32]) True
2025-04-07 13:05: SpatialEmbedding.B_su torch.Size([307, 32]) True
2025-04-07 13:05: data_embedding.weight torch.Size([96, 1]) True
2025-04-07 13:05: data_embedding.bias torch.Size([96]) True
2025-04-07 13:05: MLPA.blocks.0.linear.weight torch.Size([64, 64]) True
2025-04-07 13:05: MLPA.blocks.0.linear.bias torch.Size([64]) True
2025-04-07 13:05: MLPA.blocks.0.norm.weight torch.Size([64]) True
2025-04-07 13:05: MLPA.blocks.0.norm.bias torch.Size([64]) True
2025-04-07 13:05: MLPB.blocks.0.linear.weight torch.Size([64, 64]) True
2025-04-07 13:05: MLPB.blocks.0.linear.bias torch.Size([64]) True
2025-04-07 13:05: MLPB.blocks.0.norm.weight torch.Size([64]) True
2025-04-07 13:05: MLPB.blocks.0.norm.bias torch.Size([64]) True
2025-04-07 13:05: MLPC.blocks.0.linear.weight torch.Size([96, 96]) True
2025-04-07 13:05: MLPC.blocks.0.linear.bias torch.Size([96]) True
2025-04-07 13:05: MLPC.blocks.0.norm.weight torch.Size([96]) True
2025-04-07 13:05: MLPC.blocks.0.norm.bias torch.Size([96]) True
2025-04-07 13:05: MLPD.blocks.0.linear.weight torch.Size([128, 128]) True
2025-04-07 13:05: MLPD.blocks.0.linear.bias torch.Size([128]) True
2025-04-07 13:05: MLPD.blocks.0.norm.weight torch.Size([128]) True
2025-04-07 13:05: MLPD.blocks.0.norm.bias torch.Size([128]) True
2025-04-07 13:05: MLPE.blocks.0.linear.weight torch.Size([224, 224]) True
2025-04-07 13:05: MLPE.blocks.0.linear.bias torch.Size([224]) True
2025-04-07 13:05: MLPE.blocks.0.norm.weight torch.Size([224]) True
2025-04-07 13:05: MLPE.blocks.0.norm.bias torch.Size([224]) True
2025-04-07 13:05: MLPE.blocks.1.linear.weight torch.Size([224, 224]) True
2025-04-07 13:05: MLPE.blocks.1.linear.bias torch.Size([224]) True
2025-04-07 13:05: MLPE.blocks.1.norm.weight torch.Size([224]) True
2025-04-07 13:05: MLPE.blocks.1.norm.bias torch.Size([224]) True
2025-04-07 13:05: MLPE.blocks.2.linear.weight torch.Size([224, 224]) True
2025-04-07 13:05: MLPE.blocks.2.linear.bias torch.Size([224]) True
2025-04-07 13:05: MLPE.blocks.2.norm.weight torch.Size([224]) True
2025-04-07 13:05: MLPE.blocks.2.norm.bias torch.Size([224]) True
2025-04-07 13:05: MLPF.blocks.0.linear.weight torch.Size([12, 12]) True
2025-04-07 13:05: MLPF.blocks.0.linear.bias torch.Size([12]) True
2025-04-07 13:05: MLPF.blocks.0.norm.weight torch.Size([12]) True
2025-04-07 13:05: MLPF.blocks.0.norm.bias torch.Size([12]) True
2025-04-07 13:05: MLPF.blocks.1.linear.weight torch.Size([12, 12]) True
2025-04-07 13:05: MLPF.blocks.1.linear.bias torch.Size([12]) True
2025-04-07 13:05: MLPF.blocks.1.norm.weight torch.Size([12]) True
2025-04-07 13:05: MLPF.blocks.1.norm.bias torch.Size([12]) True
2025-04-07 13:05: steps_linear.weight torch.Size([9, 12]) True
2025-04-07 13:05: steps_linear.bias torch.Size([9]) True
2025-04-07 13:05: out_linear.weight torch.Size([1, 224]) True
2025-04-07 13:05: out_linear.bias torch.Size([1]) True
2025-04-07 13:05: Total params num: 217470
2025-04-07 13:05: *****************Finish Parameter****************
2025-04-07 13:05: Train Epoch 1: 0/159 Loss: 65.589424
2025-04-07 13:05: Train Epoch 1: 20/159 Loss: 13.655357
2025-04-07 13:05: Train Epoch 1: 40/159 Loss: 9.163928
2025-04-07 13:05: Train Epoch 1: 60/159 Loss: 9.137123
2025-04-07 13:05: Train Epoch 1: 80/159 Loss: 7.879640
2025-04-07 13:05: Train Epoch 1: 100/159 Loss: 7.807212
2025-04-07 13:05: Train Epoch 1: 120/159 Loss: 6.331015
2025-04-07 13:05: Train Epoch 1: 140/159 Loss: 6.243287
2025-04-07 13:05: **********Train Epoch 1: Average Loss: 9.884232
2025-04-07 13:05: **********Train Epoch 1: MAE: 9.884232 RMSE: 13.896668 MAPE: 0.155564
2025-04-07 13:05: **********Val Epoch 1: Average Loss: 4.201629
2025-04-07 13:05: **********Val Epoch 1: MAE: 4.201629 RMSE: 8.235288 MAPE: 0.075937
2025-04-07 13:05: *********************************Current best model saved!
2025-04-07 13:05: Train Epoch 1: 0/159 Loss: 6.058083
2025-04-07 13:05: Train Epoch 1: 20/159 Loss: 5.897754
2025-04-07 13:05: Train Epoch 1: 40/159 Loss: 5.246946
2025-04-07 13:05: Train Epoch 1: 60/159 Loss: 5.367328
2025-04-07 13:05: Train Epoch 1: 80/159 Loss: 4.573376
2025-04-07 13:05: Train Epoch 1: 100/159 Loss: 4.846632
2025-04-07 13:05: Train Epoch 1: 120/159 Loss: 5.355935
2025-04-07 13:05: Train Epoch 1: 140/159 Loss: 4.800341
2025-04-07 13:05: **********Train Epoch 1: Average Loss: 5.256569
2025-04-07 13:05: **********Train Epoch 1: MAE: 5.256569 RMSE: 8.624588 MAPE: 0.091316
2025-04-07 13:05: **********Val Epoch 1: Average Loss: 3.428683
2025-04-07 13:05: **********Val Epoch 1: MAE: 3.428683 RMSE: 6.969414 MAPE: 0.064445
2025-04-07 13:05: *********************************Current best model saved!
2025-04-07 13:05: Total training time: 0.9455min, best loss: 3.428683
2025-04-07 13:07: Experiment log path in: /data/zm/2025code/log/in12_out9
2025-04-07 13:07: Train: (10183, 12, 38, 3), (10183, 9, 38, 3)
2025-04-07 13:07: Val: (3394, 12, 38, 3), (3394, 9, 38, 3)
2025-04-07 13:07: Test: (3395, 12, 38, 3), (3395, 9, 38, 3)
2025-04-07 13:07: memory_usage: (0.837890625, 2.0)
2025-04-07 13:07: Applying learning rate decay.
2025-04-07 13:07: *****************Model Parameter*****************
2025-04-07 13:07: data_l torch.Size([96]) True
2025-04-07 13:07: tod_embedding.weight torch.Size([288, 32]) True
2025-04-07 13:07: dow_embedding.weight torch.Size([7, 32]) True
2025-04-07 13:07: SpatialEmbedding.B_sp torch.Size([307, 32]) True
2025-04-07 13:07: SpatialEmbedding.B_su torch.Size([307, 32]) True
2025-04-07 13:07: data_embedding.weight torch.Size([96, 1]) True
2025-04-07 13:07: data_embedding.bias torch.Size([96]) True
2025-04-07 13:07: MLPA.blocks.0.linear.weight torch.Size([64, 64]) True
2025-04-07 13:07: MLPA.blocks.0.linear.bias torch.Size([64]) True
2025-04-07 13:07: MLPA.blocks.0.norm.weight torch.Size([64]) True
2025-04-07 13:07: MLPA.blocks.0.norm.bias torch.Size([64]) True
2025-04-07 13:07: MLPB.blocks.0.linear.weight torch.Size([64, 64]) True
2025-04-07 13:07: MLPB.blocks.0.linear.bias torch.Size([64]) True
2025-04-07 13:07: MLPB.blocks.0.norm.weight torch.Size([64]) True
2025-04-07 13:07: MLPB.blocks.0.norm.bias torch.Size([64]) True
2025-04-07 13:07: MLPC.blocks.0.linear.weight torch.Size([96, 96]) True
2025-04-07 13:07: MLPC.blocks.0.linear.bias torch.Size([96]) True
2025-04-07 13:07: MLPC.blocks.0.norm.weight torch.Size([96]) True
2025-04-07 13:07: MLPC.blocks.0.norm.bias torch.Size([96]) True
2025-04-07 13:07: MLPD.blocks.0.linear.weight torch.Size([128, 128]) True
2025-04-07 13:07: MLPD.blocks.0.linear.bias torch.Size([128]) True
2025-04-07 13:07: MLPD.blocks.0.norm.weight torch.Size([128]) True
2025-04-07 13:07: MLPD.blocks.0.norm.bias torch.Size([128]) True
2025-04-07 13:07: MLPE.blocks.0.linear.weight torch.Size([224, 224]) True
2025-04-07 13:07: MLPE.blocks.0.linear.bias torch.Size([224]) True
2025-04-07 13:07: MLPE.blocks.0.norm.weight torch.Size([224]) True
2025-04-07 13:07: MLPE.blocks.0.norm.bias torch.Size([224]) True
2025-04-07 13:07: MLPE.blocks.1.linear.weight torch.Size([224, 224]) True
2025-04-07 13:07: MLPE.blocks.1.linear.bias torch.Size([224]) True
2025-04-07 13:07: MLPE.blocks.1.norm.weight torch.Size([224]) True
2025-04-07 13:07: MLPE.blocks.1.norm.bias torch.Size([224]) True
2025-04-07 13:07: MLPE.blocks.2.linear.weight torch.Size([224, 224]) True
2025-04-07 13:07: MLPE.blocks.2.linear.bias torch.Size([224]) True
2025-04-07 13:07: MLPE.blocks.2.norm.weight torch.Size([224]) True
2025-04-07 13:07: MLPE.blocks.2.norm.bias torch.Size([224]) True
2025-04-07 13:07: MLPF.blocks.0.linear.weight torch.Size([12, 12]) True
2025-04-07 13:07: MLPF.blocks.0.linear.bias torch.Size([12]) True
2025-04-07 13:07: MLPF.blocks.0.norm.weight torch.Size([12]) True
2025-04-07 13:07: MLPF.blocks.0.norm.bias torch.Size([12]) True
2025-04-07 13:07: MLPF.blocks.1.linear.weight torch.Size([12, 12]) True
2025-04-07 13:07: MLPF.blocks.1.linear.bias torch.Size([12]) True
2025-04-07 13:07: MLPF.blocks.1.norm.weight torch.Size([12]) True
2025-04-07 13:07: MLPF.blocks.1.norm.bias torch.Size([12]) True
2025-04-07 13:07: steps_linear.weight torch.Size([9, 12]) True
2025-04-07 13:07: steps_linear.bias torch.Size([9]) True
2025-04-07 13:07: out_linear.weight torch.Size([1, 224]) True
2025-04-07 13:07: out_linear.bias torch.Size([1]) True
2025-04-07 13:07: Total params num: 217470
2025-04-07 13:07: *****************Finish Parameter****************
2025-04-07 13:07: Train Epoch 1: 0/159 Loss: 65.589424
2025-04-07 13:07: Train Epoch 1: 20/159 Loss: 13.655357
2025-04-07 13:07: Train Epoch 1: 40/159 Loss: 9.163928
2025-04-07 13:07: Train Epoch 1: 60/159 Loss: 9.137123
2025-04-07 13:07: Train Epoch 1: 80/159 Loss: 7.879640
2025-04-07 13:07: Train Epoch 1: 100/159 Loss: 7.807212
2025-04-07 13:07: Train Epoch 1: 120/159 Loss: 6.331015
2025-04-07 13:07: Train Epoch 1: 140/159 Loss: 6.243287
2025-04-07 13:07: **********Train Epoch 1: Average Loss: 9.884232
2025-04-07 13:07: **********Train Epoch 1: MAE: 9.884232 RMSE: 13.896668 MAPE: 0.155564
2025-04-07 13:07: **********Val Epoch 1: Average Loss: 4.201629
2025-04-07 13:07: **********Val Epoch 1: MAE: 4.201629 RMSE: 8.235288 MAPE: 0.075937
2025-04-07 13:07: *********************************Current best model saved!
2025-04-07 13:07: Train Epoch 1: 0/159 Loss: 6.058083
2025-04-07 13:07: Train Epoch 1: 20/159 Loss: 5.897754
2025-04-07 13:07: Train Epoch 1: 40/159 Loss: 5.246946
2025-04-07 13:07: Train Epoch 1: 60/159 Loss: 5.367328
2025-04-07 13:07: Train Epoch 1: 80/159 Loss: 4.573376
2025-04-07 13:07: Train Epoch 1: 100/159 Loss: 4.846632
2025-04-07 13:07: Train Epoch 1: 120/159 Loss: 5.355935
2025-04-07 13:07: Train Epoch 1: 140/159 Loss: 4.800341
2025-04-07 13:07: **********Train Epoch 1: Average Loss: 5.256569
2025-04-07 13:07: **********Train Epoch 1: MAE: 5.256569 RMSE: 8.624588 MAPE: 0.091316
2025-04-07 13:08: **********Val Epoch 1: Average Loss: 3.428683
2025-04-07 13:08: **********Val Epoch 1: MAE: 3.428683 RMSE: 6.969414 MAPE: 0.064445
2025-04-07 13:08: *********************************Current best model saved!
2025-04-07 13:08: Total training time: 0.9570min, best loss: 3.428683
2025-04-07 13:08: Experiment log path in: /data/zm/2025code/log/in12_out9
2025-04-07 13:08: Train: (10183, 12, 38, 3), (10183, 9, 38, 3)
2025-04-07 13:08: Val: (3394, 12, 38, 3), (3394, 9, 38, 3)
2025-04-07 13:08: Test: (3395, 12, 38, 3), (3395, 9, 38, 3)
2025-04-07 13:08: memory_usage: (0.837890625, 2.0)
2025-04-07 13:08: Applying learning rate decay.
2025-04-07 13:08: *****************Model Parameter*****************
2025-04-07 13:08: data_l torch.Size([96]) True
2025-04-07 13:08: tod_embedding.weight torch.Size([288, 32]) True
2025-04-07 13:08: dow_embedding.weight torch.Size([7, 32]) True
2025-04-07 13:08: SpatialEmbedding.B_sp torch.Size([307, 32]) True
2025-04-07 13:08: SpatialEmbedding.B_su torch.Size([307, 32]) True
2025-04-07 13:08: data_embedding.weight torch.Size([96, 1]) True
2025-04-07 13:08: data_embedding.bias torch.Size([96]) True
2025-04-07 13:08: MLPA.blocks.0.linear.weight torch.Size([64, 64]) True
2025-04-07 13:08: MLPA.blocks.0.linear.bias torch.Size([64]) True
2025-04-07 13:08: MLPA.blocks.0.norm.weight torch.Size([64]) True
2025-04-07 13:08: MLPA.blocks.0.norm.bias torch.Size([64]) True
2025-04-07 13:08: MLPB.blocks.0.linear.weight torch.Size([64, 64]) True
2025-04-07 13:08: MLPB.blocks.0.linear.bias torch.Size([64]) True
2025-04-07 13:08: MLPB.blocks.0.norm.weight torch.Size([64]) True
2025-04-07 13:08: MLPB.blocks.0.norm.bias torch.Size([64]) True
2025-04-07 13:08: MLPC.blocks.0.linear.weight torch.Size([96, 96]) True
2025-04-07 13:08: MLPC.blocks.0.linear.bias torch.Size([96]) True
2025-04-07 13:08: MLPC.blocks.0.norm.weight torch.Size([96]) True
2025-04-07 13:08: MLPC.blocks.0.norm.bias torch.Size([96]) True
2025-04-07 13:08: MLPD.blocks.0.linear.weight torch.Size([128, 128]) True
2025-04-07 13:08: MLPD.blocks.0.linear.bias torch.Size([128]) True
2025-04-07 13:08: MLPD.blocks.0.norm.weight torch.Size([128]) True
2025-04-07 13:08: MLPD.blocks.0.norm.bias torch.Size([128]) True
2025-04-07 13:08: MLPE.blocks.0.linear.weight torch.Size([224, 224]) True
2025-04-07 13:08: MLPE.blocks.0.linear.bias torch.Size([224]) True
2025-04-07 13:08: MLPE.blocks.0.norm.weight torch.Size([224]) True
2025-04-07 13:08: MLPE.blocks.0.norm.bias torch.Size([224]) True
2025-04-07 13:08: MLPE.blocks.1.linear.weight torch.Size([224, 224]) True
2025-04-07 13:08: MLPE.blocks.1.linear.bias torch.Size([224]) True
2025-04-07 13:08: MLPE.blocks.1.norm.weight torch.Size([224]) True
2025-04-07 13:08: MLPE.blocks.1.norm.bias torch.Size([224]) True
2025-04-07 13:08: MLPE.blocks.2.linear.weight torch.Size([224, 224]) True
2025-04-07 13:08: MLPE.blocks.2.linear.bias torch.Size([224]) True
2025-04-07 13:08: MLPE.blocks.2.norm.weight torch.Size([224]) True
2025-04-07 13:08: MLPE.blocks.2.norm.bias torch.Size([224]) True
2025-04-07 13:08: MLPF.blocks.0.linear.weight torch.Size([12, 12]) True
2025-04-07 13:08: MLPF.blocks.0.linear.bias torch.Size([12]) True
2025-04-07 13:08: MLPF.blocks.0.norm.weight torch.Size([12]) True
2025-04-07 13:08: MLPF.blocks.0.norm.bias torch.Size([12]) True
2025-04-07 13:08: MLPF.blocks.1.linear.weight torch.Size([12, 12]) True
2025-04-07 13:08: MLPF.blocks.1.linear.bias torch.Size([12]) True
2025-04-07 13:08: MLPF.blocks.1.norm.weight torch.Size([12]) True
2025-04-07 13:08: MLPF.blocks.1.norm.bias torch.Size([12]) True
2025-04-07 13:08: steps_linear.weight torch.Size([9, 12]) True
2025-04-07 13:08: steps_linear.bias torch.Size([9]) True
2025-04-07 13:08: out_linear.weight torch.Size([1, 224]) True
2025-04-07 13:08: out_linear.bias torch.Size([1]) True
2025-04-07 13:08: Total params num: 217470
2025-04-07 13:08: *****************Finish Parameter****************
2025-04-07 13:08: Train Epoch 1: 0/159 Loss: 65.589424
2025-04-07 13:08: Train Epoch 1: 20/159 Loss: 13.655357
2025-04-07 13:08: Train Epoch 1: 40/159 Loss: 9.163928
2025-04-07 13:08: Train Epoch 1: 60/159 Loss: 9.137123
2025-04-07 13:08: Train Epoch 1: 80/159 Loss: 7.879640
2025-04-07 13:08: Train Epoch 1: 100/159 Loss: 7.807212
2025-04-07 13:08: Train Epoch 1: 120/159 Loss: 6.331015
2025-04-07 13:08: Train Epoch 1: 140/159 Loss: 6.243287
2025-04-07 13:08: **********Train Epoch 1: Average Loss: 9.884232
2025-04-07 13:08: **********Train Epoch 1: MAE: 9.884232 RMSE: 13.896668 MAPE: 0.155564
2025-04-07 13:08: **********Val Epoch 1: Average Loss: 4.201629
2025-04-07 13:08: **********Val Epoch 1: MAE: 4.201629 RMSE: 8.235288 MAPE: 0.075937
2025-04-07 13:08: *********************************Current best model saved!
2025-04-07 13:08: Train Epoch 1: 0/159 Loss: 6.058083
2025-04-07 13:08: Train Epoch 1: 20/159 Loss: 5.897754
2025-04-07 13:09: Train Epoch 1: 40/159 Loss: 5.246946
2025-04-07 13:09: Train Epoch 1: 60/159 Loss: 5.367328
2025-04-07 13:09: Train Epoch 1: 80/159 Loss: 4.573376
2025-04-07 13:09: Train Epoch 1: 100/159 Loss: 4.846632
2025-04-07 13:09: Train Epoch 1: 120/159 Loss: 5.355935
2025-04-07 13:09: Train Epoch 1: 140/159 Loss: 4.800341
2025-04-07 13:09: **********Train Epoch 1: Average Loss: 5.256569
2025-04-07 13:09: **********Train Epoch 1: MAE: 5.256569 RMSE: 8.624588 MAPE: 0.091316
2025-04-07 13:09: **********Val Epoch 1: Average Loss: 3.428683
2025-04-07 13:09: **********Val Epoch 1: MAE: 3.428683 RMSE: 6.969414 MAPE: 0.064445
2025-04-07 13:09: *********************************Current best model saved!
2025-04-07 13:09: Total training time: 0.9556min, best loss: 3.428683
2025-04-07 13:09: Saving current best model to ./checkpoints/PeMSD4SPEED_12_9_3.pth
2025-04-07 13:09: Horizon 01, MAE: 2.5073, RMSE: 4.8945, MAPE: 6.9790%
2025-04-07 13:09: Horizon 02, MAE: 2.9139, RMSE: 5.1038, MAPE: 7.4250%
2025-04-07 13:09: Horizon 03, MAE: 4.1876, RMSE: 8.3094, MAPE: 11.8065%
2025-04-07 13:09: Horizon 04, MAE: 3.5968, RMSE: 7.3607, MAPE: 10.3366%
2025-04-07 13:09: Horizon 05, MAE: 3.4877, RMSE: 6.9033, MAPE: 9.7635%
2025-04-07 13:09: Horizon 06, MAE: 2.9709, RMSE: 6.1465, MAPE: 8.5464%
2025-04-07 13:09: Horizon 07, MAE: 3.1733, RMSE: 7.0271, MAPE: 9.6079%
2025-04-07 13:09: Horizon 08, MAE: 3.2516, RMSE: 6.2948, MAPE: 8.7503%
2025-04-07 13:09: Horizon 09, MAE: 4.2793, RMSE: 8.8940, MAPE: 12.3427%
2025-04-07 13:09: Average Horizon, MAE: 3.3743, RMSE: 6.8862, MAPE: 9.5064%
